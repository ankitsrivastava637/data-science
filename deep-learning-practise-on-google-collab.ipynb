{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlDvRDLWiiGx"
      },
      "source": [
        "**Chapter 2 : Intro to Theano**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzAS_ucShAUO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4c346037-3043-438e-85b7-ba54e0569e3c"
      },
      "source": [
        "#Example of Theano library\n",
        "import theano\n",
        "from theano import tensor\n",
        "#declare two symbolic floating-point scalars\n",
        "a = tensor.dscalar()\n",
        "b = tensor.dscalar()\n",
        "#create a symbolic expression\n",
        "c = a + b\n",
        "# convert the expression into a callable object that takes (a,b) and computes c\n",
        "f = theano.function([a,b], c)\n",
        "# bind 1.5 to 'a', 2.5 to 'b' and evaluate 'c'\n",
        "result = f(1.5, 2.5)\n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMPHuDMYjeug"
      },
      "source": [
        "**# Chapter 3 : Intro to TensorFlow**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xp3kGcCAjqqR"
      },
      "source": [
        "**Simple TensorFlow example :**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESv_d5hLhAgq"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVKoAm46hAj6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c6b7661d-6d69-4903-af0d-b68ca502d125"
      },
      "source": [
        "\n",
        "import os\n",
        "import inspect\n",
        "import tensorflow\n",
        "print(os.path.dirname(inspect.getfile(tensorflow)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b97hS5_Giebi"
      },
      "source": [
        "**Chapter 4 : Intro to Keras**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4N0V3sehAqA"
      },
      "source": [
        "import keras as k"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckqAYPr9cvgO"
      },
      "source": [
        "from keras.layers import *\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import numpy\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSMNgPgAhAv9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "1c300581-c682-4db4-d835-be95d3d7ac7c"
      },
      "source": [
        "#Load Pima India Onset of Diabetes Dataset\n",
        "\n",
        "import pandas as pd\n",
        "dataset = pd.read_csv(\"/content/diabetes.csv\")\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>763</th>\n",
              "      <td>10</td>\n",
              "      <td>101</td>\n",
              "      <td>76</td>\n",
              "      <td>48</td>\n",
              "      <td>180</td>\n",
              "      <td>32.9</td>\n",
              "      <td>0.171</td>\n",
              "      <td>63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>764</th>\n",
              "      <td>2</td>\n",
              "      <td>122</td>\n",
              "      <td>70</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "      <td>36.8</td>\n",
              "      <td>0.340</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>765</th>\n",
              "      <td>5</td>\n",
              "      <td>121</td>\n",
              "      <td>72</td>\n",
              "      <td>23</td>\n",
              "      <td>112</td>\n",
              "      <td>26.2</td>\n",
              "      <td>0.245</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>766</th>\n",
              "      <td>1</td>\n",
              "      <td>126</td>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30.1</td>\n",
              "      <td>0.349</td>\n",
              "      <td>47</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>767</th>\n",
              "      <td>1</td>\n",
              "      <td>93</td>\n",
              "      <td>70</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>30.4</td>\n",
              "      <td>0.315</td>\n",
              "      <td>23</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>768 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Pregnancies  Glucose  ...  Age  Outcome\n",
              "0              6      148  ...   50        1\n",
              "1              1       85  ...   31        0\n",
              "2              8      183  ...   32        1\n",
              "3              1       89  ...   21        0\n",
              "4              0      137  ...   33        1\n",
              "..           ...      ...  ...  ...      ...\n",
              "763           10      101  ...   63        0\n",
              "764            2      122  ...   27        0\n",
              "765            5      121  ...   30        0\n",
              "766            1      126  ...   47        1\n",
              "767            1       93  ...   23        0\n",
              "\n",
              "[768 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZsDfIO7hAy5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "8ef90787-736d-4881-f648-e2738ac9a5bc"
      },
      "source": [
        "#Split into Input(X) and Output(Y) variables\n",
        "X = dataset.iloc[:, :8]\n",
        "Y = dataset.iloc[:, 8]\n",
        "X\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>763</th>\n",
              "      <td>10</td>\n",
              "      <td>101</td>\n",
              "      <td>76</td>\n",
              "      <td>48</td>\n",
              "      <td>180</td>\n",
              "      <td>32.9</td>\n",
              "      <td>0.171</td>\n",
              "      <td>63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>764</th>\n",
              "      <td>2</td>\n",
              "      <td>122</td>\n",
              "      <td>70</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "      <td>36.8</td>\n",
              "      <td>0.340</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>765</th>\n",
              "      <td>5</td>\n",
              "      <td>121</td>\n",
              "      <td>72</td>\n",
              "      <td>23</td>\n",
              "      <td>112</td>\n",
              "      <td>26.2</td>\n",
              "      <td>0.245</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>766</th>\n",
              "      <td>1</td>\n",
              "      <td>126</td>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30.1</td>\n",
              "      <td>0.349</td>\n",
              "      <td>47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>767</th>\n",
              "      <td>1</td>\n",
              "      <td>93</td>\n",
              "      <td>70</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>30.4</td>\n",
              "      <td>0.315</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>768 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Pregnancies  Glucose  BloodPressure  ...   BMI  DiabetesPedigreeFunction  Age\n",
              "0              6      148             72  ...  33.6                     0.627   50\n",
              "1              1       85             66  ...  26.6                     0.351   31\n",
              "2              8      183             64  ...  23.3                     0.672   32\n",
              "3              1       89             66  ...  28.1                     0.167   21\n",
              "4              0      137             40  ...  43.1                     2.288   33\n",
              "..           ...      ...            ...  ...   ...                       ...  ...\n",
              "763           10      101             76  ...  32.9                     0.171   63\n",
              "764            2      122             70  ...  36.8                     0.340   27\n",
              "765            5      121             72  ...  26.2                     0.245   30\n",
              "766            1      126             60  ...  30.1                     0.349   47\n",
              "767            1       93             70  ...  30.4                     0.315   23\n",
              "\n",
              "[768 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uAo7uEDhA2G",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "de823bd8-0d41-4edd-a703-5eb9aeaa1072"
      },
      "source": [
        "Y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      1\n",
              "1      0\n",
              "2      1\n",
              "3      0\n",
              "4      1\n",
              "      ..\n",
              "763    0\n",
              "764    0\n",
              "765    0\n",
              "766    1\n",
              "767    0\n",
              "Name: Outcome, Length: 768, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0A7G4qi9hA5T"
      },
      "source": [
        "#Create-Define Model\n",
        "\n",
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model\n",
        "import tensorflow as tf\n",
        "from keras.layers import *\n",
        "from keras.models import Sequential\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim=8, kernel_initializer='uniform', activation='relu'))\n",
        "model.add(Dense(8, kernel_initializer='uniform', activation='relu'))\n",
        "model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9n6EnbXNT7N1"
      },
      "source": [
        "#Model Compile\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGG3iVxjT7Qk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 806
        },
        "outputId": "330356e2-75ae-459a-ba04-6b5f5bc50126"
      },
      "source": [
        "#Fit the Model on Data\n",
        "\n",
        "model.fit(X, Y, epochs = 23, batch_size = 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/23\n",
            "768/768 [==============================] - 0s 177us/step - loss: 0.3535 - accuracy: 0.8438\n",
            "Epoch 2/23\n",
            "768/768 [==============================] - 0s 137us/step - loss: 0.3578 - accuracy: 0.8542\n",
            "Epoch 3/23\n",
            "768/768 [==============================] - 0s 134us/step - loss: 0.3706 - accuracy: 0.8385\n",
            "Epoch 4/23\n",
            "768/768 [==============================] - 0s 124us/step - loss: 0.3788 - accuracy: 0.8307\n",
            "Epoch 5/23\n",
            "768/768 [==============================] - 0s 143us/step - loss: 0.3784 - accuracy: 0.8268\n",
            "Epoch 6/23\n",
            "768/768 [==============================] - 0s 132us/step - loss: 0.3574 - accuracy: 0.8372\n",
            "Epoch 7/23\n",
            "768/768 [==============================] - 0s 141us/step - loss: 0.3540 - accuracy: 0.8320\n",
            "Epoch 8/23\n",
            "768/768 [==============================] - 0s 154us/step - loss: 0.3595 - accuracy: 0.8320\n",
            "Epoch 9/23\n",
            "768/768 [==============================] - 0s 131us/step - loss: 0.3617 - accuracy: 0.8333\n",
            "Epoch 10/23\n",
            "768/768 [==============================] - 0s 144us/step - loss: 0.3537 - accuracy: 0.8320\n",
            "Epoch 11/23\n",
            "768/768 [==============================] - 0s 127us/step - loss: 0.3692 - accuracy: 0.8424\n",
            "Epoch 12/23\n",
            "768/768 [==============================] - 0s 126us/step - loss: 0.3677 - accuracy: 0.8242\n",
            "Epoch 13/23\n",
            "768/768 [==============================] - 0s 145us/step - loss: 0.3717 - accuracy: 0.8307\n",
            "Epoch 14/23\n",
            "768/768 [==============================] - 0s 128us/step - loss: 0.3630 - accuracy: 0.8359\n",
            "Epoch 15/23\n",
            "768/768 [==============================] - 0s 130us/step - loss: 0.3716 - accuracy: 0.8333\n",
            "Epoch 16/23\n",
            "768/768 [==============================] - 0s 146us/step - loss: 0.3795 - accuracy: 0.8333\n",
            "Epoch 17/23\n",
            "768/768 [==============================] - 0s 144us/step - loss: 0.3582 - accuracy: 0.8333\n",
            "Epoch 18/23\n",
            "768/768 [==============================] - 0s 132us/step - loss: 0.3578 - accuracy: 0.8320\n",
            "Epoch 19/23\n",
            "768/768 [==============================] - 0s 165us/step - loss: 0.3619 - accuracy: 0.8333\n",
            "Epoch 20/23\n",
            "768/768 [==============================] - 0s 132us/step - loss: 0.3506 - accuracy: 0.8464\n",
            "Epoch 21/23\n",
            "768/768 [==============================] - 0s 133us/step - loss: 0.3635 - accuracy: 0.8372\n",
            "Epoch 22/23\n",
            "768/768 [==============================] - 0s 136us/step - loss: 0.3671 - accuracy: 0.8424\n",
            "Epoch 23/23\n",
            "768/768 [==============================] - 0s 123us/step - loss: 0.3613 - accuracy: 0.8464\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f8a335c3a20>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOeQF0zWT7TQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "f439d05c-e095-492d-e02d-75820c7793a8"
      },
      "source": [
        "#Evaluate the Model \n",
        "\n",
        "scores = model.evaluate(X, Y)\n",
        "print(model.metrics_names[1], scores[1]*100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "768/768 [==============================] - 0s 36us/step\n",
            "accuracy 83.33333134651184\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mR4z9fo5T7WJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dd20e760-d205-4b79-cb72-89541a40cef8"
      },
      "source": [
        "from keras.layers import *\n",
        "from keras.models import *\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import numpy\n",
        "# fix random seed for reproducibilty\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "\n",
        "\n",
        "#Load Pima Indian Onset of Diabetic Dataset\n",
        "import pandas as pd\n",
        "dataset = pd.read_csv(\"/content/diabetes.csv\")\n",
        "\n",
        "#Split the data into X and Y variables\n",
        "X = dataset.iloc[:, :8]\n",
        "Y = dataset.iloc[:, 8]\n",
        "\n",
        "#Create-Define Model\n",
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim = 8, kernel_initializer='uniform', activation = 'relu'))\n",
        "model.add(Dense(8, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "model.add(Dense(1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
        "\n",
        "#Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer= 'adam', metrics=['accuracy'])\n",
        "\n",
        "#Fit the Model on the Data\n",
        "model.fit(X, Y, epochs = 10000, batch_size = 10)\n",
        "\n",
        "#Evaluate the model \n",
        "scores = model.evaluate(X, Y) \n",
        "print(model.metrics_names[1], scores[1]*100)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 3814/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4022 - accuracy: 0.8021\n",
            "Epoch 3815/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4140 - accuracy: 0.8060\n",
            "Epoch 3816/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4124 - accuracy: 0.7995\n",
            "Epoch 3817/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4180 - accuracy: 0.8073\n",
            "Epoch 3818/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4188 - accuracy: 0.8021\n",
            "Epoch 3819/10000\n",
            "768/768 [==============================] - 0s 131us/step - loss: 0.4040 - accuracy: 0.8151\n",
            "Epoch 3820/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4072 - accuracy: 0.8164\n",
            "Epoch 3821/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4048 - accuracy: 0.8073\n",
            "Epoch 3822/10000\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4016 - accuracy: 0.8125\n",
            "Epoch 3823/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4124 - accuracy: 0.7969\n",
            "Epoch 3824/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4204 - accuracy: 0.7969\n",
            "Epoch 3825/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4139 - accuracy: 0.8060\n",
            "Epoch 3826/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4114 - accuracy: 0.8047\n",
            "Epoch 3827/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4095 - accuracy: 0.8177\n",
            "Epoch 3828/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4101 - accuracy: 0.8021\n",
            "Epoch 3829/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4099 - accuracy: 0.8112\n",
            "Epoch 3830/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4103 - accuracy: 0.8008\n",
            "Epoch 3831/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4157 - accuracy: 0.8021\n",
            "Epoch 3832/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4325 - accuracy: 0.7930\n",
            "Epoch 3833/10000\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.4092 - accuracy: 0.8034\n",
            "Epoch 3834/10000\n",
            "768/768 [==============================] - 0s 120us/step - loss: 0.4111 - accuracy: 0.8099\n",
            "Epoch 3835/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4088 - accuracy: 0.8008\n",
            "Epoch 3836/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4088 - accuracy: 0.7904\n",
            "Epoch 3837/10000\n",
            "768/768 [==============================] - 0s 128us/step - loss: 0.4053 - accuracy: 0.8138\n",
            "Epoch 3838/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4103 - accuracy: 0.7995\n",
            "Epoch 3839/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4061 - accuracy: 0.8177\n",
            "Epoch 3840/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4069 - accuracy: 0.8060\n",
            "Epoch 3841/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4162 - accuracy: 0.8021\n",
            "Epoch 3842/10000\n",
            "768/768 [==============================] - 0s 124us/step - loss: 0.4090 - accuracy: 0.8086\n",
            "Epoch 3843/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4165 - accuracy: 0.8034\n",
            "Epoch 3844/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4058 - accuracy: 0.8112\n",
            "Epoch 3845/10000\n",
            "768/768 [==============================] - 0s 120us/step - loss: 0.4076 - accuracy: 0.7956\n",
            "Epoch 3846/10000\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.4089 - accuracy: 0.8086\n",
            "Epoch 3847/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4164 - accuracy: 0.8060\n",
            "Epoch 3848/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4077 - accuracy: 0.8112\n",
            "Epoch 3849/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4033 - accuracy: 0.8060\n",
            "Epoch 3850/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4081 - accuracy: 0.8086\n",
            "Epoch 3851/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4132 - accuracy: 0.7943\n",
            "Epoch 3852/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4076 - accuracy: 0.7982\n",
            "Epoch 3853/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4029 - accuracy: 0.8125\n",
            "Epoch 3854/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4206 - accuracy: 0.7995\n",
            "Epoch 3855/10000\n",
            "768/768 [==============================] - 0s 120us/step - loss: 0.4070 - accuracy: 0.8086\n",
            "Epoch 3856/10000\n",
            "768/768 [==============================] - 0s 120us/step - loss: 0.4150 - accuracy: 0.8060\n",
            "Epoch 3857/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4154 - accuracy: 0.8008\n",
            "Epoch 3858/10000\n",
            "768/768 [==============================] - 0s 110us/step - loss: 0.4090 - accuracy: 0.7917\n",
            "Epoch 3859/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4098 - accuracy: 0.7982\n",
            "Epoch 3860/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4112 - accuracy: 0.7995\n",
            "Epoch 3861/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4166 - accuracy: 0.7930\n",
            "Epoch 3862/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4157 - accuracy: 0.8125\n",
            "Epoch 3863/10000\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.4086 - accuracy: 0.8047\n",
            "Epoch 3864/10000\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.4112 - accuracy: 0.7969\n",
            "Epoch 3865/10000\n",
            "768/768 [==============================] - 0s 122us/step - loss: 0.4109 - accuracy: 0.7930\n",
            "Epoch 3866/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4130 - accuracy: 0.8073\n",
            "Epoch 3867/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4111 - accuracy: 0.8099\n",
            "Epoch 3868/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4142 - accuracy: 0.7995\n",
            "Epoch 3869/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4089 - accuracy: 0.7956\n",
            "Epoch 3870/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4236 - accuracy: 0.8034\n",
            "Epoch 3871/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4115 - accuracy: 0.7995\n",
            "Epoch 3872/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4057 - accuracy: 0.8060\n",
            "Epoch 3873/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4059 - accuracy: 0.8034\n",
            "Epoch 3874/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4090 - accuracy: 0.8112\n",
            "Epoch 3875/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4147 - accuracy: 0.8008\n",
            "Epoch 3876/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4236 - accuracy: 0.7956\n",
            "Epoch 3877/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4109 - accuracy: 0.7930\n",
            "Epoch 3878/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4145 - accuracy: 0.7995\n",
            "Epoch 3879/10000\n",
            "768/768 [==============================] - 0s 125us/step - loss: 0.4085 - accuracy: 0.8138\n",
            "Epoch 3880/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4045 - accuracy: 0.8086\n",
            "Epoch 3881/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4165 - accuracy: 0.7943\n",
            "Epoch 3882/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4062 - accuracy: 0.8047\n",
            "Epoch 3883/10000\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.4193 - accuracy: 0.8021\n",
            "Epoch 3884/10000\n",
            "768/768 [==============================] - 0s 127us/step - loss: 0.4118 - accuracy: 0.8008\n",
            "Epoch 3885/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4074 - accuracy: 0.8047\n",
            "Epoch 3886/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4153 - accuracy: 0.8060\n",
            "Epoch 3887/10000\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4142 - accuracy: 0.7956\n",
            "Epoch 3888/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4061 - accuracy: 0.8008\n",
            "Epoch 3889/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4142 - accuracy: 0.7956\n",
            "Epoch 3890/10000\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4195 - accuracy: 0.7982\n",
            "Epoch 3891/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4062 - accuracy: 0.8047\n",
            "Epoch 3892/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4066 - accuracy: 0.8060\n",
            "Epoch 3893/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4026 - accuracy: 0.7956\n",
            "Epoch 3894/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4136 - accuracy: 0.8086\n",
            "Epoch 3895/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4055 - accuracy: 0.8047\n",
            "Epoch 3896/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4079 - accuracy: 0.8073\n",
            "Epoch 3897/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4164 - accuracy: 0.8164\n",
            "Epoch 3898/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4133 - accuracy: 0.8099\n",
            "Epoch 3899/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4061 - accuracy: 0.8047\n",
            "Epoch 3900/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4045 - accuracy: 0.8073\n",
            "Epoch 3901/10000\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.4128 - accuracy: 0.8086\n",
            "Epoch 3902/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4023 - accuracy: 0.8021\n",
            "Epoch 3903/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4159 - accuracy: 0.7878\n",
            "Epoch 3904/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4282 - accuracy: 0.7956\n",
            "Epoch 3905/10000\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4189 - accuracy: 0.7982\n",
            "Epoch 3906/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4088 - accuracy: 0.8047\n",
            "Epoch 3907/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4053 - accuracy: 0.8073\n",
            "Epoch 3908/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4107 - accuracy: 0.8138\n",
            "Epoch 3909/10000\n",
            "768/768 [==============================] - 0s 122us/step - loss: 0.4028 - accuracy: 0.8125\n",
            "Epoch 3910/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4116 - accuracy: 0.8021\n",
            "Epoch 3911/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4162 - accuracy: 0.8099\n",
            "Epoch 3912/10000\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.4072 - accuracy: 0.8034\n",
            "Epoch 3913/10000\n",
            "768/768 [==============================] - 0s 122us/step - loss: 0.4201 - accuracy: 0.7995\n",
            "Epoch 3914/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4210 - accuracy: 0.8086\n",
            "Epoch 3915/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4139 - accuracy: 0.8008\n",
            "Epoch 3916/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4081 - accuracy: 0.8047\n",
            "Epoch 3917/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4190 - accuracy: 0.7982\n",
            "Epoch 3918/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4125 - accuracy: 0.8060\n",
            "Epoch 3919/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4157 - accuracy: 0.8060\n",
            "Epoch 3920/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4052 - accuracy: 0.8008\n",
            "Epoch 3921/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4053 - accuracy: 0.8099\n",
            "Epoch 3922/10000\n",
            "768/768 [==============================] - 0s 120us/step - loss: 0.4085 - accuracy: 0.8112\n",
            "Epoch 3923/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4082 - accuracy: 0.8047\n",
            "Epoch 3924/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4138 - accuracy: 0.8073\n",
            "Epoch 3925/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4119 - accuracy: 0.7969\n",
            "Epoch 3926/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4127 - accuracy: 0.8021\n",
            "Epoch 3927/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4093 - accuracy: 0.8112\n",
            "Epoch 3928/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4138 - accuracy: 0.7969\n",
            "Epoch 3929/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4105 - accuracy: 0.8021\n",
            "Epoch 3930/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4125 - accuracy: 0.8047\n",
            "Epoch 3931/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4035 - accuracy: 0.7969\n",
            "Epoch 3932/10000\n",
            "768/768 [==============================] - 0s 120us/step - loss: 0.4165 - accuracy: 0.8086\n",
            "Epoch 3933/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4093 - accuracy: 0.8073\n",
            "Epoch 3934/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4120 - accuracy: 0.7982\n",
            "Epoch 3935/10000\n",
            "768/768 [==============================] - 0s 144us/step - loss: 0.4039 - accuracy: 0.8047\n",
            "Epoch 3936/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4066 - accuracy: 0.8138\n",
            "Epoch 3937/10000\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4086 - accuracy: 0.8151\n",
            "Epoch 3938/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4110 - accuracy: 0.8034\n",
            "Epoch 3939/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4074 - accuracy: 0.8112\n",
            "Epoch 3940/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4064 - accuracy: 0.8086\n",
            "Epoch 3941/10000\n",
            "768/768 [==============================] - 0s 110us/step - loss: 0.4120 - accuracy: 0.8047\n",
            "Epoch 3942/10000\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4095 - accuracy: 0.8034\n",
            "Epoch 3943/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4110 - accuracy: 0.8086\n",
            "Epoch 3944/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4059 - accuracy: 0.8099\n",
            "Epoch 3945/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4080 - accuracy: 0.7917\n",
            "Epoch 3946/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4066 - accuracy: 0.8099\n",
            "Epoch 3947/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4116 - accuracy: 0.8047\n",
            "Epoch 3948/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4073 - accuracy: 0.8047\n",
            "Epoch 3949/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4059 - accuracy: 0.8086\n",
            "Epoch 3950/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4002 - accuracy: 0.8112\n",
            "Epoch 3951/10000\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.4060 - accuracy: 0.8008\n",
            "Epoch 3952/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4067 - accuracy: 0.8034\n",
            "Epoch 3953/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4138 - accuracy: 0.8073\n",
            "Epoch 3954/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4079 - accuracy: 0.7956\n",
            "Epoch 3955/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4123 - accuracy: 0.7969\n",
            "Epoch 3956/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4117 - accuracy: 0.8073\n",
            "Epoch 3957/10000\n",
            "768/768 [==============================] - 0s 123us/step - loss: 0.4124 - accuracy: 0.7995\n",
            "Epoch 3958/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4195 - accuracy: 0.7982\n",
            "Epoch 3959/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4161 - accuracy: 0.8099\n",
            "Epoch 3960/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4109 - accuracy: 0.8047\n",
            "Epoch 3961/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4165 - accuracy: 0.8034\n",
            "Epoch 3962/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4063 - accuracy: 0.8099\n",
            "Epoch 3963/10000\n",
            "768/768 [==============================] - 0s 122us/step - loss: 0.4099 - accuracy: 0.8047\n",
            "Epoch 3964/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4065 - accuracy: 0.8073\n",
            "Epoch 3965/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4156 - accuracy: 0.8008\n",
            "Epoch 3966/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4188 - accuracy: 0.7969\n",
            "Epoch 3967/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4073 - accuracy: 0.8190\n",
            "Epoch 3968/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4066 - accuracy: 0.8060\n",
            "Epoch 3969/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4086 - accuracy: 0.7969\n",
            "Epoch 3970/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4113 - accuracy: 0.8034\n",
            "Epoch 3971/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4084 - accuracy: 0.8112\n",
            "Epoch 3972/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4168 - accuracy: 0.7982\n",
            "Epoch 3973/10000\n",
            "768/768 [==============================] - 0s 120us/step - loss: 0.4151 - accuracy: 0.8060\n",
            "Epoch 3974/10000\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4073 - accuracy: 0.8112\n",
            "Epoch 3975/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4038 - accuracy: 0.8164\n",
            "Epoch 3976/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4042 - accuracy: 0.8177\n",
            "Epoch 3977/10000\n",
            "768/768 [==============================] - 0s 110us/step - loss: 0.4056 - accuracy: 0.8112\n",
            "Epoch 3978/10000\n",
            "768/768 [==============================] - 0s 120us/step - loss: 0.4181 - accuracy: 0.7995\n",
            "Epoch 3979/10000\n",
            "768/768 [==============================] - 0s 120us/step - loss: 0.4062 - accuracy: 0.8216\n",
            "Epoch 3980/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4074 - accuracy: 0.7995\n",
            "Epoch 3981/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4178 - accuracy: 0.7969\n",
            "Epoch 3982/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4149 - accuracy: 0.8112\n",
            "Epoch 3983/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4131 - accuracy: 0.8047\n",
            "Epoch 3984/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4268 - accuracy: 0.7969\n",
            "Epoch 3985/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4020 - accuracy: 0.8099\n",
            "Epoch 3986/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4127 - accuracy: 0.7969\n",
            "Epoch 3987/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4188 - accuracy: 0.7930\n",
            "Epoch 3988/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4133 - accuracy: 0.7995\n",
            "Epoch 3989/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4067 - accuracy: 0.8125\n",
            "Epoch 3990/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4078 - accuracy: 0.8099\n",
            "Epoch 3991/10000\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.4049 - accuracy: 0.8125\n",
            "Epoch 3992/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4076 - accuracy: 0.8073\n",
            "Epoch 3993/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4062 - accuracy: 0.8047\n",
            "Epoch 3994/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4105 - accuracy: 0.8086\n",
            "Epoch 3995/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4149 - accuracy: 0.7982\n",
            "Epoch 3996/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4084 - accuracy: 0.8034\n",
            "Epoch 3997/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4191 - accuracy: 0.7995\n",
            "Epoch 3998/10000\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4127 - accuracy: 0.8021\n",
            "Epoch 3999/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4068 - accuracy: 0.8034\n",
            "Epoch 4000/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4044 - accuracy: 0.8034\n",
            "Epoch 4001/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4391 - accuracy: 0.7904\n",
            "Epoch 4002/10000\n",
            "768/768 [==============================] - 0s 126us/step - loss: 0.4063 - accuracy: 0.8086\n",
            "Epoch 4003/10000\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.4072 - accuracy: 0.8060\n",
            "Epoch 4004/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4111 - accuracy: 0.8099\n",
            "Epoch 4005/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4040 - accuracy: 0.8034\n",
            "Epoch 4006/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4186 - accuracy: 0.8073\n",
            "Epoch 4007/10000\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4032 - accuracy: 0.8021\n",
            "Epoch 4008/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4005 - accuracy: 0.8164\n",
            "Epoch 4009/10000\n",
            "768/768 [==============================] - 0s 109us/step - loss: 0.4092 - accuracy: 0.8034\n",
            "Epoch 4010/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4143 - accuracy: 0.7969\n",
            "Epoch 4011/10000\n",
            "768/768 [==============================] - 0s 120us/step - loss: 0.4159 - accuracy: 0.8034\n",
            "Epoch 4012/10000\n",
            "768/768 [==============================] - 0s 120us/step - loss: 0.4247 - accuracy: 0.8034\n",
            "Epoch 4013/10000\n",
            "768/768 [==============================] - 0s 120us/step - loss: 0.4034 - accuracy: 0.8021\n",
            "Epoch 4014/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4069 - accuracy: 0.8073\n",
            "Epoch 4015/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4064 - accuracy: 0.8112\n",
            "Epoch 4016/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4204 - accuracy: 0.7891\n",
            "Epoch 4017/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4094 - accuracy: 0.8008\n",
            "Epoch 4018/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4077 - accuracy: 0.8047\n",
            "Epoch 4019/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4081 - accuracy: 0.8021\n",
            "Epoch 4020/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4065 - accuracy: 0.8047\n",
            "Epoch 4021/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4145 - accuracy: 0.8099\n",
            "Epoch 4022/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4070 - accuracy: 0.7943\n",
            "Epoch 4023/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4128 - accuracy: 0.8086\n",
            "Epoch 4024/10000\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4103 - accuracy: 0.8034\n",
            "Epoch 4025/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4159 - accuracy: 0.8060\n",
            "Epoch 4026/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4098 - accuracy: 0.8099\n",
            "Epoch 4027/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.3995 - accuracy: 0.8125\n",
            "Epoch 4028/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4034 - accuracy: 0.8086\n",
            "Epoch 4029/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4052 - accuracy: 0.8151\n",
            "Epoch 4030/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4109 - accuracy: 0.8073\n",
            "Epoch 4031/10000\n",
            "768/768 [==============================] - 0s 125us/step - loss: 0.4172 - accuracy: 0.7995\n",
            "Epoch 4032/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4080 - accuracy: 0.8086\n",
            "Epoch 4033/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4132 - accuracy: 0.8112\n",
            "Epoch 4034/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4207 - accuracy: 0.8034\n",
            "Epoch 4035/10000\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4142 - accuracy: 0.7995\n",
            "Epoch 4036/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4060 - accuracy: 0.8138\n",
            "Epoch 4037/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4031 - accuracy: 0.8073\n",
            "Epoch 4038/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4126 - accuracy: 0.8034\n",
            "Epoch 4039/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4108 - accuracy: 0.7969\n",
            "Epoch 4040/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4161 - accuracy: 0.8034\n",
            "Epoch 4041/10000\n",
            "768/768 [==============================] - 0s 120us/step - loss: 0.4156 - accuracy: 0.7982\n",
            "Epoch 4042/10000\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4040 - accuracy: 0.8008\n",
            "Epoch 4043/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4097 - accuracy: 0.8008\n",
            "Epoch 4044/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4019 - accuracy: 0.8047\n",
            "Epoch 4045/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4106 - accuracy: 0.8099\n",
            "Epoch 4046/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4087 - accuracy: 0.8008\n",
            "Epoch 4047/10000\n",
            "768/768 [==============================] - 0s 120us/step - loss: 0.4053 - accuracy: 0.7982\n",
            "Epoch 4048/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4087 - accuracy: 0.8073\n",
            "Epoch 4049/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4122 - accuracy: 0.8021\n",
            "Epoch 4050/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4281 - accuracy: 0.7956\n",
            "Epoch 4051/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4136 - accuracy: 0.7891\n",
            "Epoch 4052/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4073 - accuracy: 0.8190\n",
            "Epoch 4053/10000\n",
            "768/768 [==============================] - 0s 143us/step - loss: 0.4055 - accuracy: 0.8086\n",
            "Epoch 4054/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4140 - accuracy: 0.8112\n",
            "Epoch 4055/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4186 - accuracy: 0.7865\n",
            "Epoch 4056/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4109 - accuracy: 0.8021\n",
            "Epoch 4057/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4170 - accuracy: 0.8112\n",
            "Epoch 4058/10000\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.4032 - accuracy: 0.8047\n",
            "Epoch 4059/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4065 - accuracy: 0.8138\n",
            "Epoch 4060/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4015 - accuracy: 0.8086\n",
            "Epoch 4061/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4125 - accuracy: 0.7982\n",
            "Epoch 4062/10000\n",
            "768/768 [==============================] - 0s 129us/step - loss: 0.4102 - accuracy: 0.7982\n",
            "Epoch 4063/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4084 - accuracy: 0.7930\n",
            "Epoch 4064/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4072 - accuracy: 0.7982\n",
            "Epoch 4065/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4129 - accuracy: 0.8021\n",
            "Epoch 4066/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4090 - accuracy: 0.8021\n",
            "Epoch 4067/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4053 - accuracy: 0.8164\n",
            "Epoch 4068/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4074 - accuracy: 0.8099\n",
            "Epoch 4069/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4018 - accuracy: 0.8112\n",
            "Epoch 4070/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4127 - accuracy: 0.7956\n",
            "Epoch 4071/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4073 - accuracy: 0.8060\n",
            "Epoch 4072/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4056 - accuracy: 0.8086\n",
            "Epoch 4073/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4161 - accuracy: 0.7969\n",
            "Epoch 4074/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4124 - accuracy: 0.8086\n",
            "Epoch 4075/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4035 - accuracy: 0.8060\n",
            "Epoch 4076/10000\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.4067 - accuracy: 0.7969\n",
            "Epoch 4077/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4074 - accuracy: 0.8047\n",
            "Epoch 4078/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4140 - accuracy: 0.8073\n",
            "Epoch 4079/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4050 - accuracy: 0.8151\n",
            "Epoch 4080/10000\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.4137 - accuracy: 0.7995\n",
            "Epoch 4081/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4098 - accuracy: 0.8190\n",
            "Epoch 4082/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4222 - accuracy: 0.7956\n",
            "Epoch 4083/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4173 - accuracy: 0.8021\n",
            "Epoch 4084/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4217 - accuracy: 0.8021\n",
            "Epoch 4085/10000\n",
            "768/768 [==============================] - 0s 120us/step - loss: 0.4107 - accuracy: 0.8047\n",
            "Epoch 4086/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4068 - accuracy: 0.8151\n",
            "Epoch 4087/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4053 - accuracy: 0.8125\n",
            "Epoch 4088/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4113 - accuracy: 0.8021\n",
            "Epoch 4089/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4116 - accuracy: 0.8047\n",
            "Epoch 4090/10000\n",
            "768/768 [==============================] - 0s 129us/step - loss: 0.4119 - accuracy: 0.8034\n",
            "Epoch 4091/10000\n",
            "768/768 [==============================] - 0s 122us/step - loss: 0.4138 - accuracy: 0.8047\n",
            "Epoch 4092/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4091 - accuracy: 0.8125\n",
            "Epoch 4093/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4073 - accuracy: 0.7982\n",
            "Epoch 4094/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4082 - accuracy: 0.8021\n",
            "Epoch 4095/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4066 - accuracy: 0.8008\n",
            "Epoch 4096/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4169 - accuracy: 0.8086\n",
            "Epoch 4097/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4177 - accuracy: 0.8021\n",
            "Epoch 4098/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4072 - accuracy: 0.8021\n",
            "Epoch 4099/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4134 - accuracy: 0.7943\n",
            "Epoch 4100/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4174 - accuracy: 0.7982\n",
            "Epoch 4101/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4166 - accuracy: 0.7956\n",
            "Epoch 4102/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4092 - accuracy: 0.7956\n",
            "Epoch 4103/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4021 - accuracy: 0.8125\n",
            "Epoch 4104/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4215 - accuracy: 0.8047\n",
            "Epoch 4105/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4112 - accuracy: 0.8021\n",
            "Epoch 4106/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4130 - accuracy: 0.8021\n",
            "Epoch 4107/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4060 - accuracy: 0.8060\n",
            "Epoch 4108/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4044 - accuracy: 0.8112\n",
            "Epoch 4109/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4036 - accuracy: 0.8112\n",
            "Epoch 4110/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4163 - accuracy: 0.8021\n",
            "Epoch 4111/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4151 - accuracy: 0.7995\n",
            "Epoch 4112/10000\n",
            "768/768 [==============================] - 0s 110us/step - loss: 0.4050 - accuracy: 0.8099\n",
            "Epoch 4113/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4240 - accuracy: 0.7878\n",
            "Epoch 4114/10000\n",
            "768/768 [==============================] - 0s 133us/step - loss: 0.4104 - accuracy: 0.8112\n",
            "Epoch 4115/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4082 - accuracy: 0.8060\n",
            "Epoch 4116/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4046 - accuracy: 0.8099\n",
            "Epoch 4117/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4107 - accuracy: 0.8034\n",
            "Epoch 4118/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4060 - accuracy: 0.8034\n",
            "Epoch 4119/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4071 - accuracy: 0.8021\n",
            "Epoch 4120/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4059 - accuracy: 0.8125\n",
            "Epoch 4121/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4094 - accuracy: 0.7982\n",
            "Epoch 4122/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4107 - accuracy: 0.8060\n",
            "Epoch 4123/10000\n",
            "768/768 [==============================] - 0s 122us/step - loss: 0.4064 - accuracy: 0.7969\n",
            "Epoch 4124/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4203 - accuracy: 0.7969\n",
            "Epoch 4125/10000\n",
            "768/768 [==============================] - 0s 120us/step - loss: 0.4136 - accuracy: 0.8086\n",
            "Epoch 4126/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4035 - accuracy: 0.8138\n",
            "Epoch 4127/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4191 - accuracy: 0.8099\n",
            "Epoch 4128/10000\n",
            "768/768 [==============================] - 0s 127us/step - loss: 0.4104 - accuracy: 0.8047\n",
            "Epoch 4129/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4080 - accuracy: 0.7982\n",
            "Epoch 4130/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4055 - accuracy: 0.8138\n",
            "Epoch 4131/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4136 - accuracy: 0.7995\n",
            "Epoch 4132/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4045 - accuracy: 0.8099\n",
            "Epoch 4133/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4032 - accuracy: 0.7982\n",
            "Epoch 4134/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4033 - accuracy: 0.7995\n",
            "Epoch 4135/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4131 - accuracy: 0.8047\n",
            "Epoch 4136/10000\n",
            "768/768 [==============================] - 0s 138us/step - loss: 0.4052 - accuracy: 0.8034\n",
            "Epoch 4137/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4086 - accuracy: 0.8112\n",
            "Epoch 4138/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4078 - accuracy: 0.8086\n",
            "Epoch 4139/10000\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4104 - accuracy: 0.8021\n",
            "Epoch 4140/10000\n",
            "768/768 [==============================] - 0s 122us/step - loss: 0.4087 - accuracy: 0.8047\n",
            "Epoch 4141/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4104 - accuracy: 0.8086\n",
            "Epoch 4142/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4059 - accuracy: 0.8151\n",
            "Epoch 4143/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4053 - accuracy: 0.8047\n",
            "Epoch 4144/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4109 - accuracy: 0.7878\n",
            "Epoch 4145/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4109 - accuracy: 0.7943\n",
            "Epoch 4146/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4167 - accuracy: 0.7956\n",
            "Epoch 4147/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4063 - accuracy: 0.8060\n",
            "Epoch 4148/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4107 - accuracy: 0.8073\n",
            "Epoch 4149/10000\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.4133 - accuracy: 0.7995\n",
            "Epoch 4150/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4101 - accuracy: 0.8034\n",
            "Epoch 4151/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4045 - accuracy: 0.7969\n",
            "Epoch 4152/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4153 - accuracy: 0.8021\n",
            "Epoch 4153/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4141 - accuracy: 0.7943\n",
            "Epoch 4154/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4127 - accuracy: 0.7956\n",
            "Epoch 4155/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4104 - accuracy: 0.8047\n",
            "Epoch 4156/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4027 - accuracy: 0.8164\n",
            "Epoch 4157/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4015 - accuracy: 0.7995\n",
            "Epoch 4158/10000\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.4168 - accuracy: 0.7852\n",
            "Epoch 4159/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4142 - accuracy: 0.8008\n",
            "Epoch 4160/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4056 - accuracy: 0.7943\n",
            "Epoch 4161/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4061 - accuracy: 0.8047\n",
            "Epoch 4162/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4124 - accuracy: 0.7995\n",
            "Epoch 4163/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4046 - accuracy: 0.8112\n",
            "Epoch 4164/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4052 - accuracy: 0.8151\n",
            "Epoch 4165/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4159 - accuracy: 0.8034\n",
            "Epoch 4166/10000\n",
            "768/768 [==============================] - 0s 126us/step - loss: 0.4129 - accuracy: 0.8021\n",
            "Epoch 4167/10000\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.4093 - accuracy: 0.8047\n",
            "Epoch 4168/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4208 - accuracy: 0.8047\n",
            "Epoch 4169/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4094 - accuracy: 0.8021\n",
            "Epoch 4170/10000\n",
            "768/768 [==============================] - 0s 142us/step - loss: 0.4104 - accuracy: 0.8021\n",
            "Epoch 4171/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4076 - accuracy: 0.8073\n",
            "Epoch 4172/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4141 - accuracy: 0.8138\n",
            "Epoch 4173/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4048 - accuracy: 0.8099\n",
            "Epoch 4174/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4105 - accuracy: 0.8021\n",
            "Epoch 4175/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4045 - accuracy: 0.8151\n",
            "Epoch 4176/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4019 - accuracy: 0.8060\n",
            "Epoch 4177/10000\n",
            "768/768 [==============================] - 0s 124us/step - loss: 0.4117 - accuracy: 0.8099\n",
            "Epoch 4178/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4091 - accuracy: 0.7995\n",
            "Epoch 4179/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4155 - accuracy: 0.8021\n",
            "Epoch 4180/10000\n",
            "768/768 [==============================] - 0s 110us/step - loss: 0.4101 - accuracy: 0.8047\n",
            "Epoch 4181/10000\n",
            "768/768 [==============================] - 0s 129us/step - loss: 0.4186 - accuracy: 0.7943\n",
            "Epoch 4182/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4113 - accuracy: 0.7956\n",
            "Epoch 4183/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4111 - accuracy: 0.7995\n",
            "Epoch 4184/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4125 - accuracy: 0.8047\n",
            "Epoch 4185/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4069 - accuracy: 0.8112\n",
            "Epoch 4186/10000\n",
            "768/768 [==============================] - 0s 124us/step - loss: 0.4141 - accuracy: 0.7982\n",
            "Epoch 4187/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4296 - accuracy: 0.7969\n",
            "Epoch 4188/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4127 - accuracy: 0.8086\n",
            "Epoch 4189/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4126 - accuracy: 0.8125\n",
            "Epoch 4190/10000\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4100 - accuracy: 0.8086\n",
            "Epoch 4191/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4162 - accuracy: 0.8034\n",
            "Epoch 4192/10000\n",
            "768/768 [==============================] - 0s 134us/step - loss: 0.4131 - accuracy: 0.8073\n",
            "Epoch 4193/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4035 - accuracy: 0.8060\n",
            "Epoch 4194/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4095 - accuracy: 0.8099\n",
            "Epoch 4195/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4086 - accuracy: 0.8034\n",
            "Epoch 4196/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4084 - accuracy: 0.8034\n",
            "Epoch 4197/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4203 - accuracy: 0.7904\n",
            "Epoch 4198/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4066 - accuracy: 0.8086\n",
            "Epoch 4199/10000\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.4070 - accuracy: 0.8047\n",
            "Epoch 4200/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4174 - accuracy: 0.8047\n",
            "Epoch 4201/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4054 - accuracy: 0.8073\n",
            "Epoch 4202/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4109 - accuracy: 0.8034\n",
            "Epoch 4203/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4093 - accuracy: 0.8086\n",
            "Epoch 4204/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4124 - accuracy: 0.8086\n",
            "Epoch 4205/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4010 - accuracy: 0.8125\n",
            "Epoch 4206/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4075 - accuracy: 0.7995\n",
            "Epoch 4207/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4075 - accuracy: 0.8047\n",
            "Epoch 4208/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4182 - accuracy: 0.8047\n",
            "Epoch 4209/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4212 - accuracy: 0.8008\n",
            "Epoch 4210/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.3970 - accuracy: 0.8086\n",
            "Epoch 4211/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4075 - accuracy: 0.8008\n",
            "Epoch 4212/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4095 - accuracy: 0.7982\n",
            "Epoch 4213/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4087 - accuracy: 0.7982\n",
            "Epoch 4214/10000\n",
            "768/768 [==============================] - 0s 129us/step - loss: 0.4097 - accuracy: 0.8060\n",
            "Epoch 4215/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4094 - accuracy: 0.8112\n",
            "Epoch 4216/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4099 - accuracy: 0.8151\n",
            "Epoch 4217/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4143 - accuracy: 0.8034\n",
            "Epoch 4218/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4111 - accuracy: 0.8073\n",
            "Epoch 4219/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4125 - accuracy: 0.7982\n",
            "Epoch 4220/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4048 - accuracy: 0.8125\n",
            "Epoch 4221/10000\n",
            "768/768 [==============================] - 0s 110us/step - loss: 0.4051 - accuracy: 0.8138\n",
            "Epoch 4222/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4141 - accuracy: 0.8112\n",
            "Epoch 4223/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4107 - accuracy: 0.8073\n",
            "Epoch 4224/10000\n",
            "768/768 [==============================] - 0s 123us/step - loss: 0.4218 - accuracy: 0.8073\n",
            "Epoch 4225/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4084 - accuracy: 0.8086\n",
            "Epoch 4226/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4117 - accuracy: 0.8008\n",
            "Epoch 4227/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4077 - accuracy: 0.8112\n",
            "Epoch 4228/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4152 - accuracy: 0.7969\n",
            "Epoch 4229/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4050 - accuracy: 0.8086\n",
            "Epoch 4230/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4079 - accuracy: 0.8099\n",
            "Epoch 4231/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4064 - accuracy: 0.8060\n",
            "Epoch 4232/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4112 - accuracy: 0.8099\n",
            "Epoch 4233/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4033 - accuracy: 0.8047\n",
            "Epoch 4234/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4059 - accuracy: 0.8047\n",
            "Epoch 4235/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4111 - accuracy: 0.8138\n",
            "Epoch 4236/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4058 - accuracy: 0.7956\n",
            "Epoch 4237/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4113 - accuracy: 0.8112\n",
            "Epoch 4238/10000\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.4172 - accuracy: 0.8008\n",
            "Epoch 4239/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4129 - accuracy: 0.8047\n",
            "Epoch 4240/10000\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4093 - accuracy: 0.7982\n",
            "Epoch 4241/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4009 - accuracy: 0.8047\n",
            "Epoch 4242/10000\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.4088 - accuracy: 0.8060\n",
            "Epoch 4243/10000\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.4241 - accuracy: 0.7878\n",
            "Epoch 4244/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4145 - accuracy: 0.8047\n",
            "Epoch 4245/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4049 - accuracy: 0.8060\n",
            "Epoch 4246/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4134 - accuracy: 0.8021\n",
            "Epoch 4247/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4138 - accuracy: 0.8086\n",
            "Epoch 4248/10000\n",
            "768/768 [==============================] - 0s 124us/step - loss: 0.4092 - accuracy: 0.7904\n",
            "Epoch 4249/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4079 - accuracy: 0.7995\n",
            "Epoch 4250/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4176 - accuracy: 0.7969\n",
            "Epoch 4251/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4056 - accuracy: 0.8060\n",
            "Epoch 4252/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4059 - accuracy: 0.8047\n",
            "Epoch 4253/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4060 - accuracy: 0.8034\n",
            "Epoch 4254/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4099 - accuracy: 0.8125\n",
            "Epoch 4255/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4059 - accuracy: 0.7995\n",
            "Epoch 4256/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4031 - accuracy: 0.8021\n",
            "Epoch 4257/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4079 - accuracy: 0.8112\n",
            "Epoch 4258/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4077 - accuracy: 0.8021\n",
            "Epoch 4259/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4053 - accuracy: 0.8112\n",
            "Epoch 4260/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4065 - accuracy: 0.8112\n",
            "Epoch 4261/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4076 - accuracy: 0.8073\n",
            "Epoch 4262/10000\n",
            "768/768 [==============================] - 0s 120us/step - loss: 0.4168 - accuracy: 0.8073\n",
            "Epoch 4263/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4092 - accuracy: 0.8099\n",
            "Epoch 4264/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4068 - accuracy: 0.7982\n",
            "Epoch 4265/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4142 - accuracy: 0.7995\n",
            "Epoch 4266/10000\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4149 - accuracy: 0.8073\n",
            "Epoch 4267/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4092 - accuracy: 0.8021\n",
            "Epoch 4268/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4109 - accuracy: 0.8047\n",
            "Epoch 4269/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4077 - accuracy: 0.7995\n",
            "Epoch 4270/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4097 - accuracy: 0.8021\n",
            "Epoch 4271/10000\n",
            "768/768 [==============================] - 0s 128us/step - loss: 0.4066 - accuracy: 0.8060\n",
            "Epoch 4272/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4064 - accuracy: 0.8073\n",
            "Epoch 4273/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4106 - accuracy: 0.8112\n",
            "Epoch 4274/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4078 - accuracy: 0.8112\n",
            "Epoch 4275/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4100 - accuracy: 0.8073\n",
            "Epoch 4276/10000\n",
            "768/768 [==============================] - 0s 124us/step - loss: 0.4084 - accuracy: 0.8008\n",
            "Epoch 4277/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4218 - accuracy: 0.7943\n",
            "Epoch 4278/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4134 - accuracy: 0.7878\n",
            "Epoch 4279/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4147 - accuracy: 0.8021\n",
            "Epoch 4280/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4104 - accuracy: 0.8008\n",
            "Epoch 4281/10000\n",
            "768/768 [==============================] - 0s 124us/step - loss: 0.4098 - accuracy: 0.8073\n",
            "Epoch 4282/10000\n",
            "768/768 [==============================] - 0s 122us/step - loss: 0.4159 - accuracy: 0.8047\n",
            "Epoch 4283/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.3998 - accuracy: 0.8047\n",
            "Epoch 4284/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4123 - accuracy: 0.8047\n",
            "Epoch 4285/10000\n",
            "768/768 [==============================] - 0s 123us/step - loss: 0.4132 - accuracy: 0.8047\n",
            "Epoch 4286/10000\n",
            "768/768 [==============================] - 0s 122us/step - loss: 0.4220 - accuracy: 0.8034\n",
            "Epoch 4287/10000\n",
            "768/768 [==============================] - 0s 110us/step - loss: 0.4128 - accuracy: 0.8073\n",
            "Epoch 4288/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4145 - accuracy: 0.8086\n",
            "Epoch 4289/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4186 - accuracy: 0.8008\n",
            "Epoch 4290/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4173 - accuracy: 0.7995\n",
            "Epoch 4291/10000\n",
            "768/768 [==============================] - 0s 110us/step - loss: 0.4020 - accuracy: 0.8047\n",
            "Epoch 4292/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4092 - accuracy: 0.8008\n",
            "Epoch 4293/10000\n",
            "768/768 [==============================] - 0s 126us/step - loss: 0.4120 - accuracy: 0.7982\n",
            "Epoch 4294/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4186 - accuracy: 0.8060\n",
            "Epoch 4295/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4053 - accuracy: 0.8073\n",
            "Epoch 4296/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4085 - accuracy: 0.8034\n",
            "Epoch 4297/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4075 - accuracy: 0.8047\n",
            "Epoch 4298/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4026 - accuracy: 0.8034\n",
            "Epoch 4299/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4122 - accuracy: 0.8112\n",
            "Epoch 4300/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4068 - accuracy: 0.7995\n",
            "Epoch 4301/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4050 - accuracy: 0.8047\n",
            "Epoch 4302/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4116 - accuracy: 0.8086\n",
            "Epoch 4303/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4040 - accuracy: 0.8008\n",
            "Epoch 4304/10000\n",
            "768/768 [==============================] - 0s 126us/step - loss: 0.4072 - accuracy: 0.7943\n",
            "Epoch 4305/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4185 - accuracy: 0.7891\n",
            "Epoch 4306/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4144 - accuracy: 0.7995\n",
            "Epoch 4307/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4026 - accuracy: 0.8151\n",
            "Epoch 4308/10000\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.4018 - accuracy: 0.8216\n",
            "Epoch 4309/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4126 - accuracy: 0.8086\n",
            "Epoch 4310/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4104 - accuracy: 0.7969\n",
            "Epoch 4311/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4170 - accuracy: 0.8047\n",
            "Epoch 4312/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4250 - accuracy: 0.7995\n",
            "Epoch 4313/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4112 - accuracy: 0.7943\n",
            "Epoch 4314/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4084 - accuracy: 0.8021\n",
            "Epoch 4315/10000\n",
            "768/768 [==============================] - 0s 124us/step - loss: 0.4155 - accuracy: 0.7904\n",
            "Epoch 4316/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4088 - accuracy: 0.8021\n",
            "Epoch 4317/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4035 - accuracy: 0.8073\n",
            "Epoch 4318/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4040 - accuracy: 0.8008\n",
            "Epoch 4319/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4031 - accuracy: 0.8060\n",
            "Epoch 4320/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4093 - accuracy: 0.8034\n",
            "Epoch 4321/10000\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4052 - accuracy: 0.8151\n",
            "Epoch 4322/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4050 - accuracy: 0.8177\n",
            "Epoch 4323/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4192 - accuracy: 0.7969\n",
            "Epoch 4324/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4118 - accuracy: 0.8008\n",
            "Epoch 4325/10000\n",
            "768/768 [==============================] - 0s 127us/step - loss: 0.4136 - accuracy: 0.8125\n",
            "Epoch 4326/10000\n",
            "768/768 [==============================] - 0s 131us/step - loss: 0.4139 - accuracy: 0.7904\n",
            "Epoch 4327/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4050 - accuracy: 0.8099\n",
            "Epoch 4328/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4114 - accuracy: 0.8086\n",
            "Epoch 4329/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4003 - accuracy: 0.8073\n",
            "Epoch 4330/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4086 - accuracy: 0.8034\n",
            "Epoch 4331/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4193 - accuracy: 0.7995\n",
            "Epoch 4332/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4114 - accuracy: 0.7878\n",
            "Epoch 4333/10000\n",
            "768/768 [==============================] - 0s 127us/step - loss: 0.4077 - accuracy: 0.8034\n",
            "Epoch 4334/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4013 - accuracy: 0.8034\n",
            "Epoch 4335/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4059 - accuracy: 0.8060\n",
            "Epoch 4336/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4091 - accuracy: 0.8034\n",
            "Epoch 4337/10000\n",
            "768/768 [==============================] - 0s 124us/step - loss: 0.3993 - accuracy: 0.8099\n",
            "Epoch 4338/10000\n",
            "768/768 [==============================] - 0s 110us/step - loss: 0.4143 - accuracy: 0.8034\n",
            "Epoch 4339/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4173 - accuracy: 0.7969\n",
            "Epoch 4340/10000\n",
            "768/768 [==============================] - 0s 110us/step - loss: 0.4081 - accuracy: 0.8125\n",
            "Epoch 4341/10000\n",
            "768/768 [==============================] - 0s 120us/step - loss: 0.4115 - accuracy: 0.8125\n",
            "Epoch 4342/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4049 - accuracy: 0.8073\n",
            "Epoch 4343/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4042 - accuracy: 0.7982\n",
            "Epoch 4344/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4101 - accuracy: 0.8073\n",
            "Epoch 4345/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4223 - accuracy: 0.7969\n",
            "Epoch 4346/10000\n",
            "768/768 [==============================] - 0s 122us/step - loss: 0.4033 - accuracy: 0.8060\n",
            "Epoch 4347/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4047 - accuracy: 0.8177\n",
            "Epoch 4348/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4042 - accuracy: 0.7956\n",
            "Epoch 4349/10000\n",
            "768/768 [==============================] - 0s 122us/step - loss: 0.4158 - accuracy: 0.7995\n",
            "Epoch 4350/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4043 - accuracy: 0.8125\n",
            "Epoch 4351/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4114 - accuracy: 0.8099\n",
            "Epoch 4352/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4092 - accuracy: 0.8060\n",
            "Epoch 4353/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4101 - accuracy: 0.8151\n",
            "Epoch 4354/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4151 - accuracy: 0.8073\n",
            "Epoch 4355/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4071 - accuracy: 0.8060\n",
            "Epoch 4356/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4039 - accuracy: 0.8164\n",
            "Epoch 4357/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4210 - accuracy: 0.7930\n",
            "Epoch 4358/10000\n",
            "768/768 [==============================] - 0s 120us/step - loss: 0.4097 - accuracy: 0.8086\n",
            "Epoch 4359/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4090 - accuracy: 0.8138\n",
            "Epoch 4360/10000\n",
            "768/768 [==============================] - 0s 124us/step - loss: 0.4044 - accuracy: 0.8008\n",
            "Epoch 4361/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4024 - accuracy: 0.8112\n",
            "Epoch 4362/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4074 - accuracy: 0.8112\n",
            "Epoch 4363/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4132 - accuracy: 0.8060\n",
            "Epoch 4364/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4131 - accuracy: 0.7995\n",
            "Epoch 4365/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4106 - accuracy: 0.8047\n",
            "Epoch 4366/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4123 - accuracy: 0.7917\n",
            "Epoch 4367/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4075 - accuracy: 0.8073\n",
            "Epoch 4368/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4097 - accuracy: 0.8021\n",
            "Epoch 4369/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4199 - accuracy: 0.7956\n",
            "Epoch 4370/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4153 - accuracy: 0.8008\n",
            "Epoch 4371/10000\n",
            "768/768 [==============================] - 0s 120us/step - loss: 0.4098 - accuracy: 0.8099\n",
            "Epoch 4372/10000\n",
            "768/768 [==============================] - 0s 128us/step - loss: 0.4396 - accuracy: 0.7995\n",
            "Epoch 4373/10000\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4120 - accuracy: 0.7956\n",
            "Epoch 4374/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4079 - accuracy: 0.8073\n",
            "Epoch 4375/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4107 - accuracy: 0.8034\n",
            "Epoch 4376/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4109 - accuracy: 0.7956\n",
            "Epoch 4377/10000\n",
            "768/768 [==============================] - 0s 124us/step - loss: 0.4062 - accuracy: 0.7995\n",
            "Epoch 4378/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4078 - accuracy: 0.8047\n",
            "Epoch 4379/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4075 - accuracy: 0.8021\n",
            "Epoch 4380/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4090 - accuracy: 0.7969\n",
            "Epoch 4381/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4109 - accuracy: 0.7956\n",
            "Epoch 4382/10000\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.4023 - accuracy: 0.8060\n",
            "Epoch 4383/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4120 - accuracy: 0.7995\n",
            "Epoch 4384/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4141 - accuracy: 0.7891\n",
            "Epoch 4385/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4151 - accuracy: 0.7982\n",
            "Epoch 4386/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4082 - accuracy: 0.8125\n",
            "Epoch 4387/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4155 - accuracy: 0.8021\n",
            "Epoch 4388/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.3979 - accuracy: 0.8112\n",
            "Epoch 4389/10000\n",
            "768/768 [==============================] - 0s 127us/step - loss: 0.4098 - accuracy: 0.8086\n",
            "Epoch 4390/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4103 - accuracy: 0.8060\n",
            "Epoch 4391/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4162 - accuracy: 0.7956\n",
            "Epoch 4392/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4164 - accuracy: 0.8086\n",
            "Epoch 4393/10000\n",
            "768/768 [==============================] - 0s 123us/step - loss: 0.4167 - accuracy: 0.7969\n",
            "Epoch 4394/10000\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4040 - accuracy: 0.7995\n",
            "Epoch 4395/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4014 - accuracy: 0.8164\n",
            "Epoch 4396/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4318 - accuracy: 0.8021\n",
            "Epoch 4397/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4119 - accuracy: 0.8099\n",
            "Epoch 4398/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4199 - accuracy: 0.7982\n",
            "Epoch 4399/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4038 - accuracy: 0.8034\n",
            "Epoch 4400/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4066 - accuracy: 0.8073\n",
            "Epoch 4401/10000\n",
            "768/768 [==============================] - 0s 138us/step - loss: 0.4074 - accuracy: 0.8112\n",
            "Epoch 4402/10000\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4055 - accuracy: 0.8034\n",
            "Epoch 4403/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4084 - accuracy: 0.8125\n",
            "Epoch 4404/10000\n",
            "768/768 [==============================] - 0s 122us/step - loss: 0.4160 - accuracy: 0.7930\n",
            "Epoch 4405/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4124 - accuracy: 0.8034\n",
            "Epoch 4406/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4084 - accuracy: 0.8034\n",
            "Epoch 4407/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4046 - accuracy: 0.8073\n",
            "Epoch 4408/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4070 - accuracy: 0.7995\n",
            "Epoch 4409/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4044 - accuracy: 0.8073\n",
            "Epoch 4410/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4057 - accuracy: 0.8021\n",
            "Epoch 4411/10000\n",
            "768/768 [==============================] - 0s 120us/step - loss: 0.4119 - accuracy: 0.8086\n",
            "Epoch 4412/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4094 - accuracy: 0.8099\n",
            "Epoch 4413/10000\n",
            "768/768 [==============================] - 0s 123us/step - loss: 0.4037 - accuracy: 0.8073\n",
            "Epoch 4414/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4121 - accuracy: 0.7943\n",
            "Epoch 4415/10000\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.4162 - accuracy: 0.7969\n",
            "Epoch 4416/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4087 - accuracy: 0.7943\n",
            "Epoch 4417/10000\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.4083 - accuracy: 0.8073\n",
            "Epoch 4418/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4072 - accuracy: 0.7943\n",
            "Epoch 4419/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4173 - accuracy: 0.7930\n",
            "Epoch 4420/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4063 - accuracy: 0.8060\n",
            "Epoch 4421/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4012 - accuracy: 0.8060\n",
            "Epoch 4422/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4178 - accuracy: 0.8073\n",
            "Epoch 4423/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4017 - accuracy: 0.8138\n",
            "Epoch 4424/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4083 - accuracy: 0.7956\n",
            "Epoch 4425/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4007 - accuracy: 0.8073\n",
            "Epoch 4426/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4078 - accuracy: 0.7956\n",
            "Epoch 4427/10000\n",
            "768/768 [==============================] - 0s 132us/step - loss: 0.4149 - accuracy: 0.8060\n",
            "Epoch 4428/10000\n",
            "768/768 [==============================] - 0s 120us/step - loss: 0.4099 - accuracy: 0.8112\n",
            "Epoch 4429/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4032 - accuracy: 0.8099\n",
            "Epoch 4430/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4187 - accuracy: 0.7930\n",
            "Epoch 4431/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4109 - accuracy: 0.7969\n",
            "Epoch 4432/10000\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4077 - accuracy: 0.8034\n",
            "Epoch 4433/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4174 - accuracy: 0.8047\n",
            "Epoch 4434/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4194 - accuracy: 0.7995\n",
            "Epoch 4435/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4185 - accuracy: 0.7956\n",
            "Epoch 4436/10000\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.4047 - accuracy: 0.8021\n",
            "Epoch 4437/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4156 - accuracy: 0.7904\n",
            "Epoch 4438/10000\n",
            "768/768 [==============================] - 0s 120us/step - loss: 0.4137 - accuracy: 0.8034\n",
            "Epoch 4439/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4058 - accuracy: 0.8099\n",
            "Epoch 4440/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4069 - accuracy: 0.8034\n",
            "Epoch 4441/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4090 - accuracy: 0.8125\n",
            "Epoch 4442/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4098 - accuracy: 0.8073\n",
            "Epoch 4443/10000\n",
            "768/768 [==============================] - 0s 120us/step - loss: 0.4207 - accuracy: 0.8021\n",
            "Epoch 4444/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4117 - accuracy: 0.8073\n",
            "Epoch 4445/10000\n",
            "768/768 [==============================] - 0s 110us/step - loss: 0.4019 - accuracy: 0.8112\n",
            "Epoch 4446/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4050 - accuracy: 0.8086\n",
            "Epoch 4447/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4068 - accuracy: 0.7891\n",
            "Epoch 4448/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4108 - accuracy: 0.8034\n",
            "Epoch 4449/10000\n",
            "768/768 [==============================] - 0s 122us/step - loss: 0.3993 - accuracy: 0.8177\n",
            "Epoch 4450/10000\n",
            "768/768 [==============================] - 0s 124us/step - loss: 0.4150 - accuracy: 0.8138\n",
            "Epoch 4451/10000\n",
            "768/768 [==============================] - 0s 129us/step - loss: 0.4171 - accuracy: 0.7891\n",
            "Epoch 4452/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4156 - accuracy: 0.8099\n",
            "Epoch 4453/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4106 - accuracy: 0.7982\n",
            "Epoch 4454/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4083 - accuracy: 0.8060\n",
            "Epoch 4455/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4081 - accuracy: 0.8060\n",
            "Epoch 4456/10000\n",
            "768/768 [==============================] - 0s 110us/step - loss: 0.4140 - accuracy: 0.8008\n",
            "Epoch 4457/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4046 - accuracy: 0.7995\n",
            "Epoch 4458/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4142 - accuracy: 0.7930\n",
            "Epoch 4459/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4005 - accuracy: 0.8047\n",
            "Epoch 4460/10000\n",
            "768/768 [==============================] - 0s 134us/step - loss: 0.4030 - accuracy: 0.7982\n",
            "Epoch 4461/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4075 - accuracy: 0.8073\n",
            "Epoch 4462/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4108 - accuracy: 0.8008\n",
            "Epoch 4463/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4184 - accuracy: 0.8099\n",
            "Epoch 4464/10000\n",
            "768/768 [==============================] - 0s 120us/step - loss: 0.4110 - accuracy: 0.8021\n",
            "Epoch 4465/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4097 - accuracy: 0.8112\n",
            "Epoch 4466/10000\n",
            "768/768 [==============================] - 0s 120us/step - loss: 0.4099 - accuracy: 0.8008\n",
            "Epoch 4467/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4045 - accuracy: 0.8151\n",
            "Epoch 4468/10000\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4109 - accuracy: 0.7995\n",
            "Epoch 4469/10000\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4113 - accuracy: 0.7982\n",
            "Epoch 4470/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4094 - accuracy: 0.8047\n",
            "Epoch 4471/10000\n",
            "768/768 [==============================] - 0s 127us/step - loss: 0.4068 - accuracy: 0.8099\n",
            "Epoch 4472/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4201 - accuracy: 0.7956\n",
            "Epoch 4473/10000\n",
            "768/768 [==============================] - 0s 123us/step - loss: 0.4331 - accuracy: 0.7943\n",
            "Epoch 4474/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4072 - accuracy: 0.8008\n",
            "Epoch 4475/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4128 - accuracy: 0.8099\n",
            "Epoch 4476/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4046 - accuracy: 0.8021\n",
            "Epoch 4477/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4155 - accuracy: 0.7943\n",
            "Epoch 4478/10000\n",
            "768/768 [==============================] - 0s 124us/step - loss: 0.4092 - accuracy: 0.8008\n",
            "Epoch 4479/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4042 - accuracy: 0.8021\n",
            "Epoch 4480/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4061 - accuracy: 0.8112\n",
            "Epoch 4481/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4051 - accuracy: 0.8125\n",
            "Epoch 4482/10000\n",
            "768/768 [==============================] - 0s 124us/step - loss: 0.4082 - accuracy: 0.8099\n",
            "Epoch 4483/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4100 - accuracy: 0.8086\n",
            "Epoch 4484/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4010 - accuracy: 0.8086\n",
            "Epoch 4485/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4121 - accuracy: 0.8073\n",
            "Epoch 4486/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4082 - accuracy: 0.8086\n",
            "Epoch 4487/10000\n",
            "768/768 [==============================] - 0s 123us/step - loss: 0.4076 - accuracy: 0.8112\n",
            "Epoch 4488/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4171 - accuracy: 0.8138\n",
            "Epoch 4489/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4097 - accuracy: 0.8138\n",
            "Epoch 4490/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4095 - accuracy: 0.8008\n",
            "Epoch 4491/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4008 - accuracy: 0.8112\n",
            "Epoch 4492/10000\n",
            "768/768 [==============================] - 0s 123us/step - loss: 0.4075 - accuracy: 0.8073\n",
            "Epoch 4493/10000\n",
            "768/768 [==============================] - 0s 123us/step - loss: 0.4061 - accuracy: 0.8034\n",
            "Epoch 4494/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4078 - accuracy: 0.8099\n",
            "Epoch 4495/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4049 - accuracy: 0.8060\n",
            "Epoch 4496/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4105 - accuracy: 0.8047\n",
            "Epoch 4497/10000\n",
            "768/768 [==============================] - 0s 120us/step - loss: 0.4180 - accuracy: 0.7982\n",
            "Epoch 4498/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4023 - accuracy: 0.8060\n",
            "Epoch 4499/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4165 - accuracy: 0.7943\n",
            "Epoch 4500/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4121 - accuracy: 0.8164\n",
            "Epoch 4501/10000\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4027 - accuracy: 0.8086\n",
            "Epoch 4502/10000\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4186 - accuracy: 0.7943\n",
            "Epoch 4503/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4067 - accuracy: 0.8021\n",
            "Epoch 4504/10000\n",
            "768/768 [==============================] - 0s 126us/step - loss: 0.4077 - accuracy: 0.7969\n",
            "Epoch 4505/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4081 - accuracy: 0.8073\n",
            "Epoch 4506/10000\n",
            "768/768 [==============================] - 0s 123us/step - loss: 0.4115 - accuracy: 0.7982\n",
            "Epoch 4507/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4025 - accuracy: 0.8177\n",
            "Epoch 4508/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4013 - accuracy: 0.8099\n",
            "Epoch 4509/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4050 - accuracy: 0.8112\n",
            "Epoch 4510/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4068 - accuracy: 0.8034\n",
            "Epoch 4511/10000\n",
            "768/768 [==============================] - 0s 120us/step - loss: 0.4180 - accuracy: 0.7969\n",
            "Epoch 4512/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4189 - accuracy: 0.7943\n",
            "Epoch 4513/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4110 - accuracy: 0.8008\n",
            "Epoch 4514/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4413 - accuracy: 0.7982\n",
            "Epoch 4515/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4060 - accuracy: 0.8112\n",
            "Epoch 4516/10000\n",
            "768/768 [==============================] - 0s 122us/step - loss: 0.4159 - accuracy: 0.8034\n",
            "Epoch 4517/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4224 - accuracy: 0.7995\n",
            "Epoch 4518/10000\n",
            "768/768 [==============================] - 0s 134us/step - loss: 0.4042 - accuracy: 0.7995\n",
            "Epoch 4519/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4097 - accuracy: 0.8008\n",
            "Epoch 4520/10000\n",
            "768/768 [==============================] - 0s 123us/step - loss: 0.4136 - accuracy: 0.7943\n",
            "Epoch 4521/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4037 - accuracy: 0.8125\n",
            "Epoch 4522/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4105 - accuracy: 0.8047\n",
            "Epoch 4523/10000\n",
            "768/768 [==============================] - 0s 122us/step - loss: 0.4205 - accuracy: 0.7969\n",
            "Epoch 4524/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4086 - accuracy: 0.8047\n",
            "Epoch 4525/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4088 - accuracy: 0.8099\n",
            "Epoch 4526/10000\n",
            "768/768 [==============================] - 0s 129us/step - loss: 0.4098 - accuracy: 0.8021\n",
            "Epoch 4527/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4225 - accuracy: 0.7943\n",
            "Epoch 4528/10000\n",
            "768/768 [==============================] - 0s 132us/step - loss: 0.4102 - accuracy: 0.8008\n",
            "Epoch 4529/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4111 - accuracy: 0.8034\n",
            "Epoch 4530/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4053 - accuracy: 0.8177\n",
            "Epoch 4531/10000\n",
            "768/768 [==============================] - 0s 122us/step - loss: 0.4068 - accuracy: 0.8151\n",
            "Epoch 4532/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4080 - accuracy: 0.8047\n",
            "Epoch 4533/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4084 - accuracy: 0.8060\n",
            "Epoch 4534/10000\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4062 - accuracy: 0.7995\n",
            "Epoch 4535/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4151 - accuracy: 0.7969\n",
            "Epoch 4536/10000\n",
            "768/768 [==============================] - 0s 110us/step - loss: 0.4154 - accuracy: 0.8073\n",
            "Epoch 4537/10000\n",
            "768/768 [==============================] - 0s 120us/step - loss: 0.4041 - accuracy: 0.8125\n",
            "Epoch 4538/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4084 - accuracy: 0.8034\n",
            "Epoch 4539/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4004 - accuracy: 0.8047\n",
            "Epoch 4540/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4091 - accuracy: 0.8073\n",
            "Epoch 4541/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4082 - accuracy: 0.8060\n",
            "Epoch 4542/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4060 - accuracy: 0.8034\n",
            "Epoch 4543/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4092 - accuracy: 0.8099\n",
            "Epoch 4544/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4067 - accuracy: 0.8060\n",
            "Epoch 4545/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4030 - accuracy: 0.8073\n",
            "Epoch 4546/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4120 - accuracy: 0.7891\n",
            "Epoch 4547/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4057 - accuracy: 0.7995\n",
            "Epoch 4548/10000\n",
            "768/768 [==============================] - 0s 120us/step - loss: 0.4108 - accuracy: 0.7995\n",
            "Epoch 4549/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4020 - accuracy: 0.8034\n",
            "Epoch 4550/10000\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4146 - accuracy: 0.8047\n",
            "Epoch 4551/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4055 - accuracy: 0.8060\n",
            "Epoch 4552/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4045 - accuracy: 0.8112\n",
            "Epoch 4553/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4045 - accuracy: 0.8034\n",
            "Epoch 4554/10000\n",
            "768/768 [==============================] - 0s 120us/step - loss: 0.4102 - accuracy: 0.8047\n",
            "Epoch 4555/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4148 - accuracy: 0.7917\n",
            "Epoch 4556/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4140 - accuracy: 0.8047\n",
            "Epoch 4557/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4073 - accuracy: 0.8073\n",
            "Epoch 4558/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4067 - accuracy: 0.8112\n",
            "Epoch 4559/10000\n",
            "768/768 [==============================] - 0s 125us/step - loss: 0.4132 - accuracy: 0.7982\n",
            "Epoch 4560/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4134 - accuracy: 0.8021\n",
            "Epoch 4561/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4117 - accuracy: 0.8164\n",
            "Epoch 4562/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4036 - accuracy: 0.8086\n",
            "Epoch 4563/10000\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4085 - accuracy: 0.8021\n",
            "Epoch 4564/10000\n",
            "768/768 [==============================] - 0s 122us/step - loss: 0.4090 - accuracy: 0.8047\n",
            "Epoch 4565/10000\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4190 - accuracy: 0.8125\n",
            "Epoch 4566/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4087 - accuracy: 0.7930\n",
            "Epoch 4567/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4152 - accuracy: 0.8008\n",
            "Epoch 4568/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.3983 - accuracy: 0.8034\n",
            "Epoch 4569/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4089 - accuracy: 0.7969\n",
            "Epoch 4570/10000\n",
            "768/768 [==============================] - 0s 124us/step - loss: 0.4084 - accuracy: 0.8112\n",
            "Epoch 4571/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4057 - accuracy: 0.8008\n",
            "Epoch 4572/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4072 - accuracy: 0.7969\n",
            "Epoch 4573/10000\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4050 - accuracy: 0.8125\n",
            "Epoch 4574/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4183 - accuracy: 0.7917\n",
            "Epoch 4575/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4079 - accuracy: 0.8008\n",
            "Epoch 4576/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4113 - accuracy: 0.8060\n",
            "Epoch 4577/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4087 - accuracy: 0.7969\n",
            "Epoch 4578/10000\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4061 - accuracy: 0.8073\n",
            "Epoch 4579/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4052 - accuracy: 0.8034\n",
            "Epoch 4580/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4100 - accuracy: 0.8099\n",
            "Epoch 4581/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4185 - accuracy: 0.8021\n",
            "Epoch 4582/10000\n",
            "768/768 [==============================] - 0s 122us/step - loss: 0.4117 - accuracy: 0.7969\n",
            "Epoch 4583/10000\n",
            "768/768 [==============================] - 0s 122us/step - loss: 0.4171 - accuracy: 0.8034\n",
            "Epoch 4584/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.3967 - accuracy: 0.8034\n",
            "Epoch 4585/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4113 - accuracy: 0.8021\n",
            "Epoch 4586/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4209 - accuracy: 0.7969\n",
            "Epoch 4587/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4147 - accuracy: 0.8099\n",
            "Epoch 4588/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4077 - accuracy: 0.7995\n",
            "Epoch 4589/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4079 - accuracy: 0.8047\n",
            "Epoch 4590/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4095 - accuracy: 0.7878\n",
            "Epoch 4591/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4091 - accuracy: 0.8060\n",
            "Epoch 4592/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4084 - accuracy: 0.8086\n",
            "Epoch 4593/10000\n",
            "768/768 [==============================] - 0s 122us/step - loss: 0.4199 - accuracy: 0.8008\n",
            "Epoch 4594/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4058 - accuracy: 0.8099\n",
            "Epoch 4595/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4019 - accuracy: 0.8190\n",
            "Epoch 4596/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4022 - accuracy: 0.8164\n",
            "Epoch 4597/10000\n",
            "768/768 [==============================] - 0s 120us/step - loss: 0.4101 - accuracy: 0.8021\n",
            "Epoch 4598/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4108 - accuracy: 0.8021\n",
            "Epoch 4599/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4035 - accuracy: 0.8086\n",
            "Epoch 4600/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4066 - accuracy: 0.8125\n",
            "Epoch 4601/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4019 - accuracy: 0.8099\n",
            "Epoch 4602/10000\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.4039 - accuracy: 0.8190\n",
            "Epoch 4603/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4071 - accuracy: 0.8151\n",
            "Epoch 4604/10000\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.4023 - accuracy: 0.8138\n",
            "Epoch 4605/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4125 - accuracy: 0.7995\n",
            "Epoch 4606/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4136 - accuracy: 0.8021\n",
            "Epoch 4607/10000\n",
            "768/768 [==============================] - 0s 123us/step - loss: 0.4146 - accuracy: 0.7995\n",
            "Epoch 4608/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4053 - accuracy: 0.8086\n",
            "Epoch 4609/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4088 - accuracy: 0.7969\n",
            "Epoch 4610/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4041 - accuracy: 0.8099\n",
            "Epoch 4611/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4173 - accuracy: 0.7995\n",
            "Epoch 4612/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4078 - accuracy: 0.7982\n",
            "Epoch 4613/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4116 - accuracy: 0.8021\n",
            "Epoch 4614/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4033 - accuracy: 0.8047\n",
            "Epoch 4615/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4058 - accuracy: 0.8034\n",
            "Epoch 4616/10000\n",
            "768/768 [==============================] - 0s 127us/step - loss: 0.4140 - accuracy: 0.8099\n",
            "Epoch 4617/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4091 - accuracy: 0.7956\n",
            "Epoch 4618/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4157 - accuracy: 0.7826\n",
            "Epoch 4619/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4047 - accuracy: 0.8138\n",
            "Epoch 4620/10000\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.4111 - accuracy: 0.8034\n",
            "Epoch 4621/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4153 - accuracy: 0.8125\n",
            "Epoch 4622/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4083 - accuracy: 0.8099\n",
            "Epoch 4623/10000\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4038 - accuracy: 0.8034\n",
            "Epoch 4624/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4020 - accuracy: 0.8021\n",
            "Epoch 4625/10000\n",
            "768/768 [==============================] - 0s 120us/step - loss: 0.4141 - accuracy: 0.7956\n",
            "Epoch 4626/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4070 - accuracy: 0.7982\n",
            "Epoch 4627/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4100 - accuracy: 0.8047\n",
            "Epoch 4628/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4141 - accuracy: 0.8086\n",
            "Epoch 4629/10000\n",
            "768/768 [==============================] - 0s 110us/step - loss: 0.4163 - accuracy: 0.7943\n",
            "Epoch 4630/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4223 - accuracy: 0.7982\n",
            "Epoch 4631/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4109 - accuracy: 0.8047\n",
            "Epoch 4632/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4032 - accuracy: 0.7956\n",
            "Epoch 4633/10000\n",
            "768/768 [==============================] - 0s 109us/step - loss: 0.4139 - accuracy: 0.8125\n",
            "Epoch 4634/10000\n",
            "768/768 [==============================] - 0s 130us/step - loss: 0.4084 - accuracy: 0.8060\n",
            "Epoch 4635/10000\n",
            "768/768 [==============================] - 0s 125us/step - loss: 0.4071 - accuracy: 0.8073\n",
            "Epoch 4636/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4072 - accuracy: 0.8086\n",
            "Epoch 4637/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4060 - accuracy: 0.8060\n",
            "Epoch 4638/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4100 - accuracy: 0.8060\n",
            "Epoch 4639/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4055 - accuracy: 0.8138\n",
            "Epoch 4640/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4117 - accuracy: 0.7930\n",
            "Epoch 4641/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4077 - accuracy: 0.8073\n",
            "Epoch 4642/10000\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.4059 - accuracy: 0.8177\n",
            "Epoch 4643/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4137 - accuracy: 0.8047\n",
            "Epoch 4644/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4058 - accuracy: 0.8008\n",
            "Epoch 4645/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4066 - accuracy: 0.8060\n",
            "Epoch 4646/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4058 - accuracy: 0.8034\n",
            "Epoch 4647/10000\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.4079 - accuracy: 0.8034\n",
            "Epoch 4648/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4123 - accuracy: 0.8138\n",
            "Epoch 4649/10000\n",
            "768/768 [==============================] - 0s 120us/step - loss: 0.4067 - accuracy: 0.8086\n",
            "Epoch 4650/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4055 - accuracy: 0.8073\n",
            "Epoch 4651/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4029 - accuracy: 0.8047\n",
            "Epoch 4652/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4061 - accuracy: 0.8034\n",
            "Epoch 4653/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4048 - accuracy: 0.8008\n",
            "Epoch 4654/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4063 - accuracy: 0.8047\n",
            "Epoch 4655/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4158 - accuracy: 0.8008\n",
            "Epoch 4656/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4100 - accuracy: 0.8047\n",
            "Epoch 4657/10000\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.4078 - accuracy: 0.8073\n",
            "Epoch 4658/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4152 - accuracy: 0.7969\n",
            "Epoch 4659/10000\n",
            "768/768 [==============================] - 0s 110us/step - loss: 0.4121 - accuracy: 0.8138\n",
            "Epoch 4660/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4139 - accuracy: 0.7969\n",
            "Epoch 4661/10000\n",
            "768/768 [==============================] - 0s 110us/step - loss: 0.4038 - accuracy: 0.7956\n",
            "Epoch 4662/10000\n",
            "768/768 [==============================] - 0s 120us/step - loss: 0.4098 - accuracy: 0.8021\n",
            "Epoch 4663/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4093 - accuracy: 0.8008\n",
            "Epoch 4664/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4114 - accuracy: 0.7969\n",
            "Epoch 4665/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4143 - accuracy: 0.8008\n",
            "Epoch 4666/10000\n",
            "768/768 [==============================] - 0s 123us/step - loss: 0.4127 - accuracy: 0.8034\n",
            "Epoch 4667/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4043 - accuracy: 0.8099\n",
            "Epoch 4668/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4062 - accuracy: 0.8021\n",
            "Epoch 4669/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4034 - accuracy: 0.8125\n",
            "Epoch 4670/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4153 - accuracy: 0.7904\n",
            "Epoch 4671/10000\n",
            "768/768 [==============================] - 0s 133us/step - loss: 0.4033 - accuracy: 0.8021\n",
            "Epoch 4672/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4039 - accuracy: 0.8086\n",
            "Epoch 4673/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4078 - accuracy: 0.8060\n",
            "Epoch 4674/10000\n",
            "768/768 [==============================] - 0s 110us/step - loss: 0.3985 - accuracy: 0.8086\n",
            "Epoch 4675/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4111 - accuracy: 0.8086\n",
            "Epoch 4676/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4053 - accuracy: 0.8021\n",
            "Epoch 4677/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4042 - accuracy: 0.8060\n",
            "Epoch 4678/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4058 - accuracy: 0.7995\n",
            "Epoch 4679/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4105 - accuracy: 0.8021\n",
            "Epoch 4680/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4092 - accuracy: 0.8060\n",
            "Epoch 4681/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4157 - accuracy: 0.8047\n",
            "Epoch 4682/10000\n",
            "768/768 [==============================] - 0s 125us/step - loss: 0.4271 - accuracy: 0.7956\n",
            "Epoch 4683/10000\n",
            "768/768 [==============================] - 0s 122us/step - loss: 0.4080 - accuracy: 0.8164\n",
            "Epoch 4684/10000\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.4131 - accuracy: 0.8047\n",
            "Epoch 4685/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4127 - accuracy: 0.8060\n",
            "Epoch 4686/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4190 - accuracy: 0.8086\n",
            "Epoch 4687/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4165 - accuracy: 0.8008\n",
            "Epoch 4688/10000\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.4225 - accuracy: 0.8008\n",
            "Epoch 4689/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4084 - accuracy: 0.7956\n",
            "Epoch 4690/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4115 - accuracy: 0.8125\n",
            "Epoch 4691/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4124 - accuracy: 0.8125\n",
            "Epoch 4692/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4128 - accuracy: 0.7956\n",
            "Epoch 4693/10000\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.4086 - accuracy: 0.8047\n",
            "Epoch 4694/10000\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.4124 - accuracy: 0.8047\n",
            "Epoch 4695/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4059 - accuracy: 0.8125\n",
            "Epoch 4696/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4094 - accuracy: 0.8034\n",
            "Epoch 4697/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4033 - accuracy: 0.8112\n",
            "Epoch 4698/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4094 - accuracy: 0.8021\n",
            "Epoch 4699/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4087 - accuracy: 0.8125\n",
            "Epoch 4700/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4155 - accuracy: 0.7982\n",
            "Epoch 4701/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4187 - accuracy: 0.8008\n",
            "Epoch 4702/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4104 - accuracy: 0.8086\n",
            "Epoch 4703/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4120 - accuracy: 0.8047\n",
            "Epoch 4704/10000\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4107 - accuracy: 0.8086\n",
            "Epoch 4705/10000\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4045 - accuracy: 0.8047\n",
            "Epoch 4706/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4085 - accuracy: 0.8086\n",
            "Epoch 4707/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4127 - accuracy: 0.8021\n",
            "Epoch 4708/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4185 - accuracy: 0.7995\n",
            "Epoch 4709/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4047 - accuracy: 0.7969\n",
            "Epoch 4710/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4091 - accuracy: 0.8034\n",
            "Epoch 4711/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4098 - accuracy: 0.8073\n",
            "Epoch 4712/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4084 - accuracy: 0.8047\n",
            "Epoch 4713/10000\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4069 - accuracy: 0.8099\n",
            "Epoch 4714/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4138 - accuracy: 0.8086\n",
            "Epoch 4715/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4046 - accuracy: 0.8086\n",
            "Epoch 4716/10000\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4049 - accuracy: 0.7943\n",
            "Epoch 4717/10000\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4056 - accuracy: 0.8060\n",
            "Epoch 4718/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4057 - accuracy: 0.7995\n",
            "Epoch 4719/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4094 - accuracy: 0.8138\n",
            "Epoch 4720/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4120 - accuracy: 0.8112\n",
            "Epoch 4721/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4076 - accuracy: 0.8047\n",
            "Epoch 4722/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4027 - accuracy: 0.8021\n",
            "Epoch 4723/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4040 - accuracy: 0.8021\n",
            "Epoch 4724/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4079 - accuracy: 0.8073\n",
            "Epoch 4725/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4144 - accuracy: 0.7969\n",
            "Epoch 4726/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4121 - accuracy: 0.7930\n",
            "Epoch 4727/10000\n",
            "768/768 [==============================] - 0s 126us/step - loss: 0.4164 - accuracy: 0.7930\n",
            "Epoch 4728/10000\n",
            "768/768 [==============================] - 0s 110us/step - loss: 0.4083 - accuracy: 0.8086\n",
            "Epoch 4729/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4293 - accuracy: 0.7943\n",
            "Epoch 4730/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4063 - accuracy: 0.8099\n",
            "Epoch 4731/10000\n",
            "768/768 [==============================] - 0s 124us/step - loss: 0.4017 - accuracy: 0.8047\n",
            "Epoch 4732/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4135 - accuracy: 0.8034\n",
            "Epoch 4733/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4200 - accuracy: 0.8021\n",
            "Epoch 4734/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4180 - accuracy: 0.8021\n",
            "Epoch 4735/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4036 - accuracy: 0.8151\n",
            "Epoch 4736/10000\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4057 - accuracy: 0.8060\n",
            "Epoch 4737/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4058 - accuracy: 0.8021\n",
            "Epoch 4738/10000\n",
            "768/768 [==============================] - 0s 124us/step - loss: 0.4057 - accuracy: 0.8151\n",
            "Epoch 4739/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4211 - accuracy: 0.8034\n",
            "Epoch 4740/10000\n",
            "768/768 [==============================] - 0s 122us/step - loss: 0.4050 - accuracy: 0.7982\n",
            "Epoch 4741/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4040 - accuracy: 0.8060\n",
            "Epoch 4742/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4113 - accuracy: 0.7995\n",
            "Epoch 4743/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4013 - accuracy: 0.8112\n",
            "Epoch 4744/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4060 - accuracy: 0.8125\n",
            "Epoch 4745/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4131 - accuracy: 0.7956\n",
            "Epoch 4746/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4132 - accuracy: 0.8073\n",
            "Epoch 4747/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4044 - accuracy: 0.8086\n",
            "Epoch 4748/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4053 - accuracy: 0.8112\n",
            "Epoch 4749/10000\n",
            "768/768 [==============================] - 0s 125us/step - loss: 0.4040 - accuracy: 0.8073\n",
            "Epoch 4750/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4061 - accuracy: 0.8008\n",
            "Epoch 4751/10000\n",
            "768/768 [==============================] - 0s 124us/step - loss: 0.4062 - accuracy: 0.8112\n",
            "Epoch 4752/10000\n",
            "768/768 [==============================] - 0s 128us/step - loss: 0.4127 - accuracy: 0.7995\n",
            "Epoch 4753/10000\n",
            "768/768 [==============================] - 0s 129us/step - loss: 0.4100 - accuracy: 0.8047\n",
            "Epoch 4754/10000\n",
            "768/768 [==============================] - 0s 120us/step - loss: 0.4102 - accuracy: 0.8073\n",
            "Epoch 4755/10000\n",
            "768/768 [==============================] - 0s 120us/step - loss: 0.4107 - accuracy: 0.8021\n",
            "Epoch 4756/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4094 - accuracy: 0.7995\n",
            "Epoch 4757/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4050 - accuracy: 0.8229\n",
            "Epoch 4758/10000\n",
            "768/768 [==============================] - 0s 110us/step - loss: 0.4104 - accuracy: 0.7917\n",
            "Epoch 4759/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4126 - accuracy: 0.7995\n",
            "Epoch 4760/10000\n",
            "768/768 [==============================] - 0s 120us/step - loss: 0.4057 - accuracy: 0.8034\n",
            "Epoch 4761/10000\n",
            "768/768 [==============================] - 0s 120us/step - loss: 0.4095 - accuracy: 0.7982\n",
            "Epoch 4762/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4081 - accuracy: 0.8047\n",
            "Epoch 4763/10000\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4109 - accuracy: 0.8073\n",
            "Epoch 4764/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4051 - accuracy: 0.8112\n",
            "Epoch 4765/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4094 - accuracy: 0.8060\n",
            "Epoch 4766/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4043 - accuracy: 0.8164\n",
            "Epoch 4767/10000\n",
            "768/768 [==============================] - 0s 120us/step - loss: 0.4111 - accuracy: 0.8086\n",
            "Epoch 4768/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4023 - accuracy: 0.8086\n",
            "Epoch 4769/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4026 - accuracy: 0.8086\n",
            "Epoch 4770/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4061 - accuracy: 0.7995\n",
            "Epoch 4771/10000\n",
            "768/768 [==============================] - 0s 110us/step - loss: 0.4107 - accuracy: 0.8073\n",
            "Epoch 4772/10000\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.4133 - accuracy: 0.7956\n",
            "Epoch 4773/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4175 - accuracy: 0.7956\n",
            "Epoch 4774/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4126 - accuracy: 0.8151\n",
            "Epoch 4775/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4127 - accuracy: 0.7956\n",
            "Epoch 4776/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4029 - accuracy: 0.8060\n",
            "Epoch 4777/10000\n",
            "768/768 [==============================] - 0s 128us/step - loss: 0.4063 - accuracy: 0.7995\n",
            "Epoch 4778/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4088 - accuracy: 0.8060\n",
            "Epoch 4779/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4047 - accuracy: 0.8073\n",
            "Epoch 4780/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4052 - accuracy: 0.7956\n",
            "Epoch 4781/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4021 - accuracy: 0.8151\n",
            "Epoch 4782/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4064 - accuracy: 0.8008\n",
            "Epoch 4783/10000\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4100 - accuracy: 0.8008\n",
            "Epoch 4784/10000\n",
            "768/768 [==============================] - 0s 110us/step - loss: 0.4169 - accuracy: 0.8086\n",
            "Epoch 4785/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4207 - accuracy: 0.7904\n",
            "Epoch 4786/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4006 - accuracy: 0.8125\n",
            "Epoch 4787/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4178 - accuracy: 0.7956\n",
            "Epoch 4788/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4121 - accuracy: 0.8099\n",
            "Epoch 4789/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4128 - accuracy: 0.8034\n",
            "Epoch 4790/10000\n",
            "768/768 [==============================] - 0s 127us/step - loss: 0.4143 - accuracy: 0.8034\n",
            "Epoch 4791/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4224 - accuracy: 0.7982\n",
            "Epoch 4792/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4143 - accuracy: 0.8021\n",
            "Epoch 4793/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4133 - accuracy: 0.7969\n",
            "Epoch 4794/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4221 - accuracy: 0.7995\n",
            "Epoch 4795/10000\n",
            "768/768 [==============================] - 0s 122us/step - loss: 0.4114 - accuracy: 0.8060\n",
            "Epoch 4796/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4109 - accuracy: 0.8021\n",
            "Epoch 4797/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4070 - accuracy: 0.8073\n",
            "Epoch 4798/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4096 - accuracy: 0.8073\n",
            "Epoch 4799/10000\n",
            "768/768 [==============================] - 0s 122us/step - loss: 0.4091 - accuracy: 0.8060\n",
            "Epoch 4800/10000\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.4043 - accuracy: 0.8151\n",
            "Epoch 4801/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4054 - accuracy: 0.8086\n",
            "Epoch 4802/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4089 - accuracy: 0.8086\n",
            "Epoch 4803/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4060 - accuracy: 0.8073\n",
            "Epoch 4804/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4068 - accuracy: 0.7995\n",
            "Epoch 4805/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4053 - accuracy: 0.8060\n",
            "Epoch 4806/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4194 - accuracy: 0.8060\n",
            "Epoch 4807/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4076 - accuracy: 0.8151\n",
            "Epoch 4808/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4049 - accuracy: 0.8138\n",
            "Epoch 4809/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4034 - accuracy: 0.8151\n",
            "Epoch 4810/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4118 - accuracy: 0.8008\n",
            "Epoch 4811/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4147 - accuracy: 0.7943\n",
            "Epoch 4812/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4133 - accuracy: 0.7917\n",
            "Epoch 4813/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4085 - accuracy: 0.7995\n",
            "Epoch 4814/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4178 - accuracy: 0.7969\n",
            "Epoch 4815/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4076 - accuracy: 0.8073\n",
            "Epoch 4816/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4099 - accuracy: 0.8164\n",
            "Epoch 4817/10000\n",
            "768/768 [==============================] - 0s 125us/step - loss: 0.4052 - accuracy: 0.8112\n",
            "Epoch 4818/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4068 - accuracy: 0.8099\n",
            "Epoch 4819/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4120 - accuracy: 0.7995\n",
            "Epoch 4820/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4172 - accuracy: 0.7917\n",
            "Epoch 4821/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4052 - accuracy: 0.8034\n",
            "Epoch 4822/10000\n",
            "768/768 [==============================] - 0s 130us/step - loss: 0.4113 - accuracy: 0.8047\n",
            "Epoch 4823/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4081 - accuracy: 0.8099\n",
            "Epoch 4824/10000\n",
            "768/768 [==============================] - 0s 110us/step - loss: 0.4051 - accuracy: 0.8099\n",
            "Epoch 4825/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4182 - accuracy: 0.8112\n",
            "Epoch 4826/10000\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.4016 - accuracy: 0.8047\n",
            "Epoch 4827/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4049 - accuracy: 0.8021\n",
            "Epoch 4828/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4098 - accuracy: 0.8034\n",
            "Epoch 4829/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4073 - accuracy: 0.8073\n",
            "Epoch 4830/10000\n",
            "768/768 [==============================] - 0s 128us/step - loss: 0.4042 - accuracy: 0.7969\n",
            "Epoch 4831/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4096 - accuracy: 0.7969\n",
            "Epoch 4832/10000\n",
            "768/768 [==============================] - 0s 110us/step - loss: 0.4151 - accuracy: 0.8099\n",
            "Epoch 4833/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4056 - accuracy: 0.8047\n",
            "Epoch 4834/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4107 - accuracy: 0.8008\n",
            "Epoch 4835/10000\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.4145 - accuracy: 0.7982\n",
            "Epoch 4836/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4149 - accuracy: 0.7891\n",
            "Epoch 4837/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4083 - accuracy: 0.8047\n",
            "Epoch 4838/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4044 - accuracy: 0.8073\n",
            "Epoch 4839/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4080 - accuracy: 0.8099\n",
            "Epoch 4840/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4081 - accuracy: 0.8060\n",
            "Epoch 4841/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4058 - accuracy: 0.8060\n",
            "Epoch 4842/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4118 - accuracy: 0.8060\n",
            "Epoch 4843/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4073 - accuracy: 0.8021\n",
            "Epoch 4844/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4099 - accuracy: 0.8073\n",
            "Epoch 4845/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4150 - accuracy: 0.8008\n",
            "Epoch 4846/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4136 - accuracy: 0.8047\n",
            "Epoch 4847/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4016 - accuracy: 0.8112\n",
            "Epoch 4848/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4117 - accuracy: 0.8008\n",
            "Epoch 4849/10000\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.4036 - accuracy: 0.8099\n",
            "Epoch 4850/10000\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4106 - accuracy: 0.8060\n",
            "Epoch 4851/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4214 - accuracy: 0.8034\n",
            "Epoch 4852/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4054 - accuracy: 0.8021\n",
            "Epoch 4853/10000\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.4153 - accuracy: 0.8008\n",
            "Epoch 4854/10000\n",
            "768/768 [==============================] - 0s 131us/step - loss: 0.4072 - accuracy: 0.8073\n",
            "Epoch 4855/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4081 - accuracy: 0.8073\n",
            "Epoch 4856/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4173 - accuracy: 0.8008\n",
            "Epoch 4857/10000\n",
            "768/768 [==============================] - 0s 124us/step - loss: 0.4147 - accuracy: 0.7995\n",
            "Epoch 4858/10000\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4155 - accuracy: 0.8112\n",
            "Epoch 4859/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4116 - accuracy: 0.7969\n",
            "Epoch 4860/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4079 - accuracy: 0.8008\n",
            "Epoch 4861/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4154 - accuracy: 0.8060\n",
            "Epoch 4862/10000\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4121 - accuracy: 0.8021\n",
            "Epoch 4863/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4067 - accuracy: 0.8021\n",
            "Epoch 4864/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4044 - accuracy: 0.8060\n",
            "Epoch 4865/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4038 - accuracy: 0.8112\n",
            "Epoch 4866/10000\n",
            "768/768 [==============================] - 0s 133us/step - loss: 0.4016 - accuracy: 0.8151\n",
            "Epoch 4867/10000\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4260 - accuracy: 0.7917\n",
            "Epoch 4868/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4016 - accuracy: 0.8073\n",
            "Epoch 4869/10000\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4071 - accuracy: 0.8008\n",
            "Epoch 4870/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4084 - accuracy: 0.8138\n",
            "Epoch 4871/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4056 - accuracy: 0.8060\n",
            "Epoch 4872/10000\n",
            "768/768 [==============================] - 0s 123us/step - loss: 0.4050 - accuracy: 0.8125\n",
            "Epoch 4873/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4072 - accuracy: 0.8034\n",
            "Epoch 4874/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4232 - accuracy: 0.7982\n",
            "Epoch 4875/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4098 - accuracy: 0.8060\n",
            "Epoch 4876/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4025 - accuracy: 0.8190\n",
            "Epoch 4877/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4297 - accuracy: 0.8086\n",
            "Epoch 4878/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4088 - accuracy: 0.7982\n",
            "Epoch 4879/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4092 - accuracy: 0.8203\n",
            "Epoch 4880/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4059 - accuracy: 0.8099\n",
            "Epoch 4881/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4067 - accuracy: 0.8099\n",
            "Epoch 4882/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4054 - accuracy: 0.8086\n",
            "Epoch 4883/10000\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.4015 - accuracy: 0.8112\n",
            "Epoch 4884/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4223 - accuracy: 0.8008\n",
            "Epoch 4885/10000\n",
            "768/768 [==============================] - 0s 126us/step - loss: 0.4198 - accuracy: 0.8034\n",
            "Epoch 4886/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4080 - accuracy: 0.8008\n",
            "Epoch 4887/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4104 - accuracy: 0.8060\n",
            "Epoch 4888/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4144 - accuracy: 0.8086\n",
            "Epoch 4889/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4094 - accuracy: 0.8073\n",
            "Epoch 4890/10000\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4043 - accuracy: 0.7995\n",
            "Epoch 4891/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4139 - accuracy: 0.7982\n",
            "Epoch 4892/10000\n",
            "768/768 [==============================] - 0s 110us/step - loss: 0.4261 - accuracy: 0.7982\n",
            "Epoch 4893/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4060 - accuracy: 0.8060\n",
            "Epoch 4894/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4043 - accuracy: 0.8177\n",
            "Epoch 4895/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4041 - accuracy: 0.8112\n",
            "Epoch 4896/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4115 - accuracy: 0.8047\n",
            "Epoch 4897/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4026 - accuracy: 0.7995\n",
            "Epoch 4898/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4007 - accuracy: 0.8190\n",
            "Epoch 4899/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4006 - accuracy: 0.8086\n",
            "Epoch 4900/10000\n",
            "768/768 [==============================] - 0s 120us/step - loss: 0.4037 - accuracy: 0.8073\n",
            "Epoch 4901/10000\n",
            "768/768 [==============================] - 0s 110us/step - loss: 0.4016 - accuracy: 0.8021\n",
            "Epoch 4902/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4091 - accuracy: 0.8021\n",
            "Epoch 4903/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4105 - accuracy: 0.7982\n",
            "Epoch 4904/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4054 - accuracy: 0.8021\n",
            "Epoch 4905/10000\n",
            "768/768 [==============================] - 0s 110us/step - loss: 0.4141 - accuracy: 0.8073\n",
            "Epoch 4906/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4193 - accuracy: 0.8021\n",
            "Epoch 4907/10000\n",
            "768/768 [==============================] - 0s 110us/step - loss: 0.4106 - accuracy: 0.8034\n",
            "Epoch 4908/10000\n",
            "768/768 [==============================] - 0s 110us/step - loss: 0.4103 - accuracy: 0.7969\n",
            "Epoch 4909/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4068 - accuracy: 0.8060\n",
            "Epoch 4910/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4132 - accuracy: 0.8047\n",
            "Epoch 4911/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4139 - accuracy: 0.8086\n",
            "Epoch 4912/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4134 - accuracy: 0.8034\n",
            "Epoch 4913/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4039 - accuracy: 0.8164\n",
            "Epoch 4914/10000\n",
            "768/768 [==============================] - 0s 130us/step - loss: 0.4104 - accuracy: 0.8021\n",
            "Epoch 4915/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4068 - accuracy: 0.8021\n",
            "Epoch 4916/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4087 - accuracy: 0.8021\n",
            "Epoch 4917/10000\n",
            "768/768 [==============================] - 0s 122us/step - loss: 0.4055 - accuracy: 0.8112\n",
            "Epoch 4918/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4147 - accuracy: 0.8164\n",
            "Epoch 4919/10000\n",
            "768/768 [==============================] - 0s 123us/step - loss: 0.4205 - accuracy: 0.7956\n",
            "Epoch 4920/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4172 - accuracy: 0.7943\n",
            "Epoch 4921/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4128 - accuracy: 0.8060\n",
            "Epoch 4922/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4063 - accuracy: 0.8034\n",
            "Epoch 4923/10000\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4084 - accuracy: 0.8086\n",
            "Epoch 4924/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4055 - accuracy: 0.8060\n",
            "Epoch 4925/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4015 - accuracy: 0.8073\n",
            "Epoch 4926/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4085 - accuracy: 0.8086\n",
            "Epoch 4927/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4119 - accuracy: 0.7969\n",
            "Epoch 4928/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4102 - accuracy: 0.8060\n",
            "Epoch 4929/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4090 - accuracy: 0.8060\n",
            "Epoch 4930/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4072 - accuracy: 0.8021\n",
            "Epoch 4931/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4026 - accuracy: 0.8151\n",
            "Epoch 4932/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4092 - accuracy: 0.8073\n",
            "Epoch 4933/10000\n",
            "768/768 [==============================] - 0s 126us/step - loss: 0.4132 - accuracy: 0.7930\n",
            "Epoch 4934/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4054 - accuracy: 0.8073\n",
            "Epoch 4935/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4053 - accuracy: 0.8021\n",
            "Epoch 4936/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4124 - accuracy: 0.8008\n",
            "Epoch 4937/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4126 - accuracy: 0.7943\n",
            "Epoch 4938/10000\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4050 - accuracy: 0.8047\n",
            "Epoch 4939/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4060 - accuracy: 0.8112\n",
            "Epoch 4940/10000\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4124 - accuracy: 0.7995\n",
            "Epoch 4941/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4016 - accuracy: 0.8164\n",
            "Epoch 4942/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4105 - accuracy: 0.7982\n",
            "Epoch 4943/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4105 - accuracy: 0.8060\n",
            "Epoch 4944/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4216 - accuracy: 0.8021\n",
            "Epoch 4945/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4039 - accuracy: 0.8047\n",
            "Epoch 4946/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4144 - accuracy: 0.8047\n",
            "Epoch 4947/10000\n",
            "768/768 [==============================] - 0s 122us/step - loss: 0.4046 - accuracy: 0.8099\n",
            "Epoch 4948/10000\n",
            "768/768 [==============================] - 0s 123us/step - loss: 0.4079 - accuracy: 0.8008\n",
            "Epoch 4949/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4097 - accuracy: 0.8060\n",
            "Epoch 4950/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4078 - accuracy: 0.8086\n",
            "Epoch 4951/10000\n",
            "768/768 [==============================] - 0s 120us/step - loss: 0.4016 - accuracy: 0.8021\n",
            "Epoch 4952/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4064 - accuracy: 0.8060\n",
            "Epoch 4953/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4048 - accuracy: 0.8086\n",
            "Epoch 4954/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4154 - accuracy: 0.8060\n",
            "Epoch 4955/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4169 - accuracy: 0.8034\n",
            "Epoch 4956/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4092 - accuracy: 0.8034\n",
            "Epoch 4957/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4179 - accuracy: 0.7969\n",
            "Epoch 4958/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4159 - accuracy: 0.7917\n",
            "Epoch 4959/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4055 - accuracy: 0.8008\n",
            "Epoch 4960/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4073 - accuracy: 0.8034\n",
            "Epoch 4961/10000\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4112 - accuracy: 0.8086\n",
            "Epoch 4962/10000\n",
            "768/768 [==============================] - 0s 124us/step - loss: 0.4008 - accuracy: 0.8177\n",
            "Epoch 4963/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4144 - accuracy: 0.7917\n",
            "Epoch 4964/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4125 - accuracy: 0.8047\n",
            "Epoch 4965/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4128 - accuracy: 0.8047\n",
            "Epoch 4966/10000\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4184 - accuracy: 0.7891\n",
            "Epoch 4967/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4152 - accuracy: 0.7982\n",
            "Epoch 4968/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4102 - accuracy: 0.7982\n",
            "Epoch 4969/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4081 - accuracy: 0.8034\n",
            "Epoch 4970/10000\n",
            "768/768 [==============================] - 0s 125us/step - loss: 0.4068 - accuracy: 0.8086\n",
            "Epoch 4971/10000\n",
            "768/768 [==============================] - 0s 129us/step - loss: 0.4199 - accuracy: 0.7943\n",
            "Epoch 4972/10000\n",
            "768/768 [==============================] - 0s 122us/step - loss: 0.4095 - accuracy: 0.8099\n",
            "Epoch 4973/10000\n",
            "768/768 [==============================] - 0s 123us/step - loss: 0.4153 - accuracy: 0.7995\n",
            "Epoch 4974/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4022 - accuracy: 0.8047\n",
            "Epoch 4975/10000\n",
            "768/768 [==============================] - 0s 122us/step - loss: 0.4078 - accuracy: 0.8060\n",
            "Epoch 4976/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4039 - accuracy: 0.8138\n",
            "Epoch 4977/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.3999 - accuracy: 0.8125\n",
            "Epoch 4978/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4036 - accuracy: 0.7956\n",
            "Epoch 4979/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4031 - accuracy: 0.8099\n",
            "Epoch 4980/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4133 - accuracy: 0.8099\n",
            "Epoch 4981/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4081 - accuracy: 0.8060\n",
            "Epoch 4982/10000\n",
            "768/768 [==============================] - 0s 128us/step - loss: 0.4096 - accuracy: 0.8021\n",
            "Epoch 4983/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4073 - accuracy: 0.8060\n",
            "Epoch 4984/10000\n",
            "768/768 [==============================] - 0s 125us/step - loss: 0.4041 - accuracy: 0.8034\n",
            "Epoch 4985/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4077 - accuracy: 0.7982\n",
            "Epoch 4986/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4060 - accuracy: 0.8047\n",
            "Epoch 4987/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4088 - accuracy: 0.8099\n",
            "Epoch 4988/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4052 - accuracy: 0.8125\n",
            "Epoch 4989/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4040 - accuracy: 0.8125\n",
            "Epoch 4990/10000\n",
            "768/768 [==============================] - 0s 110us/step - loss: 0.4084 - accuracy: 0.8099\n",
            "Epoch 4991/10000\n",
            "768/768 [==============================] - 0s 110us/step - loss: 0.4107 - accuracy: 0.7982\n",
            "Epoch 4992/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4045 - accuracy: 0.8008\n",
            "Epoch 4993/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4184 - accuracy: 0.7943\n",
            "Epoch 4994/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4070 - accuracy: 0.8073\n",
            "Epoch 4995/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4069 - accuracy: 0.8073\n",
            "Epoch 4996/10000\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4115 - accuracy: 0.7956\n",
            "Epoch 4997/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4189 - accuracy: 0.8099\n",
            "Epoch 4998/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4121 - accuracy: 0.8060\n",
            "Epoch 4999/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4125 - accuracy: 0.7969\n",
            "Epoch 5000/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4048 - accuracy: 0.8086\n",
            "Epoch 5001/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4053 - accuracy: 0.7917\n",
            "Epoch 5002/10000\n",
            "768/768 [==============================] - 0s 127us/step - loss: 0.4099 - accuracy: 0.8008\n",
            "Epoch 5003/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4205 - accuracy: 0.7930\n",
            "Epoch 5004/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4162 - accuracy: 0.8021\n",
            "Epoch 5005/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4027 - accuracy: 0.8216\n",
            "Epoch 5006/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4024 - accuracy: 0.8229\n",
            "Epoch 5007/10000\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.4076 - accuracy: 0.8060\n",
            "Epoch 5008/10000\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4163 - accuracy: 0.8021\n",
            "Epoch 5009/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4066 - accuracy: 0.8073\n",
            "Epoch 5010/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4082 - accuracy: 0.7943\n",
            "Epoch 5011/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4079 - accuracy: 0.8125\n",
            "Epoch 5012/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4041 - accuracy: 0.8125\n",
            "Epoch 5013/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4184 - accuracy: 0.8073\n",
            "Epoch 5014/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4121 - accuracy: 0.7969\n",
            "Epoch 5015/10000\n",
            "768/768 [==============================] - 0s 110us/step - loss: 0.4135 - accuracy: 0.8021\n",
            "Epoch 5016/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4081 - accuracy: 0.8034\n",
            "Epoch 5017/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4057 - accuracy: 0.8034\n",
            "Epoch 5018/10000\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.4090 - accuracy: 0.7995\n",
            "Epoch 5019/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4057 - accuracy: 0.8034\n",
            "Epoch 5020/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4049 - accuracy: 0.8086\n",
            "Epoch 5021/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4065 - accuracy: 0.8060\n",
            "Epoch 5022/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4045 - accuracy: 0.8099\n",
            "Epoch 5023/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4062 - accuracy: 0.8034\n",
            "Epoch 5024/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4041 - accuracy: 0.8112\n",
            "Epoch 5025/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4087 - accuracy: 0.8047\n",
            "Epoch 5026/10000\n",
            "768/768 [==============================] - 0s 122us/step - loss: 0.4073 - accuracy: 0.8034\n",
            "Epoch 5027/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4133 - accuracy: 0.8073\n",
            "Epoch 5028/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4133 - accuracy: 0.7930\n",
            "Epoch 5029/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4119 - accuracy: 0.8021\n",
            "Epoch 5030/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4044 - accuracy: 0.8112\n",
            "Epoch 5031/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4079 - accuracy: 0.8008\n",
            "Epoch 5032/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4080 - accuracy: 0.8021\n",
            "Epoch 5033/10000\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4065 - accuracy: 0.8008\n",
            "Epoch 5034/10000\n",
            "768/768 [==============================] - 0s 125us/step - loss: 0.4127 - accuracy: 0.8034\n",
            "Epoch 5035/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4137 - accuracy: 0.7995\n",
            "Epoch 5036/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4112 - accuracy: 0.8073\n",
            "Epoch 5037/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4073 - accuracy: 0.8073\n",
            "Epoch 5038/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4093 - accuracy: 0.7969\n",
            "Epoch 5039/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.3999 - accuracy: 0.8047\n",
            "Epoch 5040/10000\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.4044 - accuracy: 0.8034\n",
            "Epoch 5041/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4088 - accuracy: 0.8021\n",
            "Epoch 5042/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4040 - accuracy: 0.8086\n",
            "Epoch 5043/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4051 - accuracy: 0.8073\n",
            "Epoch 5044/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4127 - accuracy: 0.8034\n",
            "Epoch 5045/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4047 - accuracy: 0.8138\n",
            "Epoch 5046/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4050 - accuracy: 0.7995\n",
            "Epoch 5047/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4142 - accuracy: 0.7917\n",
            "Epoch 5048/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4172 - accuracy: 0.8008\n",
            "Epoch 5049/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4096 - accuracy: 0.8086\n",
            "Epoch 5050/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4062 - accuracy: 0.8177\n",
            "Epoch 5051/10000\n",
            "768/768 [==============================] - 0s 110us/step - loss: 0.4136 - accuracy: 0.8021\n",
            "Epoch 5052/10000\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.4141 - accuracy: 0.8047\n",
            "Epoch 5053/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4056 - accuracy: 0.8047\n",
            "Epoch 5054/10000\n",
            "768/768 [==============================] - 0s 109us/step - loss: 0.4057 - accuracy: 0.8125\n",
            "Epoch 5055/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4129 - accuracy: 0.8112\n",
            "Epoch 5056/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4114 - accuracy: 0.8034\n",
            "Epoch 5057/10000\n",
            "768/768 [==============================] - 0s 110us/step - loss: 0.4122 - accuracy: 0.8021\n",
            "Epoch 5058/10000\n",
            "768/768 [==============================] - 0s 110us/step - loss: 0.4114 - accuracy: 0.8112\n",
            "Epoch 5059/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4177 - accuracy: 0.8086\n",
            "Epoch 5060/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4217 - accuracy: 0.7917\n",
            "Epoch 5061/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4163 - accuracy: 0.8073\n",
            "Epoch 5062/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4288 - accuracy: 0.7969\n",
            "Epoch 5063/10000\n",
            "768/768 [==============================] - 0s 122us/step - loss: 0.4015 - accuracy: 0.8125\n",
            "Epoch 5064/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4078 - accuracy: 0.8060\n",
            "Epoch 5065/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.3962 - accuracy: 0.8125\n",
            "Epoch 5066/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4067 - accuracy: 0.8021\n",
            "Epoch 5067/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4112 - accuracy: 0.8047\n",
            "Epoch 5068/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4046 - accuracy: 0.8073\n",
            "Epoch 5069/10000\n",
            "768/768 [==============================] - 0s 126us/step - loss: 0.4175 - accuracy: 0.7956\n",
            "Epoch 5070/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4070 - accuracy: 0.7982\n",
            "Epoch 5071/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4197 - accuracy: 0.8047\n",
            "Epoch 5072/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4061 - accuracy: 0.7930\n",
            "Epoch 5073/10000\n",
            "768/768 [==============================] - 0s 110us/step - loss: 0.4081 - accuracy: 0.8086\n",
            "Epoch 5074/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4136 - accuracy: 0.8034\n",
            "Epoch 5075/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4094 - accuracy: 0.8008\n",
            "Epoch 5076/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4085 - accuracy: 0.8112\n",
            "Epoch 5077/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4057 - accuracy: 0.8008\n",
            "Epoch 5078/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4072 - accuracy: 0.8047\n",
            "Epoch 5079/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4074 - accuracy: 0.8086\n",
            "Epoch 5080/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4037 - accuracy: 0.8125\n",
            "Epoch 5081/10000\n",
            "768/768 [==============================] - 0s 110us/step - loss: 0.4120 - accuracy: 0.8047\n",
            "Epoch 5082/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4146 - accuracy: 0.7995\n",
            "Epoch 5083/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4111 - accuracy: 0.8086\n",
            "Epoch 5084/10000\n",
            "768/768 [==============================] - 0s 124us/step - loss: 0.4048 - accuracy: 0.7969\n",
            "Epoch 5085/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4067 - accuracy: 0.7956\n",
            "Epoch 5086/10000\n",
            "768/768 [==============================] - 0s 120us/step - loss: 0.4058 - accuracy: 0.8164\n",
            "Epoch 5087/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4047 - accuracy: 0.8008\n",
            "Epoch 5088/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4057 - accuracy: 0.8112\n",
            "Epoch 5089/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4117 - accuracy: 0.7917\n",
            "Epoch 5090/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4259 - accuracy: 0.7943\n",
            "Epoch 5091/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4117 - accuracy: 0.8021\n",
            "Epoch 5092/10000\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4130 - accuracy: 0.7956\n",
            "Epoch 5093/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4134 - accuracy: 0.8034\n",
            "Epoch 5094/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4209 - accuracy: 0.7943\n",
            "Epoch 5095/10000\n",
            "768/768 [==============================] - 0s 110us/step - loss: 0.4059 - accuracy: 0.8073\n",
            "Epoch 5096/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.3989 - accuracy: 0.8125\n",
            "Epoch 5097/10000\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.4103 - accuracy: 0.8073\n",
            "Epoch 5098/10000\n",
            "768/768 [==============================] - 0s 120us/step - loss: 0.4147 - accuracy: 0.7982\n",
            "Epoch 5099/10000\n",
            "768/768 [==============================] - 0s 126us/step - loss: 0.4102 - accuracy: 0.7982\n",
            "Epoch 5100/10000\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.4111 - accuracy: 0.8047\n",
            "Epoch 5101/10000\n",
            "768/768 [==============================] - 0s 122us/step - loss: 0.4070 - accuracy: 0.8021\n",
            "Epoch 5102/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4132 - accuracy: 0.7930\n",
            "Epoch 5103/10000\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.4010 - accuracy: 0.8138\n",
            "Epoch 5104/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4086 - accuracy: 0.8164\n",
            "Epoch 5105/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4105 - accuracy: 0.8138\n",
            "Epoch 5106/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4079 - accuracy: 0.8047\n",
            "Epoch 5107/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4099 - accuracy: 0.8008\n",
            "Epoch 5108/10000\n",
            "768/768 [==============================] - 0s 123us/step - loss: 0.4024 - accuracy: 0.8047\n",
            "Epoch 5109/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4154 - accuracy: 0.8099\n",
            "Epoch 5110/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4074 - accuracy: 0.8060\n",
            "Epoch 5111/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4074 - accuracy: 0.7995\n",
            "Epoch 5112/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4094 - accuracy: 0.8008\n",
            "Epoch 5113/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4072 - accuracy: 0.8086\n",
            "Epoch 5114/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4071 - accuracy: 0.8099\n",
            "Epoch 5115/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4107 - accuracy: 0.8008\n",
            "Epoch 5116/10000\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4164 - accuracy: 0.8008\n",
            "Epoch 5117/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4203 - accuracy: 0.8125\n",
            "Epoch 5118/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4046 - accuracy: 0.8177\n",
            "Epoch 5119/10000\n",
            "768/768 [==============================] - 0s 125us/step - loss: 0.4129 - accuracy: 0.8034\n",
            "Epoch 5120/10000\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4141 - accuracy: 0.8034\n",
            "Epoch 5121/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4077 - accuracy: 0.8086\n",
            "Epoch 5122/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4057 - accuracy: 0.8073\n",
            "Epoch 5123/10000\n",
            "768/768 [==============================] - 0s 124us/step - loss: 0.4119 - accuracy: 0.7904\n",
            "Epoch 5124/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4030 - accuracy: 0.7969\n",
            "Epoch 5125/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4054 - accuracy: 0.8164\n",
            "Epoch 5126/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4048 - accuracy: 0.8112\n",
            "Epoch 5127/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4177 - accuracy: 0.8073\n",
            "Epoch 5128/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4171 - accuracy: 0.7943\n",
            "Epoch 5129/10000\n",
            "768/768 [==============================] - 0s 110us/step - loss: 0.4091 - accuracy: 0.7995\n",
            "Epoch 5130/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4101 - accuracy: 0.8086\n",
            "Epoch 5131/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4034 - accuracy: 0.8099\n",
            "Epoch 5132/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4212 - accuracy: 0.8073\n",
            "Epoch 5133/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4041 - accuracy: 0.8047\n",
            "Epoch 5134/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4066 - accuracy: 0.8138\n",
            "Epoch 5135/10000\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.4045 - accuracy: 0.8060\n",
            "Epoch 5136/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4172 - accuracy: 0.7969\n",
            "Epoch 5137/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4085 - accuracy: 0.8021\n",
            "Epoch 5138/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4236 - accuracy: 0.7995\n",
            "Epoch 5139/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4128 - accuracy: 0.8060\n",
            "Epoch 5140/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4099 - accuracy: 0.8008\n",
            "Epoch 5141/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4048 - accuracy: 0.8138\n",
            "Epoch 5142/10000\n",
            "768/768 [==============================] - 0s 120us/step - loss: 0.4066 - accuracy: 0.8034\n",
            "Epoch 5143/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4176 - accuracy: 0.8021\n",
            "Epoch 5144/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4125 - accuracy: 0.7995\n",
            "Epoch 5145/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4041 - accuracy: 0.7995\n",
            "Epoch 5146/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4085 - accuracy: 0.7982\n",
            "Epoch 5147/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4079 - accuracy: 0.8125\n",
            "Epoch 5148/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4076 - accuracy: 0.8034\n",
            "Epoch 5149/10000\n",
            "768/768 [==============================] - 0s 110us/step - loss: 0.4039 - accuracy: 0.8164\n",
            "Epoch 5150/10000\n",
            "768/768 [==============================] - 0s 125us/step - loss: 0.4065 - accuracy: 0.8060\n",
            "Epoch 5151/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4026 - accuracy: 0.8177\n",
            "Epoch 5152/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4023 - accuracy: 0.8151\n",
            "Epoch 5153/10000\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4102 - accuracy: 0.8047\n",
            "Epoch 5154/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4039 - accuracy: 0.8112\n",
            "Epoch 5155/10000\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.4110 - accuracy: 0.8008\n",
            "Epoch 5156/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4089 - accuracy: 0.8099\n",
            "Epoch 5157/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4068 - accuracy: 0.8151\n",
            "Epoch 5158/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4045 - accuracy: 0.8021\n",
            "Epoch 5159/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4108 - accuracy: 0.8073\n",
            "Epoch 5160/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4025 - accuracy: 0.8047\n",
            "Epoch 5161/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4094 - accuracy: 0.8073\n",
            "Epoch 5162/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4040 - accuracy: 0.8112\n",
            "Epoch 5163/10000\n",
            "768/768 [==============================] - 0s 129us/step - loss: 0.4054 - accuracy: 0.8034\n",
            "Epoch 5164/10000\n",
            "768/768 [==============================] - 0s 125us/step - loss: 0.4151 - accuracy: 0.8047\n",
            "Epoch 5165/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4035 - accuracy: 0.8060\n",
            "Epoch 5166/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4081 - accuracy: 0.8060\n",
            "Epoch 5167/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4093 - accuracy: 0.7995\n",
            "Epoch 5168/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4109 - accuracy: 0.8008\n",
            "Epoch 5169/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4049 - accuracy: 0.8047\n",
            "Epoch 5170/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4124 - accuracy: 0.8164\n",
            "Epoch 5171/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4128 - accuracy: 0.8112\n",
            "Epoch 5172/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4056 - accuracy: 0.8034\n",
            "Epoch 5173/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4042 - accuracy: 0.8008\n",
            "Epoch 5174/10000\n",
            "768/768 [==============================] - 0s 123us/step - loss: 0.4081 - accuracy: 0.8099\n",
            "Epoch 5175/10000\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.4068 - accuracy: 0.8060\n",
            "Epoch 5176/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4090 - accuracy: 0.7982\n",
            "Epoch 5177/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4086 - accuracy: 0.8060\n",
            "Epoch 5178/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4083 - accuracy: 0.8177\n",
            "Epoch 5179/10000\n",
            "768/768 [==============================] - 0s 123us/step - loss: 0.4054 - accuracy: 0.8060\n",
            "Epoch 5180/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4090 - accuracy: 0.8034\n",
            "Epoch 5181/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4040 - accuracy: 0.8125\n",
            "Epoch 5182/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4051 - accuracy: 0.8099\n",
            "Epoch 5183/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4050 - accuracy: 0.8138\n",
            "Epoch 5184/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4069 - accuracy: 0.8047\n",
            "Epoch 5185/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4097 - accuracy: 0.8060\n",
            "Epoch 5186/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4084 - accuracy: 0.8073\n",
            "Epoch 5187/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4107 - accuracy: 0.7995\n",
            "Epoch 5188/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4024 - accuracy: 0.8073\n",
            "Epoch 5189/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4141 - accuracy: 0.8021\n",
            "Epoch 5190/10000\n",
            "768/768 [==============================] - 0s 110us/step - loss: 0.4111 - accuracy: 0.8021\n",
            "Epoch 5191/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4062 - accuracy: 0.8099\n",
            "Epoch 5192/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4086 - accuracy: 0.8073\n",
            "Epoch 5193/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4164 - accuracy: 0.7982\n",
            "Epoch 5194/10000\n",
            "768/768 [==============================] - 0s 109us/step - loss: 0.4060 - accuracy: 0.8021\n",
            "Epoch 5195/10000\n",
            "768/768 [==============================] - 0s 110us/step - loss: 0.4094 - accuracy: 0.8073\n",
            "Epoch 5196/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4062 - accuracy: 0.8034\n",
            "Epoch 5197/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4070 - accuracy: 0.8151\n",
            "Epoch 5198/10000\n",
            "768/768 [==============================] - 0s 136us/step - loss: 0.4093 - accuracy: 0.8086\n",
            "Epoch 5199/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4053 - accuracy: 0.8099\n",
            "Epoch 5200/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4099 - accuracy: 0.8099\n",
            "Epoch 5201/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4114 - accuracy: 0.8008\n",
            "Epoch 5202/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4096 - accuracy: 0.8047\n",
            "Epoch 5203/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4074 - accuracy: 0.8099\n",
            "Epoch 5204/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4239 - accuracy: 0.7982\n",
            "Epoch 5205/10000\n",
            "768/768 [==============================] - 0s 125us/step - loss: 0.4068 - accuracy: 0.8008\n",
            "Epoch 5206/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4038 - accuracy: 0.8008\n",
            "Epoch 5207/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4096 - accuracy: 0.8073\n",
            "Epoch 5208/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4072 - accuracy: 0.8099\n",
            "Epoch 5209/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4056 - accuracy: 0.8060\n",
            "Epoch 5210/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4104 - accuracy: 0.8047\n",
            "Epoch 5211/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4006 - accuracy: 0.8190\n",
            "Epoch 5212/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4077 - accuracy: 0.8034\n",
            "Epoch 5213/10000\n",
            "768/768 [==============================] - 0s 110us/step - loss: 0.4138 - accuracy: 0.7956\n",
            "Epoch 5214/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4117 - accuracy: 0.8021\n",
            "Epoch 5215/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4145 - accuracy: 0.8047\n",
            "Epoch 5216/10000\n",
            "768/768 [==============================] - 0s 110us/step - loss: 0.4152 - accuracy: 0.8112\n",
            "Epoch 5217/10000\n",
            "768/768 [==============================] - 0s 132us/step - loss: 0.4110 - accuracy: 0.8086\n",
            "Epoch 5218/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4150 - accuracy: 0.8008\n",
            "Epoch 5219/10000\n",
            "768/768 [==============================] - 0s 120us/step - loss: 0.4051 - accuracy: 0.8138\n",
            "Epoch 5220/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4116 - accuracy: 0.7956\n",
            "Epoch 5221/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4130 - accuracy: 0.7956\n",
            "Epoch 5222/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4090 - accuracy: 0.8073\n",
            "Epoch 5223/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4008 - accuracy: 0.8060\n",
            "Epoch 5224/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4075 - accuracy: 0.8021\n",
            "Epoch 5225/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4035 - accuracy: 0.7943\n",
            "Epoch 5226/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4066 - accuracy: 0.8021\n",
            "Epoch 5227/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4015 - accuracy: 0.8164\n",
            "Epoch 5228/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4104 - accuracy: 0.8099\n",
            "Epoch 5229/10000\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.4085 - accuracy: 0.8021\n",
            "Epoch 5230/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4042 - accuracy: 0.8255\n",
            "Epoch 5231/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4098 - accuracy: 0.7982\n",
            "Epoch 5232/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4133 - accuracy: 0.8021\n",
            "Epoch 5233/10000\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4058 - accuracy: 0.8138\n",
            "Epoch 5234/10000\n",
            "768/768 [==============================] - 0s 127us/step - loss: 0.4049 - accuracy: 0.8112\n",
            "Epoch 5235/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4008 - accuracy: 0.8190\n",
            "Epoch 5236/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4053 - accuracy: 0.8034\n",
            "Epoch 5237/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4122 - accuracy: 0.8047\n",
            "Epoch 5238/10000\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.4152 - accuracy: 0.8047\n",
            "Epoch 5239/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4278 - accuracy: 0.7995\n",
            "Epoch 5240/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4148 - accuracy: 0.8060\n",
            "Epoch 5241/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4169 - accuracy: 0.8099\n",
            "Epoch 5242/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4108 - accuracy: 0.8034\n",
            "Epoch 5243/10000\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.4040 - accuracy: 0.8112\n",
            "Epoch 5244/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4229 - accuracy: 0.7930\n",
            "Epoch 5245/10000\n",
            "768/768 [==============================] - 0s 109us/step - loss: 0.4102 - accuracy: 0.7995\n",
            "Epoch 5246/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4036 - accuracy: 0.8034\n",
            "Epoch 5247/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4039 - accuracy: 0.8047\n",
            "Epoch 5248/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4120 - accuracy: 0.7969\n",
            "Epoch 5249/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4099 - accuracy: 0.7969\n",
            "Epoch 5250/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4100 - accuracy: 0.8008\n",
            "Epoch 5251/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4139 - accuracy: 0.8086\n",
            "Epoch 5252/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4114 - accuracy: 0.8021\n",
            "Epoch 5253/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4089 - accuracy: 0.7930\n",
            "Epoch 5254/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4057 - accuracy: 0.8034\n",
            "Epoch 5255/10000\n",
            "768/768 [==============================] - 0s 123us/step - loss: 0.4124 - accuracy: 0.8112\n",
            "Epoch 5256/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4068 - accuracy: 0.7982\n",
            "Epoch 5257/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4117 - accuracy: 0.8060\n",
            "Epoch 5258/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4037 - accuracy: 0.8073\n",
            "Epoch 5259/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4023 - accuracy: 0.8112\n",
            "Epoch 5260/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4049 - accuracy: 0.8099\n",
            "Epoch 5261/10000\n",
            "768/768 [==============================] - 0s 110us/step - loss: 0.4061 - accuracy: 0.8034\n",
            "Epoch 5262/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4081 - accuracy: 0.8073\n",
            "Epoch 5263/10000\n",
            "768/768 [==============================] - 0s 123us/step - loss: 0.4077 - accuracy: 0.8060\n",
            "Epoch 5264/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4059 - accuracy: 0.8073\n",
            "Epoch 5265/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4192 - accuracy: 0.7995\n",
            "Epoch 5266/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4215 - accuracy: 0.8008\n",
            "Epoch 5267/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4135 - accuracy: 0.7930\n",
            "Epoch 5268/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4089 - accuracy: 0.8060\n",
            "Epoch 5269/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4270 - accuracy: 0.7917\n",
            "Epoch 5270/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4030 - accuracy: 0.7982\n",
            "Epoch 5271/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4176 - accuracy: 0.7982\n",
            "Epoch 5272/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4055 - accuracy: 0.7982\n",
            "Epoch 5273/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4025 - accuracy: 0.8099\n",
            "Epoch 5274/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4150 - accuracy: 0.7956\n",
            "Epoch 5275/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4157 - accuracy: 0.8086\n",
            "Epoch 5276/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4078 - accuracy: 0.8086\n",
            "Epoch 5277/10000\n",
            "768/768 [==============================] - 0s 122us/step - loss: 0.4039 - accuracy: 0.8073\n",
            "Epoch 5278/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4109 - accuracy: 0.7969\n",
            "Epoch 5279/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4100 - accuracy: 0.8008\n",
            "Epoch 5280/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4083 - accuracy: 0.8112\n",
            "Epoch 5281/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4012 - accuracy: 0.8099\n",
            "Epoch 5282/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4129 - accuracy: 0.8112\n",
            "Epoch 5283/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4096 - accuracy: 0.8047\n",
            "Epoch 5284/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4118 - accuracy: 0.7982\n",
            "Epoch 5285/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4065 - accuracy: 0.8060\n",
            "Epoch 5286/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4156 - accuracy: 0.8138\n",
            "Epoch 5287/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4116 - accuracy: 0.7956\n",
            "Epoch 5288/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4116 - accuracy: 0.7969\n",
            "Epoch 5289/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4060 - accuracy: 0.8047\n",
            "Epoch 5290/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4056 - accuracy: 0.8008\n",
            "Epoch 5291/10000\n",
            "768/768 [==============================] - 0s 108us/step - loss: 0.4009 - accuracy: 0.8034\n",
            "Epoch 5292/10000\n",
            "768/768 [==============================] - 0s 120us/step - loss: 0.4138 - accuracy: 0.7839\n",
            "Epoch 5293/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4038 - accuracy: 0.8060\n",
            "Epoch 5294/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4063 - accuracy: 0.7982\n",
            "Epoch 5295/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4061 - accuracy: 0.7930\n",
            "Epoch 5296/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4113 - accuracy: 0.7995\n",
            "Epoch 5297/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4198 - accuracy: 0.8021\n",
            "Epoch 5298/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.3995 - accuracy: 0.8138\n",
            "Epoch 5299/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4022 - accuracy: 0.8086\n",
            "Epoch 5300/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4107 - accuracy: 0.8060\n",
            "Epoch 5301/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4034 - accuracy: 0.8073\n",
            "Epoch 5302/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4042 - accuracy: 0.7943\n",
            "Epoch 5303/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4072 - accuracy: 0.8008\n",
            "Epoch 5304/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4092 - accuracy: 0.8008\n",
            "Epoch 5305/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4098 - accuracy: 0.8073\n",
            "Epoch 5306/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4109 - accuracy: 0.7956\n",
            "Epoch 5307/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4101 - accuracy: 0.8034\n",
            "Epoch 5308/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4097 - accuracy: 0.8099\n",
            "Epoch 5309/10000\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.4042 - accuracy: 0.8060\n",
            "Epoch 5310/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4142 - accuracy: 0.7969\n",
            "Epoch 5311/10000\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.4052 - accuracy: 0.8047\n",
            "Epoch 5312/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4048 - accuracy: 0.7995\n",
            "Epoch 5313/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4036 - accuracy: 0.8034\n",
            "Epoch 5314/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4020 - accuracy: 0.8034\n",
            "Epoch 5315/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4161 - accuracy: 0.8138\n",
            "Epoch 5316/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4292 - accuracy: 0.7969\n",
            "Epoch 5317/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4094 - accuracy: 0.8034\n",
            "Epoch 5318/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4189 - accuracy: 0.8073\n",
            "Epoch 5319/10000\n",
            "768/768 [==============================] - 0s 120us/step - loss: 0.4093 - accuracy: 0.7969\n",
            "Epoch 5320/10000\n",
            "768/768 [==============================] - 0s 122us/step - loss: 0.4036 - accuracy: 0.8125\n",
            "Epoch 5321/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4117 - accuracy: 0.7943\n",
            "Epoch 5322/10000\n",
            "768/768 [==============================] - 0s 124us/step - loss: 0.4155 - accuracy: 0.7878\n",
            "Epoch 5323/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4143 - accuracy: 0.8047\n",
            "Epoch 5324/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4040 - accuracy: 0.8151\n",
            "Epoch 5325/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4057 - accuracy: 0.8021\n",
            "Epoch 5326/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4105 - accuracy: 0.8060\n",
            "Epoch 5327/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4052 - accuracy: 0.8034\n",
            "Epoch 5328/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4144 - accuracy: 0.7956\n",
            "Epoch 5329/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4044 - accuracy: 0.8086\n",
            "Epoch 5330/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4044 - accuracy: 0.8034\n",
            "Epoch 5331/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4105 - accuracy: 0.7904\n",
            "Epoch 5332/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4042 - accuracy: 0.8138\n",
            "Epoch 5333/10000\n",
            "768/768 [==============================] - 0s 110us/step - loss: 0.4089 - accuracy: 0.7982\n",
            "Epoch 5334/10000\n",
            "768/768 [==============================] - 0s 144us/step - loss: 0.4151 - accuracy: 0.8047\n",
            "Epoch 5335/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4127 - accuracy: 0.8086\n",
            "Epoch 5336/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4077 - accuracy: 0.8047\n",
            "Epoch 5337/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4086 - accuracy: 0.8086\n",
            "Epoch 5338/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4114 - accuracy: 0.7995\n",
            "Epoch 5339/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4295 - accuracy: 0.7982\n",
            "Epoch 5340/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4082 - accuracy: 0.7995\n",
            "Epoch 5341/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4108 - accuracy: 0.8021\n",
            "Epoch 5342/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4078 - accuracy: 0.8086\n",
            "Epoch 5343/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4089 - accuracy: 0.8034\n",
            "Epoch 5344/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4141 - accuracy: 0.8021\n",
            "Epoch 5345/10000\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.4000 - accuracy: 0.8216\n",
            "Epoch 5346/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4107 - accuracy: 0.8008\n",
            "Epoch 5347/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4335 - accuracy: 0.7891\n",
            "Epoch 5348/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4145 - accuracy: 0.8099\n",
            "Epoch 5349/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4065 - accuracy: 0.8125\n",
            "Epoch 5350/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4149 - accuracy: 0.8008\n",
            "Epoch 5351/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4048 - accuracy: 0.8112\n",
            "Epoch 5352/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4033 - accuracy: 0.8060\n",
            "Epoch 5353/10000\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.4034 - accuracy: 0.8190\n",
            "Epoch 5354/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4183 - accuracy: 0.7995\n",
            "Epoch 5355/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4111 - accuracy: 0.8021\n",
            "Epoch 5356/10000\n",
            "768/768 [==============================] - 0s 124us/step - loss: 0.3964 - accuracy: 0.8125\n",
            "Epoch 5357/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4152 - accuracy: 0.7995\n",
            "Epoch 5358/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4068 - accuracy: 0.8008\n",
            "Epoch 5359/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4131 - accuracy: 0.8008\n",
            "Epoch 5360/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4006 - accuracy: 0.8099\n",
            "Epoch 5361/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4104 - accuracy: 0.8112\n",
            "Epoch 5362/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4216 - accuracy: 0.7930\n",
            "Epoch 5363/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4131 - accuracy: 0.7995\n",
            "Epoch 5364/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4003 - accuracy: 0.8034\n",
            "Epoch 5365/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4143 - accuracy: 0.7995\n",
            "Epoch 5366/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4062 - accuracy: 0.8073\n",
            "Epoch 5367/10000\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4081 - accuracy: 0.8060\n",
            "Epoch 5368/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4062 - accuracy: 0.8164\n",
            "Epoch 5369/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4027 - accuracy: 0.8151\n",
            "Epoch 5370/10000\n",
            "768/768 [==============================] - 0s 124us/step - loss: 0.4036 - accuracy: 0.8060\n",
            "Epoch 5371/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4082 - accuracy: 0.8151\n",
            "Epoch 5372/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4144 - accuracy: 0.8008\n",
            "Epoch 5373/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4041 - accuracy: 0.8047\n",
            "Epoch 5374/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4023 - accuracy: 0.8060\n",
            "Epoch 5375/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4030 - accuracy: 0.8047\n",
            "Epoch 5376/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4075 - accuracy: 0.8073\n",
            "Epoch 5377/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4060 - accuracy: 0.8099\n",
            "Epoch 5378/10000\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.4016 - accuracy: 0.8112\n",
            "Epoch 5379/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4045 - accuracy: 0.8021\n",
            "Epoch 5380/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4120 - accuracy: 0.8047\n",
            "Epoch 5381/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4109 - accuracy: 0.7969\n",
            "Epoch 5382/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4089 - accuracy: 0.8021\n",
            "Epoch 5383/10000\n",
            "768/768 [==============================] - 0s 120us/step - loss: 0.4240 - accuracy: 0.7930\n",
            "Epoch 5384/10000\n",
            "768/768 [==============================] - 0s 120us/step - loss: 0.4104 - accuracy: 0.8086\n",
            "Epoch 5385/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4164 - accuracy: 0.8021\n",
            "Epoch 5386/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4251 - accuracy: 0.7956\n",
            "Epoch 5387/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4087 - accuracy: 0.8008\n",
            "Epoch 5388/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4090 - accuracy: 0.7943\n",
            "Epoch 5389/10000\n",
            "768/768 [==============================] - 0s 127us/step - loss: 0.4095 - accuracy: 0.7982\n",
            "Epoch 5390/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4048 - accuracy: 0.8034\n",
            "Epoch 5391/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4095 - accuracy: 0.8034\n",
            "Epoch 5392/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4194 - accuracy: 0.8060\n",
            "Epoch 5393/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4112 - accuracy: 0.8112\n",
            "Epoch 5394/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4110 - accuracy: 0.7917\n",
            "Epoch 5395/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4084 - accuracy: 0.8073\n",
            "Epoch 5396/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4126 - accuracy: 0.8034\n",
            "Epoch 5397/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4023 - accuracy: 0.8138\n",
            "Epoch 5398/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4025 - accuracy: 0.8190\n",
            "Epoch 5399/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4150 - accuracy: 0.8099\n",
            "Epoch 5400/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4039 - accuracy: 0.8034\n",
            "Epoch 5401/10000\n",
            "768/768 [==============================] - 0s 126us/step - loss: 0.4148 - accuracy: 0.8138\n",
            "Epoch 5402/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4043 - accuracy: 0.8060\n",
            "Epoch 5403/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4077 - accuracy: 0.8073\n",
            "Epoch 5404/10000\n",
            "768/768 [==============================] - 0s 110us/step - loss: 0.4132 - accuracy: 0.7917\n",
            "Epoch 5405/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4076 - accuracy: 0.8047\n",
            "Epoch 5406/10000\n",
            "768/768 [==============================] - 0s 110us/step - loss: 0.4154 - accuracy: 0.7956\n",
            "Epoch 5407/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4168 - accuracy: 0.8021\n",
            "Epoch 5408/10000\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.4159 - accuracy: 0.8112\n",
            "Epoch 5409/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4090 - accuracy: 0.8034\n",
            "Epoch 5410/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4158 - accuracy: 0.7982\n",
            "Epoch 5411/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4141 - accuracy: 0.7982\n",
            "Epoch 5412/10000\n",
            "768/768 [==============================] - 0s 122us/step - loss: 0.4084 - accuracy: 0.7995\n",
            "Epoch 5413/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4074 - accuracy: 0.8073\n",
            "Epoch 5414/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4063 - accuracy: 0.8086\n",
            "Epoch 5415/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4048 - accuracy: 0.8125\n",
            "Epoch 5416/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4159 - accuracy: 0.7969\n",
            "Epoch 5417/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4065 - accuracy: 0.8099\n",
            "Epoch 5418/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4064 - accuracy: 0.7995\n",
            "Epoch 5419/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.3991 - accuracy: 0.8151\n",
            "Epoch 5420/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4088 - accuracy: 0.8047\n",
            "Epoch 5421/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4113 - accuracy: 0.8164\n",
            "Epoch 5422/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4101 - accuracy: 0.8151\n",
            "Epoch 5423/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4053 - accuracy: 0.8164\n",
            "Epoch 5424/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4121 - accuracy: 0.8047\n",
            "Epoch 5425/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4077 - accuracy: 0.8021\n",
            "Epoch 5426/10000\n",
            "768/768 [==============================] - 0s 124us/step - loss: 0.4124 - accuracy: 0.7930\n",
            "Epoch 5427/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4107 - accuracy: 0.8060\n",
            "Epoch 5428/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4051 - accuracy: 0.8021\n",
            "Epoch 5429/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4173 - accuracy: 0.8073\n",
            "Epoch 5430/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4019 - accuracy: 0.8073\n",
            "Epoch 5431/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4107 - accuracy: 0.8008\n",
            "Epoch 5432/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4037 - accuracy: 0.8151\n",
            "Epoch 5433/10000\n",
            "768/768 [==============================] - 0s 110us/step - loss: 0.4022 - accuracy: 0.7995\n",
            "Epoch 5434/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4089 - accuracy: 0.8073\n",
            "Epoch 5435/10000\n",
            "768/768 [==============================] - 0s 126us/step - loss: 0.4122 - accuracy: 0.7878\n",
            "Epoch 5436/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4053 - accuracy: 0.8060\n",
            "Epoch 5437/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4026 - accuracy: 0.8112\n",
            "Epoch 5438/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4045 - accuracy: 0.7969\n",
            "Epoch 5439/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4142 - accuracy: 0.8047\n",
            "Epoch 5440/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4143 - accuracy: 0.7943\n",
            "Epoch 5441/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4031 - accuracy: 0.8060\n",
            "Epoch 5442/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4109 - accuracy: 0.8099\n",
            "Epoch 5443/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4027 - accuracy: 0.8086\n",
            "Epoch 5444/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4068 - accuracy: 0.8177\n",
            "Epoch 5445/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4071 - accuracy: 0.7995\n",
            "Epoch 5446/10000\n",
            "768/768 [==============================] - 0s 120us/step - loss: 0.4049 - accuracy: 0.8047\n",
            "Epoch 5447/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4064 - accuracy: 0.8138\n",
            "Epoch 5448/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4093 - accuracy: 0.8086\n",
            "Epoch 5449/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4035 - accuracy: 0.8125\n",
            "Epoch 5450/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4066 - accuracy: 0.8008\n",
            "Epoch 5451/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4054 - accuracy: 0.8021\n",
            "Epoch 5452/10000\n",
            "768/768 [==============================] - 0s 129us/step - loss: 0.4048 - accuracy: 0.8021\n",
            "Epoch 5453/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4084 - accuracy: 0.8099\n",
            "Epoch 5454/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4200 - accuracy: 0.7969\n",
            "Epoch 5455/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4060 - accuracy: 0.8086\n",
            "Epoch 5456/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4100 - accuracy: 0.7995\n",
            "Epoch 5457/10000\n",
            "768/768 [==============================] - 0s 140us/step - loss: 0.4119 - accuracy: 0.8047\n",
            "Epoch 5458/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4080 - accuracy: 0.8073\n",
            "Epoch 5459/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4071 - accuracy: 0.8060\n",
            "Epoch 5460/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4178 - accuracy: 0.8008\n",
            "Epoch 5461/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4167 - accuracy: 0.7982\n",
            "Epoch 5462/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4149 - accuracy: 0.8177\n",
            "Epoch 5463/10000\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4166 - accuracy: 0.7995\n",
            "Epoch 5464/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4110 - accuracy: 0.8034\n",
            "Epoch 5465/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4028 - accuracy: 0.8112\n",
            "Epoch 5466/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4024 - accuracy: 0.8112\n",
            "Epoch 5467/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4152 - accuracy: 0.8047\n",
            "Epoch 5468/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4108 - accuracy: 0.8073\n",
            "Epoch 5469/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4034 - accuracy: 0.8164\n",
            "Epoch 5470/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4134 - accuracy: 0.8021\n",
            "Epoch 5471/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4105 - accuracy: 0.8021\n",
            "Epoch 5472/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4112 - accuracy: 0.7930\n",
            "Epoch 5473/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4123 - accuracy: 0.8034\n",
            "Epoch 5474/10000\n",
            "768/768 [==============================] - 0s 110us/step - loss: 0.4024 - accuracy: 0.8073\n",
            "Epoch 5475/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4194 - accuracy: 0.7943\n",
            "Epoch 5476/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4072 - accuracy: 0.8008\n",
            "Epoch 5477/10000\n",
            "768/768 [==============================] - 0s 123us/step - loss: 0.4052 - accuracy: 0.8047\n",
            "Epoch 5478/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4026 - accuracy: 0.8099\n",
            "Epoch 5479/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.3991 - accuracy: 0.8138\n",
            "Epoch 5480/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4032 - accuracy: 0.8047\n",
            "Epoch 5481/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4054 - accuracy: 0.8112\n",
            "Epoch 5482/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4062 - accuracy: 0.8086\n",
            "Epoch 5483/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4004 - accuracy: 0.8073\n",
            "Epoch 5484/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4066 - accuracy: 0.8008\n",
            "Epoch 5485/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4103 - accuracy: 0.7852\n",
            "Epoch 5486/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4028 - accuracy: 0.8086\n",
            "Epoch 5487/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4148 - accuracy: 0.8034\n",
            "Epoch 5488/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4166 - accuracy: 0.7956\n",
            "Epoch 5489/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.3964 - accuracy: 0.8138\n",
            "Epoch 5490/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4098 - accuracy: 0.8060\n",
            "Epoch 5491/10000\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.4098 - accuracy: 0.8099\n",
            "Epoch 5492/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4142 - accuracy: 0.7917\n",
            "Epoch 5493/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4114 - accuracy: 0.8047\n",
            "Epoch 5494/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4076 - accuracy: 0.8047\n",
            "Epoch 5495/10000\n",
            "768/768 [==============================] - 0s 130us/step - loss: 0.4039 - accuracy: 0.8008\n",
            "Epoch 5496/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4005 - accuracy: 0.8073\n",
            "Epoch 5497/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4068 - accuracy: 0.8047\n",
            "Epoch 5498/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4015 - accuracy: 0.8099\n",
            "Epoch 5499/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4211 - accuracy: 0.7956\n",
            "Epoch 5500/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4018 - accuracy: 0.8060\n",
            "Epoch 5501/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4079 - accuracy: 0.8073\n",
            "Epoch 5502/10000\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.4084 - accuracy: 0.8060\n",
            "Epoch 5503/10000\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4070 - accuracy: 0.8008\n",
            "Epoch 5504/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4165 - accuracy: 0.8034\n",
            "Epoch 5505/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4025 - accuracy: 0.8021\n",
            "Epoch 5506/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4094 - accuracy: 0.8164\n",
            "Epoch 5507/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4042 - accuracy: 0.8099\n",
            "Epoch 5508/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4080 - accuracy: 0.8008\n",
            "Epoch 5509/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4045 - accuracy: 0.8060\n",
            "Epoch 5510/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4150 - accuracy: 0.7995\n",
            "Epoch 5511/10000\n",
            "768/768 [==============================] - 0s 122us/step - loss: 0.4029 - accuracy: 0.8073\n",
            "Epoch 5512/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4072 - accuracy: 0.8034\n",
            "Epoch 5513/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4016 - accuracy: 0.8190\n",
            "Epoch 5514/10000\n",
            "768/768 [==============================] - 0s 120us/step - loss: 0.4083 - accuracy: 0.8073\n",
            "Epoch 5515/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4115 - accuracy: 0.8008\n",
            "Epoch 5516/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4095 - accuracy: 0.8008\n",
            "Epoch 5517/10000\n",
            "768/768 [==============================] - 0s 122us/step - loss: 0.4030 - accuracy: 0.8203\n",
            "Epoch 5518/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4075 - accuracy: 0.8073\n",
            "Epoch 5519/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4084 - accuracy: 0.8047\n",
            "Epoch 5520/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4092 - accuracy: 0.8034\n",
            "Epoch 5521/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4036 - accuracy: 0.8151\n",
            "Epoch 5522/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.3978 - accuracy: 0.8099\n",
            "Epoch 5523/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4272 - accuracy: 0.8047\n",
            "Epoch 5524/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4100 - accuracy: 0.8086\n",
            "Epoch 5525/10000\n",
            "768/768 [==============================] - 0s 122us/step - loss: 0.4068 - accuracy: 0.8125\n",
            "Epoch 5526/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4057 - accuracy: 0.8099\n",
            "Epoch 5527/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4093 - accuracy: 0.7995\n",
            "Epoch 5528/10000\n",
            "768/768 [==============================] - 0s 128us/step - loss: 0.4003 - accuracy: 0.8138\n",
            "Epoch 5529/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4178 - accuracy: 0.8021\n",
            "Epoch 5530/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4087 - accuracy: 0.8073\n",
            "Epoch 5531/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4082 - accuracy: 0.8008\n",
            "Epoch 5532/10000\n",
            "768/768 [==============================] - 0s 120us/step - loss: 0.4047 - accuracy: 0.8060\n",
            "Epoch 5533/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4167 - accuracy: 0.8008\n",
            "Epoch 5534/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4051 - accuracy: 0.8034\n",
            "Epoch 5535/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4190 - accuracy: 0.7943\n",
            "Epoch 5536/10000\n",
            "768/768 [==============================] - 0s 122us/step - loss: 0.4089 - accuracy: 0.8151\n",
            "Epoch 5537/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4064 - accuracy: 0.8060\n",
            "Epoch 5538/10000\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.4055 - accuracy: 0.8073\n",
            "Epoch 5539/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4136 - accuracy: 0.8047\n",
            "Epoch 5540/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4091 - accuracy: 0.8047\n",
            "Epoch 5541/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4092 - accuracy: 0.7956\n",
            "Epoch 5542/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4107 - accuracy: 0.8021\n",
            "Epoch 5543/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4004 - accuracy: 0.8021\n",
            "Epoch 5544/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4036 - accuracy: 0.7956\n",
            "Epoch 5545/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4039 - accuracy: 0.8073\n",
            "Epoch 5546/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4065 - accuracy: 0.8034\n",
            "Epoch 5547/10000\n",
            "768/768 [==============================] - 0s 120us/step - loss: 0.4084 - accuracy: 0.8138\n",
            "Epoch 5548/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4189 - accuracy: 0.8125\n",
            "Epoch 5549/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4184 - accuracy: 0.8060\n",
            "Epoch 5550/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4058 - accuracy: 0.8099\n",
            "Epoch 5551/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4011 - accuracy: 0.8086\n",
            "Epoch 5552/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4043 - accuracy: 0.8086\n",
            "Epoch 5553/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4103 - accuracy: 0.7995\n",
            "Epoch 5554/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4107 - accuracy: 0.8034\n",
            "Epoch 5555/10000\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.4179 - accuracy: 0.8021\n",
            "Epoch 5556/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4115 - accuracy: 0.7982\n",
            "Epoch 5557/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4077 - accuracy: 0.8099\n",
            "Epoch 5558/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4052 - accuracy: 0.8086\n",
            "Epoch 5559/10000\n",
            "768/768 [==============================] - 0s 120us/step - loss: 0.4058 - accuracy: 0.7995\n",
            "Epoch 5560/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4150 - accuracy: 0.7982\n",
            "Epoch 5561/10000\n",
            "768/768 [==============================] - 0s 122us/step - loss: 0.4177 - accuracy: 0.8034\n",
            "Epoch 5562/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4096 - accuracy: 0.8034\n",
            "Epoch 5563/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4049 - accuracy: 0.8112\n",
            "Epoch 5564/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4085 - accuracy: 0.8008\n",
            "Epoch 5565/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4002 - accuracy: 0.8060\n",
            "Epoch 5566/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4049 - accuracy: 0.8034\n",
            "Epoch 5567/10000\n",
            "768/768 [==============================] - 0s 120us/step - loss: 0.4090 - accuracy: 0.8073\n",
            "Epoch 5568/10000\n",
            "768/768 [==============================] - 0s 124us/step - loss: 0.4127 - accuracy: 0.8060\n",
            "Epoch 5569/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4121 - accuracy: 0.8060\n",
            "Epoch 5570/10000\n",
            "768/768 [==============================] - 0s 140us/step - loss: 0.4048 - accuracy: 0.8073\n",
            "Epoch 5571/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4018 - accuracy: 0.8086\n",
            "Epoch 5572/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4148 - accuracy: 0.7956\n",
            "Epoch 5573/10000\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4079 - accuracy: 0.8060\n",
            "Epoch 5574/10000\n",
            "768/768 [==============================] - 0s 120us/step - loss: 0.4187 - accuracy: 0.8047\n",
            "Epoch 5575/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4053 - accuracy: 0.7982\n",
            "Epoch 5576/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4033 - accuracy: 0.8125\n",
            "Epoch 5577/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4095 - accuracy: 0.8047\n",
            "Epoch 5578/10000\n",
            "768/768 [==============================] - 0s 110us/step - loss: 0.4095 - accuracy: 0.8008\n",
            "Epoch 5579/10000\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4074 - accuracy: 0.8021\n",
            "Epoch 5580/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4079 - accuracy: 0.8086\n",
            "Epoch 5581/10000\n",
            "768/768 [==============================] - 0s 122us/step - loss: 0.4061 - accuracy: 0.8047\n",
            "Epoch 5582/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4126 - accuracy: 0.8021\n",
            "Epoch 5583/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4055 - accuracy: 0.8060\n",
            "Epoch 5584/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4058 - accuracy: 0.8099\n",
            "Epoch 5585/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4081 - accuracy: 0.7982\n",
            "Epoch 5586/10000\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.4082 - accuracy: 0.8060\n",
            "Epoch 5587/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4118 - accuracy: 0.7995\n",
            "Epoch 5588/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4029 - accuracy: 0.8151\n",
            "Epoch 5589/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4002 - accuracy: 0.8021\n",
            "Epoch 5590/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4085 - accuracy: 0.8034\n",
            "Epoch 5591/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4054 - accuracy: 0.8086\n",
            "Epoch 5592/10000\n",
            "768/768 [==============================] - 0s 130us/step - loss: 0.4139 - accuracy: 0.8060\n",
            "Epoch 5593/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4081 - accuracy: 0.8086\n",
            "Epoch 5594/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4044 - accuracy: 0.8086\n",
            "Epoch 5595/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4256 - accuracy: 0.8073\n",
            "Epoch 5596/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4169 - accuracy: 0.7995\n",
            "Epoch 5597/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4168 - accuracy: 0.8073\n",
            "Epoch 5598/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4089 - accuracy: 0.8177\n",
            "Epoch 5599/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4007 - accuracy: 0.8138\n",
            "Epoch 5600/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4126 - accuracy: 0.8086\n",
            "Epoch 5601/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4039 - accuracy: 0.7956\n",
            "Epoch 5602/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4105 - accuracy: 0.8060\n",
            "Epoch 5603/10000\n",
            "768/768 [==============================] - 0s 122us/step - loss: 0.4038 - accuracy: 0.8125\n",
            "Epoch 5604/10000\n",
            "768/768 [==============================] - 0s 120us/step - loss: 0.4132 - accuracy: 0.8086\n",
            "Epoch 5605/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4018 - accuracy: 0.8151\n",
            "Epoch 5606/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4139 - accuracy: 0.7943\n",
            "Epoch 5607/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4080 - accuracy: 0.7982\n",
            "Epoch 5608/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4029 - accuracy: 0.8086\n",
            "Epoch 5609/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4062 - accuracy: 0.8034\n",
            "Epoch 5610/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4078 - accuracy: 0.8034\n",
            "Epoch 5611/10000\n",
            "768/768 [==============================] - 0s 123us/step - loss: 0.4051 - accuracy: 0.8047\n",
            "Epoch 5612/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4009 - accuracy: 0.8112\n",
            "Epoch 5613/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4133 - accuracy: 0.7982\n",
            "Epoch 5614/10000\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.4132 - accuracy: 0.7969\n",
            "Epoch 5615/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4079 - accuracy: 0.8086\n",
            "Epoch 5616/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4039 - accuracy: 0.8112\n",
            "Epoch 5617/10000\n",
            "768/768 [==============================] - 0s 126us/step - loss: 0.4075 - accuracy: 0.8034\n",
            "Epoch 5618/10000\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4102 - accuracy: 0.7930\n",
            "Epoch 5619/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4033 - accuracy: 0.8073\n",
            "Epoch 5620/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4035 - accuracy: 0.8021\n",
            "Epoch 5621/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4125 - accuracy: 0.7982\n",
            "Epoch 5622/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4030 - accuracy: 0.7969\n",
            "Epoch 5623/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4088 - accuracy: 0.8047\n",
            "Epoch 5624/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4098 - accuracy: 0.8190\n",
            "Epoch 5625/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4030 - accuracy: 0.7969\n",
            "Epoch 5626/10000\n",
            "768/768 [==============================] - 0s 110us/step - loss: 0.4120 - accuracy: 0.7956\n",
            "Epoch 5627/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4105 - accuracy: 0.8073\n",
            "Epoch 5628/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4045 - accuracy: 0.8112\n",
            "Epoch 5629/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4015 - accuracy: 0.8047\n",
            "Epoch 5630/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4059 - accuracy: 0.8112\n",
            "Epoch 5631/10000\n",
            "768/768 [==============================] - 0s 110us/step - loss: 0.4084 - accuracy: 0.8047\n",
            "Epoch 5632/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4077 - accuracy: 0.7982\n",
            "Epoch 5633/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4073 - accuracy: 0.8138\n",
            "Epoch 5634/10000\n",
            "768/768 [==============================] - 0s 129us/step - loss: 0.4074 - accuracy: 0.8073\n",
            "Epoch 5635/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4096 - accuracy: 0.7995\n",
            "Epoch 5636/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4051 - accuracy: 0.8021\n",
            "Epoch 5637/10000\n",
            "768/768 [==============================] - 0s 122us/step - loss: 0.4089 - accuracy: 0.7995\n",
            "Epoch 5638/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4183 - accuracy: 0.7943\n",
            "Epoch 5639/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4154 - accuracy: 0.7943\n",
            "Epoch 5640/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4125 - accuracy: 0.8177\n",
            "Epoch 5641/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4119 - accuracy: 0.8021\n",
            "Epoch 5642/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4065 - accuracy: 0.8021\n",
            "Epoch 5643/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4116 - accuracy: 0.8034\n",
            "Epoch 5644/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4286 - accuracy: 0.7956\n",
            "Epoch 5645/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4114 - accuracy: 0.8034\n",
            "Epoch 5646/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4112 - accuracy: 0.8086\n",
            "Epoch 5647/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4154 - accuracy: 0.8034\n",
            "Epoch 5648/10000\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.4048 - accuracy: 0.8073\n",
            "Epoch 5649/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4000 - accuracy: 0.8138\n",
            "Epoch 5650/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4072 - accuracy: 0.8086\n",
            "Epoch 5651/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4128 - accuracy: 0.8008\n",
            "Epoch 5652/10000\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4051 - accuracy: 0.8008\n",
            "Epoch 5653/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4143 - accuracy: 0.7995\n",
            "Epoch 5654/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4092 - accuracy: 0.8164\n",
            "Epoch 5655/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4019 - accuracy: 0.8073\n",
            "Epoch 5656/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4080 - accuracy: 0.8086\n",
            "Epoch 5657/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4042 - accuracy: 0.8073\n",
            "Epoch 5658/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4028 - accuracy: 0.8034\n",
            "Epoch 5659/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4150 - accuracy: 0.7982\n",
            "Epoch 5660/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4109 - accuracy: 0.8021\n",
            "Epoch 5661/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4076 - accuracy: 0.7982\n",
            "Epoch 5662/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4154 - accuracy: 0.7995\n",
            "Epoch 5663/10000\n",
            "768/768 [==============================] - 0s 120us/step - loss: 0.4187 - accuracy: 0.7943\n",
            "Epoch 5664/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4118 - accuracy: 0.8164\n",
            "Epoch 5665/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4042 - accuracy: 0.7995\n",
            "Epoch 5666/10000\n",
            "768/768 [==============================] - 0s 110us/step - loss: 0.4267 - accuracy: 0.7956\n",
            "Epoch 5667/10000\n",
            "768/768 [==============================] - 0s 110us/step - loss: 0.4145 - accuracy: 0.8060\n",
            "Epoch 5668/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4052 - accuracy: 0.7982\n",
            "Epoch 5669/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4124 - accuracy: 0.7891\n",
            "Epoch 5670/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4096 - accuracy: 0.7917\n",
            "Epoch 5671/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4172 - accuracy: 0.8008\n",
            "Epoch 5672/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4016 - accuracy: 0.8047\n",
            "Epoch 5673/10000\n",
            "768/768 [==============================] - 0s 128us/step - loss: 0.4063 - accuracy: 0.8034\n",
            "Epoch 5674/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4063 - accuracy: 0.8047\n",
            "Epoch 5675/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4010 - accuracy: 0.8099\n",
            "Epoch 5676/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4077 - accuracy: 0.8086\n",
            "Epoch 5677/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4068 - accuracy: 0.8086\n",
            "Epoch 5678/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4057 - accuracy: 0.8112\n",
            "Epoch 5679/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4021 - accuracy: 0.7969\n",
            "Epoch 5680/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4063 - accuracy: 0.8034\n",
            "Epoch 5681/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4124 - accuracy: 0.8099\n",
            "Epoch 5682/10000\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.4109 - accuracy: 0.7982\n",
            "Epoch 5683/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4106 - accuracy: 0.8060\n",
            "Epoch 5684/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4092 - accuracy: 0.8073\n",
            "Epoch 5685/10000\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.4093 - accuracy: 0.7982\n",
            "Epoch 5686/10000\n",
            "768/768 [==============================] - 0s 120us/step - loss: 0.4161 - accuracy: 0.8138\n",
            "Epoch 5687/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4002 - accuracy: 0.8112\n",
            "Epoch 5688/10000\n",
            "768/768 [==============================] - 0s 133us/step - loss: 0.4037 - accuracy: 0.8021\n",
            "Epoch 5689/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4091 - accuracy: 0.8060\n",
            "Epoch 5690/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4099 - accuracy: 0.8164\n",
            "Epoch 5691/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4069 - accuracy: 0.8047\n",
            "Epoch 5692/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.3982 - accuracy: 0.8086\n",
            "Epoch 5693/10000\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.4045 - accuracy: 0.8190\n",
            "Epoch 5694/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4064 - accuracy: 0.8151\n",
            "Epoch 5695/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4137 - accuracy: 0.8112\n",
            "Epoch 5696/10000\n",
            "768/768 [==============================] - 0s 124us/step - loss: 0.4106 - accuracy: 0.7943\n",
            "Epoch 5697/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4085 - accuracy: 0.8060\n",
            "Epoch 5698/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4090 - accuracy: 0.8125\n",
            "Epoch 5699/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4098 - accuracy: 0.7995\n",
            "Epoch 5700/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4060 - accuracy: 0.8112\n",
            "Epoch 5701/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4083 - accuracy: 0.8138\n",
            "Epoch 5702/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4065 - accuracy: 0.8047\n",
            "Epoch 5703/10000\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4068 - accuracy: 0.8021\n",
            "Epoch 5704/10000\n",
            "768/768 [==============================] - 0s 129us/step - loss: 0.4078 - accuracy: 0.8099\n",
            "Epoch 5705/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4054 - accuracy: 0.8060\n",
            "Epoch 5706/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4043 - accuracy: 0.8047\n",
            "Epoch 5707/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4056 - accuracy: 0.8164\n",
            "Epoch 5708/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4077 - accuracy: 0.8112\n",
            "Epoch 5709/10000\n",
            "768/768 [==============================] - 0s 122us/step - loss: 0.4096 - accuracy: 0.8034\n",
            "Epoch 5710/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4046 - accuracy: 0.7982\n",
            "Epoch 5711/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.3999 - accuracy: 0.8047\n",
            "Epoch 5712/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4101 - accuracy: 0.8060\n",
            "Epoch 5713/10000\n",
            "768/768 [==============================] - 0s 110us/step - loss: 0.4063 - accuracy: 0.8034\n",
            "Epoch 5714/10000\n",
            "768/768 [==============================] - 0s 109us/step - loss: 0.4045 - accuracy: 0.8034\n",
            "Epoch 5715/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4028 - accuracy: 0.8125\n",
            "Epoch 5716/10000\n",
            "768/768 [==============================] - 0s 124us/step - loss: 0.4025 - accuracy: 0.8086\n",
            "Epoch 5717/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4039 - accuracy: 0.7995\n",
            "Epoch 5718/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4120 - accuracy: 0.8190\n",
            "Epoch 5719/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4138 - accuracy: 0.8073\n",
            "Epoch 5720/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4024 - accuracy: 0.8177\n",
            "Epoch 5721/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4057 - accuracy: 0.8086\n",
            "Epoch 5722/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4030 - accuracy: 0.8021\n",
            "Epoch 5723/10000\n",
            "768/768 [==============================] - 0s 155us/step - loss: 0.4029 - accuracy: 0.7982\n",
            "Epoch 5724/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4153 - accuracy: 0.8047\n",
            "Epoch 5725/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4034 - accuracy: 0.8086\n",
            "Epoch 5726/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4156 - accuracy: 0.7943\n",
            "Epoch 5727/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4100 - accuracy: 0.8008\n",
            "Epoch 5728/10000\n",
            "768/768 [==============================] - 0s 109us/step - loss: 0.4190 - accuracy: 0.8060\n",
            "Epoch 5729/10000\n",
            "768/768 [==============================] - 0s 110us/step - loss: 0.4080 - accuracy: 0.8099\n",
            "Epoch 5730/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4045 - accuracy: 0.8086\n",
            "Epoch 5731/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.3946 - accuracy: 0.8047\n",
            "Epoch 5732/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4177 - accuracy: 0.7969\n",
            "Epoch 5733/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4066 - accuracy: 0.8099\n",
            "Epoch 5734/10000\n",
            "768/768 [==============================] - 0s 110us/step - loss: 0.4025 - accuracy: 0.8047\n",
            "Epoch 5735/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.3996 - accuracy: 0.7943\n",
            "Epoch 5736/10000\n",
            "768/768 [==============================] - 0s 110us/step - loss: 0.4100 - accuracy: 0.7982\n",
            "Epoch 5737/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4083 - accuracy: 0.8060\n",
            "Epoch 5738/10000\n",
            "768/768 [==============================] - 0s 127us/step - loss: 0.4067 - accuracy: 0.8034\n",
            "Epoch 5739/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4175 - accuracy: 0.8047\n",
            "Epoch 5740/10000\n",
            "768/768 [==============================] - 0s 108us/step - loss: 0.4097 - accuracy: 0.8021\n",
            "Epoch 5741/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4074 - accuracy: 0.7930\n",
            "Epoch 5742/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4137 - accuracy: 0.7995\n",
            "Epoch 5743/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4049 - accuracy: 0.8047\n",
            "Epoch 5744/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4050 - accuracy: 0.8138\n",
            "Epoch 5745/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4036 - accuracy: 0.8060\n",
            "Epoch 5746/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4098 - accuracy: 0.7982\n",
            "Epoch 5747/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4095 - accuracy: 0.8021\n",
            "Epoch 5748/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4056 - accuracy: 0.7995\n",
            "Epoch 5749/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4064 - accuracy: 0.8073\n",
            "Epoch 5750/10000\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.4190 - accuracy: 0.8073\n",
            "Epoch 5751/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4127 - accuracy: 0.8112\n",
            "Epoch 5752/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4134 - accuracy: 0.7969\n",
            "Epoch 5753/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4084 - accuracy: 0.8086\n",
            "Epoch 5754/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4051 - accuracy: 0.8112\n",
            "Epoch 5755/10000\n",
            "768/768 [==============================] - 0s 120us/step - loss: 0.4073 - accuracy: 0.8125\n",
            "Epoch 5756/10000\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4145 - accuracy: 0.7943\n",
            "Epoch 5757/10000\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.4028 - accuracy: 0.8112\n",
            "Epoch 5758/10000\n",
            "768/768 [==============================] - 0s 124us/step - loss: 0.4224 - accuracy: 0.7995\n",
            "Epoch 5759/10000\n",
            "768/768 [==============================] - 0s 127us/step - loss: 0.4019 - accuracy: 0.8177\n",
            "Epoch 5760/10000\n",
            "768/768 [==============================] - 0s 122us/step - loss: 0.4027 - accuracy: 0.8125\n",
            "Epoch 5761/10000\n",
            "768/768 [==============================] - 0s 135us/step - loss: 0.4077 - accuracy: 0.8073\n",
            "Epoch 5762/10000\n",
            "768/768 [==============================] - 0s 132us/step - loss: 0.4043 - accuracy: 0.8073\n",
            "Epoch 5763/10000\n",
            "768/768 [==============================] - 0s 122us/step - loss: 0.4057 - accuracy: 0.8086\n",
            "Epoch 5764/10000\n",
            "768/768 [==============================] - 0s 124us/step - loss: 0.4203 - accuracy: 0.7995\n",
            "Epoch 5765/10000\n",
            "768/768 [==============================] - 0s 131us/step - loss: 0.4150 - accuracy: 0.8034\n",
            "Epoch 5766/10000\n",
            "768/768 [==============================] - 0s 131us/step - loss: 0.4103 - accuracy: 0.8086\n",
            "Epoch 5767/10000\n",
            "768/768 [==============================] - 0s 122us/step - loss: 0.4112 - accuracy: 0.8008\n",
            "Epoch 5768/10000\n",
            "768/768 [==============================] - 0s 122us/step - loss: 0.4046 - accuracy: 0.8047\n",
            "Epoch 5769/10000\n",
            "768/768 [==============================] - 0s 132us/step - loss: 0.4052 - accuracy: 0.8229\n",
            "Epoch 5770/10000\n",
            "768/768 [==============================] - 0s 128us/step - loss: 0.4058 - accuracy: 0.8112\n",
            "Epoch 5771/10000\n",
            "768/768 [==============================] - 0s 139us/step - loss: 0.4082 - accuracy: 0.8034\n",
            "Epoch 5772/10000\n",
            "768/768 [==============================] - 0s 126us/step - loss: 0.4181 - accuracy: 0.7969\n",
            "Epoch 5773/10000\n",
            "768/768 [==============================] - 0s 120us/step - loss: 0.4069 - accuracy: 0.8086\n",
            "Epoch 5774/10000\n",
            "768/768 [==============================] - 0s 126us/step - loss: 0.4138 - accuracy: 0.8008\n",
            "Epoch 5775/10000\n",
            "768/768 [==============================] - 0s 125us/step - loss: 0.4051 - accuracy: 0.7969\n",
            "Epoch 5776/10000\n",
            "768/768 [==============================] - 0s 137us/step - loss: 0.4203 - accuracy: 0.7956\n",
            "Epoch 5777/10000\n",
            "768/768 [==============================] - 0s 120us/step - loss: 0.4000 - accuracy: 0.8086\n",
            "Epoch 5778/10000\n",
            "768/768 [==============================] - 0s 125us/step - loss: 0.4069 - accuracy: 0.8112\n",
            "Epoch 5779/10000\n",
            "768/768 [==============================] - 0s 126us/step - loss: 0.4143 - accuracy: 0.8047\n",
            "Epoch 5780/10000\n",
            "768/768 [==============================] - 0s 141us/step - loss: 0.4057 - accuracy: 0.8034\n",
            "Epoch 5781/10000\n",
            "768/768 [==============================] - 0s 131us/step - loss: 0.4033 - accuracy: 0.8151\n",
            "Epoch 5782/10000\n",
            "768/768 [==============================] - 0s 126us/step - loss: 0.4074 - accuracy: 0.7982\n",
            "Epoch 5783/10000\n",
            "768/768 [==============================] - 0s 130us/step - loss: 0.4262 - accuracy: 0.7956\n",
            "Epoch 5784/10000\n",
            "768/768 [==============================] - 0s 135us/step - loss: 0.4141 - accuracy: 0.7943\n",
            "Epoch 5785/10000\n",
            "768/768 [==============================] - 0s 129us/step - loss: 0.4090 - accuracy: 0.8073\n",
            "Epoch 5786/10000\n",
            "768/768 [==============================] - 0s 141us/step - loss: 0.4121 - accuracy: 0.7852\n",
            "Epoch 5787/10000\n",
            "768/768 [==============================] - 0s 126us/step - loss: 0.4002 - accuracy: 0.8112\n",
            "Epoch 5788/10000\n",
            "768/768 [==============================] - 0s 130us/step - loss: 0.4075 - accuracy: 0.8047\n",
            "Epoch 5789/10000\n",
            "768/768 [==============================] - 0s 124us/step - loss: 0.4044 - accuracy: 0.8060\n",
            "Epoch 5790/10000\n",
            "768/768 [==============================] - 0s 129us/step - loss: 0.4243 - accuracy: 0.7943\n",
            "Epoch 5791/10000\n",
            "768/768 [==============================] - 0s 138us/step - loss: 0.4109 - accuracy: 0.8099\n",
            "Epoch 5792/10000\n",
            "768/768 [==============================] - 0s 135us/step - loss: 0.4096 - accuracy: 0.8086\n",
            "Epoch 5793/10000\n",
            "768/768 [==============================] - 0s 130us/step - loss: 0.4066 - accuracy: 0.8151\n",
            "Epoch 5794/10000\n",
            "768/768 [==============================] - 0s 129us/step - loss: 0.4073 - accuracy: 0.8125\n",
            "Epoch 5795/10000\n",
            "768/768 [==============================] - 0s 124us/step - loss: 0.4170 - accuracy: 0.7917\n",
            "Epoch 5796/10000\n",
            "768/768 [==============================] - 0s 123us/step - loss: 0.4122 - accuracy: 0.8086\n",
            "Epoch 5797/10000\n",
            "768/768 [==============================] - 0s 123us/step - loss: 0.4080 - accuracy: 0.8034\n",
            "Epoch 5798/10000\n",
            "768/768 [==============================] - 0s 130us/step - loss: 0.4121 - accuracy: 0.8112\n",
            "Epoch 5799/10000\n",
            "768/768 [==============================] - 0s 132us/step - loss: 0.4079 - accuracy: 0.8099\n",
            "Epoch 5800/10000\n",
            "768/768 [==============================] - 0s 126us/step - loss: 0.4078 - accuracy: 0.7982\n",
            "Epoch 5801/10000\n",
            "768/768 [==============================] - 0s 153us/step - loss: 0.4014 - accuracy: 0.8034\n",
            "Epoch 5802/10000\n",
            "768/768 [==============================] - 0s 125us/step - loss: 0.4139 - accuracy: 0.8021\n",
            "Epoch 5803/10000\n",
            "768/768 [==============================] - 0s 129us/step - loss: 0.4146 - accuracy: 0.7995\n",
            "Epoch 5804/10000\n",
            "768/768 [==============================] - 0s 131us/step - loss: 0.4040 - accuracy: 0.8047\n",
            "Epoch 5805/10000\n",
            "768/768 [==============================] - 0s 125us/step - loss: 0.4175 - accuracy: 0.8190\n",
            "Epoch 5806/10000\n",
            "768/768 [==============================] - 0s 123us/step - loss: 0.4041 - accuracy: 0.7930\n",
            "Epoch 5807/10000\n",
            "768/768 [==============================] - 0s 125us/step - loss: 0.4031 - accuracy: 0.7995\n",
            "Epoch 5808/10000\n",
            "768/768 [==============================] - 0s 125us/step - loss: 0.4097 - accuracy: 0.7995\n",
            "Epoch 5809/10000\n",
            "768/768 [==============================] - 0s 128us/step - loss: 0.3980 - accuracy: 0.8151\n",
            "Epoch 5810/10000\n",
            "768/768 [==============================] - 0s 130us/step - loss: 0.4083 - accuracy: 0.8125\n",
            "Epoch 5811/10000\n",
            "768/768 [==============================] - 0s 131us/step - loss: 0.4106 - accuracy: 0.8073\n",
            "Epoch 5812/10000\n",
            "768/768 [==============================] - 0s 126us/step - loss: 0.3992 - accuracy: 0.8112\n",
            "Epoch 5813/10000\n",
            "768/768 [==============================] - 0s 128us/step - loss: 0.4103 - accuracy: 0.8008\n",
            "Epoch 5814/10000\n",
            "768/768 [==============================] - 0s 134us/step - loss: 0.4039 - accuracy: 0.7982\n",
            "Epoch 5815/10000\n",
            "768/768 [==============================] - 0s 126us/step - loss: 0.4098 - accuracy: 0.8125\n",
            "Epoch 5816/10000\n",
            "768/768 [==============================] - 0s 133us/step - loss: 0.4294 - accuracy: 0.7995\n",
            "Epoch 5817/10000\n",
            "768/768 [==============================] - 0s 125us/step - loss: 0.4010 - accuracy: 0.8060\n",
            "Epoch 5818/10000\n",
            "768/768 [==============================] - 0s 129us/step - loss: 0.4225 - accuracy: 0.8047\n",
            "Epoch 5819/10000\n",
            "768/768 [==============================] - 0s 132us/step - loss: 0.4125 - accuracy: 0.8073\n",
            "Epoch 5820/10000\n",
            "768/768 [==============================] - 0s 128us/step - loss: 0.4194 - accuracy: 0.7969\n",
            "Epoch 5821/10000\n",
            "768/768 [==============================] - 0s 137us/step - loss: 0.4169 - accuracy: 0.7943\n",
            "Epoch 5822/10000\n",
            "768/768 [==============================] - 0s 129us/step - loss: 0.4026 - accuracy: 0.8047\n",
            "Epoch 5823/10000\n",
            "768/768 [==============================] - 0s 125us/step - loss: 0.4015 - accuracy: 0.8112\n",
            "Epoch 5824/10000\n",
            "768/768 [==============================] - 0s 128us/step - loss: 0.3991 - accuracy: 0.8151\n",
            "Epoch 5825/10000\n",
            "768/768 [==============================] - 0s 127us/step - loss: 0.4087 - accuracy: 0.8021\n",
            "Epoch 5826/10000\n",
            "768/768 [==============================] - 0s 129us/step - loss: 0.4096 - accuracy: 0.8034\n",
            "Epoch 5827/10000\n",
            "768/768 [==============================] - 0s 123us/step - loss: 0.4174 - accuracy: 0.7969\n",
            "Epoch 5828/10000\n",
            "768/768 [==============================] - 0s 150us/step - loss: 0.4002 - accuracy: 0.8151\n",
            "Epoch 5829/10000\n",
            "768/768 [==============================] - 0s 130us/step - loss: 0.4049 - accuracy: 0.8060\n",
            "Epoch 5830/10000\n",
            "768/768 [==============================] - 0s 124us/step - loss: 0.4109 - accuracy: 0.8099\n",
            "Epoch 5831/10000\n",
            "768/768 [==============================] - 0s 134us/step - loss: 0.4052 - accuracy: 0.8034\n",
            "Epoch 5832/10000\n",
            "768/768 [==============================] - 0s 128us/step - loss: 0.4059 - accuracy: 0.8073\n",
            "Epoch 5833/10000\n",
            "768/768 [==============================] - 0s 132us/step - loss: 0.4073 - accuracy: 0.7969\n",
            "Epoch 5834/10000\n",
            "768/768 [==============================] - 0s 127us/step - loss: 0.4104 - accuracy: 0.7969\n",
            "Epoch 5835/10000\n",
            "768/768 [==============================] - 0s 125us/step - loss: 0.4049 - accuracy: 0.8164\n",
            "Epoch 5836/10000\n",
            "768/768 [==============================] - 0s 127us/step - loss: 0.4024 - accuracy: 0.8164\n",
            "Epoch 5837/10000\n",
            "768/768 [==============================] - 0s 128us/step - loss: 0.4078 - accuracy: 0.8164\n",
            "Epoch 5838/10000\n",
            "768/768 [==============================] - 0s 131us/step - loss: 0.4124 - accuracy: 0.8008\n",
            "Epoch 5839/10000\n",
            "768/768 [==============================] - 0s 127us/step - loss: 0.3996 - accuracy: 0.7995\n",
            "Epoch 5840/10000\n",
            "768/768 [==============================] - 0s 123us/step - loss: 0.4107 - accuracy: 0.8021\n",
            "Epoch 5841/10000\n",
            "768/768 [==============================] - 0s 130us/step - loss: 0.4056 - accuracy: 0.8034\n",
            "Epoch 5842/10000\n",
            "768/768 [==============================] - 0s 128us/step - loss: 0.4132 - accuracy: 0.7969\n",
            "Epoch 5843/10000\n",
            "768/768 [==============================] - 0s 139us/step - loss: 0.3991 - accuracy: 0.8021\n",
            "Epoch 5844/10000\n",
            "768/768 [==============================] - 0s 125us/step - loss: 0.4067 - accuracy: 0.8008\n",
            "Epoch 5845/10000\n",
            "768/768 [==============================] - 0s 126us/step - loss: 0.4180 - accuracy: 0.8060\n",
            "Epoch 5846/10000\n",
            "768/768 [==============================] - 0s 128us/step - loss: 0.4079 - accuracy: 0.8151\n",
            "Epoch 5847/10000\n",
            "768/768 [==============================] - 0s 126us/step - loss: 0.4207 - accuracy: 0.7930\n",
            "Epoch 5848/10000\n",
            "768/768 [==============================] - 0s 126us/step - loss: 0.4058 - accuracy: 0.8034\n",
            "Epoch 5849/10000\n",
            "768/768 [==============================] - 0s 127us/step - loss: 0.4067 - accuracy: 0.7943\n",
            "Epoch 5850/10000\n",
            "768/768 [==============================] - 0s 126us/step - loss: 0.4068 - accuracy: 0.7982\n",
            "Epoch 5851/10000\n",
            "768/768 [==============================] - 0s 130us/step - loss: 0.4090 - accuracy: 0.8021\n",
            "Epoch 5852/10000\n",
            "768/768 [==============================] - 0s 128us/step - loss: 0.4130 - accuracy: 0.8008\n",
            "Epoch 5853/10000\n",
            "768/768 [==============================] - 0s 130us/step - loss: 0.4108 - accuracy: 0.7995\n",
            "Epoch 5854/10000\n",
            "768/768 [==============================] - 0s 122us/step - loss: 0.4111 - accuracy: 0.7878\n",
            "Epoch 5855/10000\n",
            "768/768 [==============================] - 0s 127us/step - loss: 0.4040 - accuracy: 0.8125\n",
            "Epoch 5856/10000\n",
            "768/768 [==============================] - 0s 124us/step - loss: 0.4067 - accuracy: 0.7969\n",
            "Epoch 5857/10000\n",
            "768/768 [==============================] - 0s 134us/step - loss: 0.4124 - accuracy: 0.8086\n",
            "Epoch 5858/10000\n",
            "768/768 [==============================] - 0s 128us/step - loss: 0.4093 - accuracy: 0.8060\n",
            "Epoch 5859/10000\n",
            "768/768 [==============================] - 0s 124us/step - loss: 0.4126 - accuracy: 0.8138\n",
            "Epoch 5860/10000\n",
            "768/768 [==============================] - 0s 126us/step - loss: 0.4117 - accuracy: 0.8060\n",
            "Epoch 5861/10000\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4003 - accuracy: 0.8138\n",
            "Epoch 5862/10000\n",
            "768/768 [==============================] - 0s 123us/step - loss: 0.4152 - accuracy: 0.7982\n",
            "Epoch 5863/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4077 - accuracy: 0.8073\n",
            "Epoch 5864/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4003 - accuracy: 0.8138\n",
            "Epoch 5865/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4124 - accuracy: 0.8060\n",
            "Epoch 5866/10000\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4017 - accuracy: 0.8099\n",
            "Epoch 5867/10000\n",
            "768/768 [==============================] - 0s 124us/step - loss: 0.4044 - accuracy: 0.8073\n",
            "Epoch 5868/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4030 - accuracy: 0.7969\n",
            "Epoch 5869/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4084 - accuracy: 0.8229\n",
            "Epoch 5870/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4083 - accuracy: 0.7995\n",
            "Epoch 5871/10000\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4020 - accuracy: 0.8060\n",
            "Epoch 5872/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4023 - accuracy: 0.8112\n",
            "Epoch 5873/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4092 - accuracy: 0.8060\n",
            "Epoch 5874/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4140 - accuracy: 0.7995\n",
            "Epoch 5875/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4176 - accuracy: 0.7917\n",
            "Epoch 5876/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4092 - accuracy: 0.8099\n",
            "Epoch 5877/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4075 - accuracy: 0.8021\n",
            "Epoch 5878/10000\n",
            "768/768 [==============================] - 0s 120us/step - loss: 0.4097 - accuracy: 0.8138\n",
            "Epoch 5879/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.3998 - accuracy: 0.8099\n",
            "Epoch 5880/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4042 - accuracy: 0.8073\n",
            "Epoch 5881/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4093 - accuracy: 0.7969\n",
            "Epoch 5882/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4149 - accuracy: 0.8047\n",
            "Epoch 5883/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4049 - accuracy: 0.8086\n",
            "Epoch 5884/10000\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.4062 - accuracy: 0.8112\n",
            "Epoch 5885/10000\n",
            "768/768 [==============================] - 0s 129us/step - loss: 0.4028 - accuracy: 0.8177\n",
            "Epoch 5886/10000\n",
            "768/768 [==============================] - 0s 122us/step - loss: 0.4055 - accuracy: 0.8125\n",
            "Epoch 5887/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4020 - accuracy: 0.8047\n",
            "Epoch 5888/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4104 - accuracy: 0.8151\n",
            "Epoch 5889/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4175 - accuracy: 0.8008\n",
            "Epoch 5890/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4191 - accuracy: 0.7930\n",
            "Epoch 5891/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4114 - accuracy: 0.7982\n",
            "Epoch 5892/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4071 - accuracy: 0.8086\n",
            "Epoch 5893/10000\n",
            "768/768 [==============================] - 0s 110us/step - loss: 0.4114 - accuracy: 0.8008\n",
            "Epoch 5894/10000\n",
            "768/768 [==============================] - 0s 120us/step - loss: 0.4040 - accuracy: 0.8021\n",
            "Epoch 5895/10000\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.4028 - accuracy: 0.8125\n",
            "Epoch 5896/10000\n",
            "768/768 [==============================] - 0s 110us/step - loss: 0.4059 - accuracy: 0.7930\n",
            "Epoch 5897/10000\n",
            "768/768 [==============================] - 0s 127us/step - loss: 0.4094 - accuracy: 0.7982\n",
            "Epoch 5898/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4025 - accuracy: 0.8021\n",
            "Epoch 5899/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4048 - accuracy: 0.8125\n",
            "Epoch 5900/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4033 - accuracy: 0.8112\n",
            "Epoch 5901/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4118 - accuracy: 0.8073\n",
            "Epoch 5902/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4120 - accuracy: 0.7956\n",
            "Epoch 5903/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4068 - accuracy: 0.8047\n",
            "Epoch 5904/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4145 - accuracy: 0.8047\n",
            "Epoch 5905/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4200 - accuracy: 0.7904\n",
            "Epoch 5906/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4126 - accuracy: 0.8073\n",
            "Epoch 5907/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4075 - accuracy: 0.8047\n",
            "Epoch 5908/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4057 - accuracy: 0.7982\n",
            "Epoch 5909/10000\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.4066 - accuracy: 0.8008\n",
            "Epoch 5910/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4074 - accuracy: 0.8021\n",
            "Epoch 5911/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4089 - accuracy: 0.8047\n",
            "Epoch 5912/10000\n",
            "768/768 [==============================] - 0s 126us/step - loss: 0.4075 - accuracy: 0.8021\n",
            "Epoch 5913/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4113 - accuracy: 0.7891\n",
            "Epoch 5914/10000\n",
            "768/768 [==============================] - 0s 110us/step - loss: 0.3992 - accuracy: 0.8138\n",
            "Epoch 5915/10000\n",
            "768/768 [==============================] - 0s 110us/step - loss: 0.4083 - accuracy: 0.8047\n",
            "Epoch 5916/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4117 - accuracy: 0.8060\n",
            "Epoch 5917/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4132 - accuracy: 0.7982\n",
            "Epoch 5918/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4041 - accuracy: 0.8034\n",
            "Epoch 5919/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4015 - accuracy: 0.8112\n",
            "Epoch 5920/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4055 - accuracy: 0.8060\n",
            "Epoch 5921/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.3998 - accuracy: 0.8138\n",
            "Epoch 5922/10000\n",
            "768/768 [==============================] - 0s 125us/step - loss: 0.4045 - accuracy: 0.7982\n",
            "Epoch 5923/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4145 - accuracy: 0.7943\n",
            "Epoch 5924/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4017 - accuracy: 0.8164\n",
            "Epoch 5925/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4037 - accuracy: 0.7943\n",
            "Epoch 5926/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4085 - accuracy: 0.8099\n",
            "Epoch 5927/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4069 - accuracy: 0.8138\n",
            "Epoch 5928/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4150 - accuracy: 0.8099\n",
            "Epoch 5929/10000\n",
            "768/768 [==============================] - 0s 132us/step - loss: 0.4039 - accuracy: 0.8073\n",
            "Epoch 5930/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4009 - accuracy: 0.8112\n",
            "Epoch 5931/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4070 - accuracy: 0.8073\n",
            "Epoch 5932/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4012 - accuracy: 0.8138\n",
            "Epoch 5933/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4039 - accuracy: 0.7995\n",
            "Epoch 5934/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4063 - accuracy: 0.8086\n",
            "Epoch 5935/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4036 - accuracy: 0.8125\n",
            "Epoch 5936/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4118 - accuracy: 0.8073\n",
            "Epoch 5937/10000\n",
            "768/768 [==============================] - 0s 110us/step - loss: 0.4044 - accuracy: 0.7969\n",
            "Epoch 5938/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4038 - accuracy: 0.8060\n",
            "Epoch 5939/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4077 - accuracy: 0.8177\n",
            "Epoch 5940/10000\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4072 - accuracy: 0.7995\n",
            "Epoch 5941/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4039 - accuracy: 0.8099\n",
            "Epoch 5942/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4203 - accuracy: 0.8021\n",
            "Epoch 5943/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4078 - accuracy: 0.8073\n",
            "Epoch 5944/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4140 - accuracy: 0.8099\n",
            "Epoch 5945/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4073 - accuracy: 0.8073\n",
            "Epoch 5946/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4272 - accuracy: 0.8047\n",
            "Epoch 5947/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4114 - accuracy: 0.8034\n",
            "Epoch 5948/10000\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4049 - accuracy: 0.7943\n",
            "Epoch 5949/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4015 - accuracy: 0.8151\n",
            "Epoch 5950/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4105 - accuracy: 0.7943\n",
            "Epoch 5951/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4038 - accuracy: 0.8060\n",
            "Epoch 5952/10000\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4027 - accuracy: 0.8125\n",
            "Epoch 5953/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4070 - accuracy: 0.8164\n",
            "Epoch 5954/10000\n",
            "768/768 [==============================] - 0s 110us/step - loss: 0.4154 - accuracy: 0.8073\n",
            "Epoch 5955/10000\n",
            "768/768 [==============================] - 0s 110us/step - loss: 0.4112 - accuracy: 0.7956\n",
            "Epoch 5956/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4137 - accuracy: 0.8047\n",
            "Epoch 5957/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4065 - accuracy: 0.8073\n",
            "Epoch 5958/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4034 - accuracy: 0.8060\n",
            "Epoch 5959/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4133 - accuracy: 0.8086\n",
            "Epoch 5960/10000\n",
            "768/768 [==============================] - 0s 110us/step - loss: 0.4131 - accuracy: 0.7995\n",
            "Epoch 5961/10000\n",
            "768/768 [==============================] - 0s 110us/step - loss: 0.4078 - accuracy: 0.8151\n",
            "Epoch 5962/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4110 - accuracy: 0.8034\n",
            "Epoch 5963/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4100 - accuracy: 0.8086\n",
            "Epoch 5964/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4189 - accuracy: 0.7904\n",
            "Epoch 5965/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4040 - accuracy: 0.8060\n",
            "Epoch 5966/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4163 - accuracy: 0.8034\n",
            "Epoch 5967/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4036 - accuracy: 0.8034\n",
            "Epoch 5968/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4054 - accuracy: 0.8151\n",
            "Epoch 5969/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4088 - accuracy: 0.7982\n",
            "Epoch 5970/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4120 - accuracy: 0.8073\n",
            "Epoch 5971/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4116 - accuracy: 0.7995\n",
            "Epoch 5972/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4171 - accuracy: 0.8008\n",
            "Epoch 5973/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4076 - accuracy: 0.8099\n",
            "Epoch 5974/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4137 - accuracy: 0.7917\n",
            "Epoch 5975/10000\n",
            "768/768 [==============================] - 0s 122us/step - loss: 0.4154 - accuracy: 0.7930\n",
            "Epoch 5976/10000\n",
            "768/768 [==============================] - 0s 110us/step - loss: 0.4103 - accuracy: 0.7995\n",
            "Epoch 5977/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4024 - accuracy: 0.8164\n",
            "Epoch 5978/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4007 - accuracy: 0.8099\n",
            "Epoch 5979/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4125 - accuracy: 0.7943\n",
            "Epoch 5980/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4072 - accuracy: 0.7891\n",
            "Epoch 5981/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4037 - accuracy: 0.8099\n",
            "Epoch 5982/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4095 - accuracy: 0.8112\n",
            "Epoch 5983/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4200 - accuracy: 0.8125\n",
            "Epoch 5984/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4076 - accuracy: 0.8008\n",
            "Epoch 5985/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4222 - accuracy: 0.8021\n",
            "Epoch 5986/10000\n",
            "768/768 [==============================] - 0s 123us/step - loss: 0.4015 - accuracy: 0.8112\n",
            "Epoch 5987/10000\n",
            "768/768 [==============================] - 0s 122us/step - loss: 0.4102 - accuracy: 0.8060\n",
            "Epoch 5988/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4021 - accuracy: 0.8125\n",
            "Epoch 5989/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4061 - accuracy: 0.8034\n",
            "Epoch 5990/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4027 - accuracy: 0.8034\n",
            "Epoch 5991/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4126 - accuracy: 0.7969\n",
            "Epoch 5992/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4026 - accuracy: 0.8086\n",
            "Epoch 5993/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4062 - accuracy: 0.8151\n",
            "Epoch 5994/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4023 - accuracy: 0.8060\n",
            "Epoch 5995/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4290 - accuracy: 0.8086\n",
            "Epoch 5996/10000\n",
            "768/768 [==============================] - 0s 129us/step - loss: 0.4198 - accuracy: 0.8073\n",
            "Epoch 5997/10000\n",
            "768/768 [==============================] - 0s 124us/step - loss: 0.4063 - accuracy: 0.7930\n",
            "Epoch 5998/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4052 - accuracy: 0.8138\n",
            "Epoch 5999/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4067 - accuracy: 0.8047\n",
            "Epoch 6000/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4085 - accuracy: 0.8112\n",
            "Epoch 6001/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4119 - accuracy: 0.8060\n",
            "Epoch 6002/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4093 - accuracy: 0.8099\n",
            "Epoch 6003/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4087 - accuracy: 0.7969\n",
            "Epoch 6004/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4188 - accuracy: 0.7969\n",
            "Epoch 6005/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4084 - accuracy: 0.8034\n",
            "Epoch 6006/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4101 - accuracy: 0.7995\n",
            "Epoch 6007/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4136 - accuracy: 0.7982\n",
            "Epoch 6008/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4066 - accuracy: 0.8008\n",
            "Epoch 6009/10000\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.4112 - accuracy: 0.8060\n",
            "Epoch 6010/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4060 - accuracy: 0.8047\n",
            "Epoch 6011/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4077 - accuracy: 0.8099\n",
            "Epoch 6012/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.3991 - accuracy: 0.8164\n",
            "Epoch 6013/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4066 - accuracy: 0.8125\n",
            "Epoch 6014/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4062 - accuracy: 0.8099\n",
            "Epoch 6015/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4072 - accuracy: 0.8073\n",
            "Epoch 6016/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4091 - accuracy: 0.7982\n",
            "Epoch 6017/10000\n",
            "768/768 [==============================] - 0s 126us/step - loss: 0.4045 - accuracy: 0.8112\n",
            "Epoch 6018/10000\n",
            "768/768 [==============================] - 0s 120us/step - loss: 0.4065 - accuracy: 0.8047\n",
            "Epoch 6019/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4153 - accuracy: 0.8021\n",
            "Epoch 6020/10000\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.4081 - accuracy: 0.8112\n",
            "Epoch 6021/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4034 - accuracy: 0.8060\n",
            "Epoch 6022/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4056 - accuracy: 0.8008\n",
            "Epoch 6023/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4036 - accuracy: 0.8060\n",
            "Epoch 6024/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4117 - accuracy: 0.8008\n",
            "Epoch 6025/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4118 - accuracy: 0.8151\n",
            "Epoch 6026/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4053 - accuracy: 0.8021\n",
            "Epoch 6027/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4081 - accuracy: 0.8138\n",
            "Epoch 6028/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4118 - accuracy: 0.7969\n",
            "Epoch 6029/10000\n",
            "768/768 [==============================] - 0s 120us/step - loss: 0.4130 - accuracy: 0.8034\n",
            "Epoch 6030/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4186 - accuracy: 0.7904\n",
            "Epoch 6031/10000\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.4049 - accuracy: 0.8008\n",
            "Epoch 6032/10000\n",
            "768/768 [==============================] - 0s 134us/step - loss: 0.4031 - accuracy: 0.8073\n",
            "Epoch 6033/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4105 - accuracy: 0.8073\n",
            "Epoch 6034/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4053 - accuracy: 0.8073\n",
            "Epoch 6035/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4055 - accuracy: 0.8086\n",
            "Epoch 6036/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4065 - accuracy: 0.8060\n",
            "Epoch 6037/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4137 - accuracy: 0.8047\n",
            "Epoch 6038/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4101 - accuracy: 0.8060\n",
            "Epoch 6039/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4058 - accuracy: 0.7930\n",
            "Epoch 6040/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4138 - accuracy: 0.7943\n",
            "Epoch 6041/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4099 - accuracy: 0.7956\n",
            "Epoch 6042/10000\n",
            "768/768 [==============================] - 0s 120us/step - loss: 0.4018 - accuracy: 0.8203\n",
            "Epoch 6043/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4006 - accuracy: 0.8034\n",
            "Epoch 6044/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4014 - accuracy: 0.8034\n",
            "Epoch 6045/10000\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4050 - accuracy: 0.8060\n",
            "Epoch 6046/10000\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4058 - accuracy: 0.8151\n",
            "Epoch 6047/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4120 - accuracy: 0.8021\n",
            "Epoch 6048/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4061 - accuracy: 0.8034\n",
            "Epoch 6049/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4172 - accuracy: 0.8138\n",
            "Epoch 6050/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4040 - accuracy: 0.8073\n",
            "Epoch 6051/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4088 - accuracy: 0.8112\n",
            "Epoch 6052/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4033 - accuracy: 0.8047\n",
            "Epoch 6053/10000\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.4079 - accuracy: 0.8034\n",
            "Epoch 6054/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4039 - accuracy: 0.8073\n",
            "Epoch 6055/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4081 - accuracy: 0.8138\n",
            "Epoch 6056/10000\n",
            "768/768 [==============================] - 0s 120us/step - loss: 0.4088 - accuracy: 0.7995\n",
            "Epoch 6057/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4046 - accuracy: 0.8034\n",
            "Epoch 6058/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4053 - accuracy: 0.8151\n",
            "Epoch 6059/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4099 - accuracy: 0.7930\n",
            "Epoch 6060/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4138 - accuracy: 0.7956\n",
            "Epoch 6061/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4136 - accuracy: 0.8138\n",
            "Epoch 6062/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4050 - accuracy: 0.8112\n",
            "Epoch 6063/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4139 - accuracy: 0.7943\n",
            "Epoch 6064/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4031 - accuracy: 0.8086\n",
            "Epoch 6065/10000\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.3989 - accuracy: 0.8112\n",
            "Epoch 6066/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4115 - accuracy: 0.8073\n",
            "Epoch 6067/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4138 - accuracy: 0.8086\n",
            "Epoch 6068/10000\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4054 - accuracy: 0.8151\n",
            "Epoch 6069/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4027 - accuracy: 0.8060\n",
            "Epoch 6070/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4077 - accuracy: 0.8086\n",
            "Epoch 6071/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4091 - accuracy: 0.8164\n",
            "Epoch 6072/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4148 - accuracy: 0.7982\n",
            "Epoch 6073/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4133 - accuracy: 0.7995\n",
            "Epoch 6074/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4026 - accuracy: 0.8151\n",
            "Epoch 6075/10000\n",
            "768/768 [==============================] - 0s 122us/step - loss: 0.4161 - accuracy: 0.7852\n",
            "Epoch 6076/10000\n",
            "768/768 [==============================] - 0s 120us/step - loss: 0.4062 - accuracy: 0.8125\n",
            "Epoch 6077/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4090 - accuracy: 0.8073\n",
            "Epoch 6078/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4101 - accuracy: 0.8138\n",
            "Epoch 6079/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4143 - accuracy: 0.7956\n",
            "Epoch 6080/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4059 - accuracy: 0.7969\n",
            "Epoch 6081/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4034 - accuracy: 0.8099\n",
            "Epoch 6082/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4048 - accuracy: 0.7982\n",
            "Epoch 6083/10000\n",
            "768/768 [==============================] - 0s 127us/step - loss: 0.4099 - accuracy: 0.8034\n",
            "Epoch 6084/10000\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4061 - accuracy: 0.7995\n",
            "Epoch 6085/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4045 - accuracy: 0.8034\n",
            "Epoch 6086/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4111 - accuracy: 0.8060\n",
            "Epoch 6087/10000\n",
            "768/768 [==============================] - 0s 126us/step - loss: 0.4119 - accuracy: 0.8138\n",
            "Epoch 6088/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4021 - accuracy: 0.8034\n",
            "Epoch 6089/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4042 - accuracy: 0.8060\n",
            "Epoch 6090/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4133 - accuracy: 0.7943\n",
            "Epoch 6091/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4096 - accuracy: 0.8073\n",
            "Epoch 6092/10000\n",
            "768/768 [==============================] - 0s 122us/step - loss: 0.4102 - accuracy: 0.8073\n",
            "Epoch 6093/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4089 - accuracy: 0.8047\n",
            "Epoch 6094/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4041 - accuracy: 0.8138\n",
            "Epoch 6095/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4161 - accuracy: 0.8138\n",
            "Epoch 6096/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4123 - accuracy: 0.7969\n",
            "Epoch 6097/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4087 - accuracy: 0.8073\n",
            "Epoch 6098/10000\n",
            "768/768 [==============================] - 0s 122us/step - loss: 0.4179 - accuracy: 0.7982\n",
            "Epoch 6099/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4012 - accuracy: 0.8242\n",
            "Epoch 6100/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4054 - accuracy: 0.8086\n",
            "Epoch 6101/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4074 - accuracy: 0.8073\n",
            "Epoch 6102/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4022 - accuracy: 0.8138\n",
            "Epoch 6103/10000\n",
            "768/768 [==============================] - 0s 125us/step - loss: 0.4099 - accuracy: 0.7956\n",
            "Epoch 6104/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4063 - accuracy: 0.8099\n",
            "Epoch 6105/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4090 - accuracy: 0.8008\n",
            "Epoch 6106/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4146 - accuracy: 0.8008\n",
            "Epoch 6107/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4085 - accuracy: 0.8125\n",
            "Epoch 6108/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4082 - accuracy: 0.8008\n",
            "Epoch 6109/10000\n",
            "768/768 [==============================] - 0s 125us/step - loss: 0.4165 - accuracy: 0.8034\n",
            "Epoch 6110/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4051 - accuracy: 0.8034\n",
            "Epoch 6111/10000\n",
            "768/768 [==============================] - 0s 123us/step - loss: 0.4071 - accuracy: 0.8086\n",
            "Epoch 6112/10000\n",
            "768/768 [==============================] - 0s 123us/step - loss: 0.4128 - accuracy: 0.8060\n",
            "Epoch 6113/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4102 - accuracy: 0.8164\n",
            "Epoch 6114/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4043 - accuracy: 0.8112\n",
            "Epoch 6115/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4045 - accuracy: 0.8034\n",
            "Epoch 6116/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4151 - accuracy: 0.7943\n",
            "Epoch 6117/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4020 - accuracy: 0.8203\n",
            "Epoch 6118/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4127 - accuracy: 0.8034\n",
            "Epoch 6119/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4061 - accuracy: 0.8099\n",
            "Epoch 6120/10000\n",
            "768/768 [==============================] - 0s 127us/step - loss: 0.4049 - accuracy: 0.8099\n",
            "Epoch 6121/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4323 - accuracy: 0.7904\n",
            "Epoch 6122/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4213 - accuracy: 0.7904\n",
            "Epoch 6123/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4074 - accuracy: 0.8138\n",
            "Epoch 6124/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4051 - accuracy: 0.8112\n",
            "Epoch 6125/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4076 - accuracy: 0.8034\n",
            "Epoch 6126/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4045 - accuracy: 0.8021\n",
            "Epoch 6127/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4052 - accuracy: 0.8008\n",
            "Epoch 6128/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4003 - accuracy: 0.8125\n",
            "Epoch 6129/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4095 - accuracy: 0.8099\n",
            "Epoch 6130/10000\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4229 - accuracy: 0.7956\n",
            "Epoch 6131/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4123 - accuracy: 0.8073\n",
            "Epoch 6132/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4088 - accuracy: 0.7982\n",
            "Epoch 6133/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4055 - accuracy: 0.8060\n",
            "Epoch 6134/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4110 - accuracy: 0.8099\n",
            "Epoch 6135/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4037 - accuracy: 0.8034\n",
            "Epoch 6136/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4065 - accuracy: 0.8047\n",
            "Epoch 6137/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4131 - accuracy: 0.7956\n",
            "Epoch 6138/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4074 - accuracy: 0.8060\n",
            "Epoch 6139/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4062 - accuracy: 0.8112\n",
            "Epoch 6140/10000\n",
            "768/768 [==============================] - 0s 110us/step - loss: 0.4058 - accuracy: 0.8099\n",
            "Epoch 6141/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4056 - accuracy: 0.8060\n",
            "Epoch 6142/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4079 - accuracy: 0.8125\n",
            "Epoch 6143/10000\n",
            "768/768 [==============================] - 0s 120us/step - loss: 0.4160 - accuracy: 0.8021\n",
            "Epoch 6144/10000\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4089 - accuracy: 0.8125\n",
            "Epoch 6145/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4131 - accuracy: 0.7917\n",
            "Epoch 6146/10000\n",
            "768/768 [==============================] - 0s 122us/step - loss: 0.4065 - accuracy: 0.8086\n",
            "Epoch 6147/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4075 - accuracy: 0.7995\n",
            "Epoch 6148/10000\n",
            "768/768 [==============================] - 0s 123us/step - loss: 0.4013 - accuracy: 0.8190\n",
            "Epoch 6149/10000\n",
            "768/768 [==============================] - 0s 123us/step - loss: 0.4053 - accuracy: 0.8086\n",
            "Epoch 6150/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4041 - accuracy: 0.8099\n",
            "Epoch 6151/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4003 - accuracy: 0.7995\n",
            "Epoch 6152/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4044 - accuracy: 0.8073\n",
            "Epoch 6153/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4056 - accuracy: 0.8099\n",
            "Epoch 6154/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4088 - accuracy: 0.8021\n",
            "Epoch 6155/10000\n",
            "768/768 [==============================] - 0s 110us/step - loss: 0.4058 - accuracy: 0.8125\n",
            "Epoch 6156/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4070 - accuracy: 0.7995\n",
            "Epoch 6157/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4166 - accuracy: 0.8086\n",
            "Epoch 6158/10000\n",
            "768/768 [==============================] - 0s 110us/step - loss: 0.4072 - accuracy: 0.8034\n",
            "Epoch 6159/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4111 - accuracy: 0.8008\n",
            "Epoch 6160/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4098 - accuracy: 0.8138\n",
            "Epoch 6161/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4175 - accuracy: 0.8099\n",
            "Epoch 6162/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4160 - accuracy: 0.8008\n",
            "Epoch 6163/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4059 - accuracy: 0.8125\n",
            "Epoch 6164/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4111 - accuracy: 0.8047\n",
            "Epoch 6165/10000\n",
            "768/768 [==============================] - 0s 122us/step - loss: 0.4045 - accuracy: 0.8047\n",
            "Epoch 6166/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4137 - accuracy: 0.8021\n",
            "Epoch 6167/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4178 - accuracy: 0.7904\n",
            "Epoch 6168/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4115 - accuracy: 0.7917\n",
            "Epoch 6169/10000\n",
            "768/768 [==============================] - 0s 124us/step - loss: 0.4020 - accuracy: 0.8034\n",
            "Epoch 6170/10000\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.4125 - accuracy: 0.8099\n",
            "Epoch 6171/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4044 - accuracy: 0.8073\n",
            "Epoch 6172/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4064 - accuracy: 0.8021\n",
            "Epoch 6173/10000\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.4066 - accuracy: 0.8034\n",
            "Epoch 6174/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4060 - accuracy: 0.8138\n",
            "Epoch 6175/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4128 - accuracy: 0.8047\n",
            "Epoch 6176/10000\n",
            "768/768 [==============================] - 0s 120us/step - loss: 0.4071 - accuracy: 0.8086\n",
            "Epoch 6177/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4054 - accuracy: 0.8047\n",
            "Epoch 6178/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4181 - accuracy: 0.7982\n",
            "Epoch 6179/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4189 - accuracy: 0.7969\n",
            "Epoch 6180/10000\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4164 - accuracy: 0.7969\n",
            "Epoch 6181/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4048 - accuracy: 0.8138\n",
            "Epoch 6182/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4207 - accuracy: 0.7956\n",
            "Epoch 6183/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4098 - accuracy: 0.7982\n",
            "Epoch 6184/10000\n",
            "768/768 [==============================] - 0s 120us/step - loss: 0.3977 - accuracy: 0.8177\n",
            "Epoch 6185/10000\n",
            "768/768 [==============================] - 0s 110us/step - loss: 0.4047 - accuracy: 0.8112\n",
            "Epoch 6186/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4032 - accuracy: 0.8125\n",
            "Epoch 6187/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4102 - accuracy: 0.7943\n",
            "Epoch 6188/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4028 - accuracy: 0.8034\n",
            "Epoch 6189/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4113 - accuracy: 0.8125\n",
            "Epoch 6190/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4064 - accuracy: 0.8021\n",
            "Epoch 6191/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4136 - accuracy: 0.7995\n",
            "Epoch 6192/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4091 - accuracy: 0.8047\n",
            "Epoch 6193/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4156 - accuracy: 0.8021\n",
            "Epoch 6194/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4064 - accuracy: 0.8060\n",
            "Epoch 6195/10000\n",
            "768/768 [==============================] - 0s 122us/step - loss: 0.4111 - accuracy: 0.7995\n",
            "Epoch 6196/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4050 - accuracy: 0.8060\n",
            "Epoch 6197/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4082 - accuracy: 0.7956\n",
            "Epoch 6198/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4091 - accuracy: 0.8099\n",
            "Epoch 6199/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.3982 - accuracy: 0.8034\n",
            "Epoch 6200/10000\n",
            "768/768 [==============================] - 0s 110us/step - loss: 0.4038 - accuracy: 0.8060\n",
            "Epoch 6201/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4031 - accuracy: 0.8034\n",
            "Epoch 6202/10000\n",
            "768/768 [==============================] - 0s 120us/step - loss: 0.4167 - accuracy: 0.7995\n",
            "Epoch 6203/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4071 - accuracy: 0.8138\n",
            "Epoch 6204/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4098 - accuracy: 0.8047\n",
            "Epoch 6205/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4093 - accuracy: 0.8008\n",
            "Epoch 6206/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4143 - accuracy: 0.8099\n",
            "Epoch 6207/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4181 - accuracy: 0.8008\n",
            "Epoch 6208/10000\n",
            "768/768 [==============================] - 0s 148us/step - loss: 0.4071 - accuracy: 0.8099\n",
            "Epoch 6209/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4020 - accuracy: 0.8060\n",
            "Epoch 6210/10000\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4076 - accuracy: 0.8099\n",
            "Epoch 6211/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4065 - accuracy: 0.8112\n",
            "Epoch 6212/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4024 - accuracy: 0.8112\n",
            "Epoch 6213/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.3996 - accuracy: 0.8047\n",
            "Epoch 6214/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4099 - accuracy: 0.8008\n",
            "Epoch 6215/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4092 - accuracy: 0.8008\n",
            "Epoch 6216/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4176 - accuracy: 0.7995\n",
            "Epoch 6217/10000\n",
            "768/768 [==============================] - 0s 120us/step - loss: 0.4137 - accuracy: 0.8021\n",
            "Epoch 6218/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4045 - accuracy: 0.8151\n",
            "Epoch 6219/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4046 - accuracy: 0.8138\n",
            "Epoch 6220/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4119 - accuracy: 0.7982\n",
            "Epoch 6221/10000\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.4089 - accuracy: 0.7969\n",
            "Epoch 6222/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4178 - accuracy: 0.8125\n",
            "Epoch 6223/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4031 - accuracy: 0.8164\n",
            "Epoch 6224/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4045 - accuracy: 0.8034\n",
            "Epoch 6225/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.3978 - accuracy: 0.8138\n",
            "Epoch 6226/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4030 - accuracy: 0.8047\n",
            "Epoch 6227/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4092 - accuracy: 0.8034\n",
            "Epoch 6228/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4006 - accuracy: 0.8073\n",
            "Epoch 6229/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4122 - accuracy: 0.8034\n",
            "Epoch 6230/10000\n",
            "768/768 [==============================] - 0s 124us/step - loss: 0.4103 - accuracy: 0.8138\n",
            "Epoch 6231/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4123 - accuracy: 0.7969\n",
            "Epoch 6232/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4103 - accuracy: 0.8086\n",
            "Epoch 6233/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4094 - accuracy: 0.8138\n",
            "Epoch 6234/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4032 - accuracy: 0.8151\n",
            "Epoch 6235/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4094 - accuracy: 0.8034\n",
            "Epoch 6236/10000\n",
            "768/768 [==============================] - 0s 120us/step - loss: 0.4191 - accuracy: 0.7969\n",
            "Epoch 6237/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4091 - accuracy: 0.8125\n",
            "Epoch 6238/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4023 - accuracy: 0.8060\n",
            "Epoch 6239/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4094 - accuracy: 0.8021\n",
            "Epoch 6240/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.3991 - accuracy: 0.8125\n",
            "Epoch 6241/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4141 - accuracy: 0.7930\n",
            "Epoch 6242/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4111 - accuracy: 0.8099\n",
            "Epoch 6243/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4045 - accuracy: 0.8047\n",
            "Epoch 6244/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4068 - accuracy: 0.8008\n",
            "Epoch 6245/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4053 - accuracy: 0.8034\n",
            "Epoch 6246/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4098 - accuracy: 0.8008\n",
            "Epoch 6247/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4011 - accuracy: 0.8125\n",
            "Epoch 6248/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4026 - accuracy: 0.8177\n",
            "Epoch 6249/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4084 - accuracy: 0.8008\n",
            "Epoch 6250/10000\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4074 - accuracy: 0.8203\n",
            "Epoch 6251/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4105 - accuracy: 0.8086\n",
            "Epoch 6252/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4087 - accuracy: 0.8073\n",
            "Epoch 6253/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4010 - accuracy: 0.8177\n",
            "Epoch 6254/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4155 - accuracy: 0.7995\n",
            "Epoch 6255/10000\n",
            "768/768 [==============================] - 0s 127us/step - loss: 0.4079 - accuracy: 0.7956\n",
            "Epoch 6256/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4247 - accuracy: 0.7930\n",
            "Epoch 6257/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4053 - accuracy: 0.8177\n",
            "Epoch 6258/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4137 - accuracy: 0.8112\n",
            "Epoch 6259/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.3994 - accuracy: 0.8112\n",
            "Epoch 6260/10000\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4061 - accuracy: 0.7943\n",
            "Epoch 6261/10000\n",
            "768/768 [==============================] - 0s 123us/step - loss: 0.4109 - accuracy: 0.8112\n",
            "Epoch 6262/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4159 - accuracy: 0.7917\n",
            "Epoch 6263/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4164 - accuracy: 0.8008\n",
            "Epoch 6264/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4139 - accuracy: 0.8008\n",
            "Epoch 6265/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4074 - accuracy: 0.8060\n",
            "Epoch 6266/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.3982 - accuracy: 0.8125\n",
            "Epoch 6267/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4135 - accuracy: 0.8112\n",
            "Epoch 6268/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4148 - accuracy: 0.8034\n",
            "Epoch 6269/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4057 - accuracy: 0.8073\n",
            "Epoch 6270/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4044 - accuracy: 0.8073\n",
            "Epoch 6271/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4046 - accuracy: 0.8177\n",
            "Epoch 6272/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4095 - accuracy: 0.7995\n",
            "Epoch 6273/10000\n",
            "768/768 [==============================] - 0s 121us/step - loss: 0.4225 - accuracy: 0.7982\n",
            "Epoch 6274/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4042 - accuracy: 0.8112\n",
            "Epoch 6275/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4033 - accuracy: 0.8060\n",
            "Epoch 6276/10000\n",
            "768/768 [==============================] - 0s 110us/step - loss: 0.4005 - accuracy: 0.8034\n",
            "Epoch 6277/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4073 - accuracy: 0.8008\n",
            "Epoch 6278/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4052 - accuracy: 0.8060\n",
            "Epoch 6279/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4202 - accuracy: 0.7982\n",
            "Epoch 6280/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.3955 - accuracy: 0.8034\n",
            "Epoch 6281/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4092 - accuracy: 0.7943\n",
            "Epoch 6282/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4031 - accuracy: 0.8164\n",
            "Epoch 6283/10000\n",
            "768/768 [==============================] - 0s 111us/step - loss: 0.4037 - accuracy: 0.8060\n",
            "Epoch 6284/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4025 - accuracy: 0.8138\n",
            "Epoch 6285/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4154 - accuracy: 0.8008\n",
            "Epoch 6286/10000\n",
            "768/768 [==============================] - 0s 122us/step - loss: 0.4059 - accuracy: 0.8086\n",
            "Epoch 6287/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4053 - accuracy: 0.8112\n",
            "Epoch 6288/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4063 - accuracy: 0.8125\n",
            "Epoch 6289/10000\n",
            "768/768 [==============================] - 0s 123us/step - loss: 0.4053 - accuracy: 0.8073\n",
            "Epoch 6290/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4089 - accuracy: 0.8112\n",
            "Epoch 6291/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4033 - accuracy: 0.8099\n",
            "Epoch 6292/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4028 - accuracy: 0.8060\n",
            "Epoch 6293/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4005 - accuracy: 0.8164\n",
            "Epoch 6294/10000\n",
            "768/768 [==============================] - 0s 123us/step - loss: 0.4022 - accuracy: 0.8125\n",
            "Epoch 6295/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4314 - accuracy: 0.7943\n",
            "Epoch 6296/10000\n",
            "768/768 [==============================] - 0s 112us/step - loss: 0.4121 - accuracy: 0.8125\n",
            "Epoch 6297/10000\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4110 - accuracy: 0.7917\n",
            "Epoch 6298/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4067 - accuracy: 0.8060\n",
            "Epoch 6299/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4000 - accuracy: 0.8099\n",
            "Epoch 6300/10000\n",
            "768/768 [==============================] - 0s 132us/step - loss: 0.4023 - accuracy: 0.8060\n",
            "Epoch 6301/10000\n",
            "768/768 [==============================] - 0s 120us/step - loss: 0.4107 - accuracy: 0.8060\n",
            "Epoch 6302/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4044 - accuracy: 0.8060\n",
            "Epoch 6303/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4060 - accuracy: 0.8060\n",
            "Epoch 6304/10000\n",
            "768/768 [==============================] - 0s 114us/step - loss: 0.4111 - accuracy: 0.7969\n",
            "Epoch 6305/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4037 - accuracy: 0.8073\n",
            "Epoch 6306/10000\n",
            "768/768 [==============================] - 0s 118us/step - loss: 0.4069 - accuracy: 0.8164\n",
            "Epoch 6307/10000\n",
            "768/768 [==============================] - 0s 115us/step - loss: 0.4093 - accuracy: 0.8034\n",
            "Epoch 6308/10000\n",
            "768/768 [==============================] - 0s 117us/step - loss: 0.4205 - accuracy: 0.7969\n",
            "Epoch 6309/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4068 - accuracy: 0.8073\n",
            "Epoch 6310/10000\n",
            "768/768 [==============================] - 0s 113us/step - loss: 0.4066 - accuracy: 0.8086\n",
            "Epoch 6311/10000\n",
            "768/768 [==============================] - 0s 119us/step - loss: 0.4068 - accuracy: 0.7930\n",
            "Epoch 6312/10000\n",
            "768/768 [==============================] - 0s 116us/step - loss: 0.4119 - accuracy: 0.8112\n",
            "Epoch 6313/10000\n",
            " 10/768 [..............................] - ETA: 0s - loss: 0.3393 - accuracy: 0.9000"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWvyMEoFT7Y5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdhWM64IIC2k"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NjSRqBuEIDIx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBjnh3JoHSBO"
      },
      "source": [
        "# Chapter 8.\n",
        "\n",
        "\n",
        "# Evaluate The Performance of Deep Learning Models\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLB-TfjBNue9"
      },
      "source": [
        "**Using a Automatic Validation Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-BdzjpsT7eX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6f800cc3-e949-4e82-db90-8c5e730e6bed"
      },
      "source": [
        "#MLP with automatic validation set\n",
        "\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#fix random seed for reproducibility\n",
        "seed = 7\n",
        "np.random.seed(seed)\n",
        "\n",
        "#load pima indian dataset\n",
        "dataset = pd.read_csv(\"/content/datasets_228_482_diabetes.csv\")\n",
        "\n",
        "#Split the dataset into varibales X and Y\n",
        "X = dataset.iloc[:, :8]\n",
        "Y = dataset.iloc[:, 8]\n",
        "\n",
        "#Create-Define Model \n",
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim = 8, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "model.add(Dense(8, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "model.add(Dense(1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
        "\n",
        "\n",
        "#Compile the model \n",
        "model.compile(loss='binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "\n",
        "#Fit the model\n",
        "model.fit(X, Y, validation_split = 0.33, epochs = 150, batch_size=10)\n",
        "\n",
        "#Evaluate the model\n",
        "scores = model.evaluate(X, Y)\n",
        "print(model.metrics_names[1], scores[1]*100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 514 samples, validate on 254 samples\n",
            "Epoch 1/150\n",
            "514/514 [==============================] - 1s 1ms/step - loss: 0.6815 - accuracy: 0.6401 - val_loss: 0.6609 - val_accuracy: 0.6732\n",
            "Epoch 2/150\n",
            "514/514 [==============================] - 0s 183us/step - loss: 0.6705 - accuracy: 0.6401 - val_loss: 0.6563 - val_accuracy: 0.6732\n",
            "Epoch 3/150\n",
            "514/514 [==============================] - 0s 188us/step - loss: 0.6659 - accuracy: 0.6401 - val_loss: 0.6552 - val_accuracy: 0.6732\n",
            "Epoch 4/150\n",
            "514/514 [==============================] - 0s 190us/step - loss: 0.6609 - accuracy: 0.6401 - val_loss: 0.6523 - val_accuracy: 0.6732\n",
            "Epoch 5/150\n",
            "514/514 [==============================] - 0s 191us/step - loss: 0.6550 - accuracy: 0.6401 - val_loss: 0.6470 - val_accuracy: 0.6732\n",
            "Epoch 6/150\n",
            "514/514 [==============================] - 0s 211us/step - loss: 0.6526 - accuracy: 0.6401 - val_loss: 0.6435 - val_accuracy: 0.6732\n",
            "Epoch 7/150\n",
            "514/514 [==============================] - 0s 178us/step - loss: 0.6476 - accuracy: 0.6401 - val_loss: 0.6411 - val_accuracy: 0.6732\n",
            "Epoch 8/150\n",
            "514/514 [==============================] - 0s 190us/step - loss: 0.6418 - accuracy: 0.6401 - val_loss: 0.6327 - val_accuracy: 0.6732\n",
            "Epoch 9/150\n",
            "514/514 [==============================] - 0s 176us/step - loss: 0.6368 - accuracy: 0.6401 - val_loss: 0.6264 - val_accuracy: 0.6732\n",
            "Epoch 10/150\n",
            "514/514 [==============================] - 0s 175us/step - loss: 0.6314 - accuracy: 0.6401 - val_loss: 0.6167 - val_accuracy: 0.6811\n",
            "Epoch 11/150\n",
            "514/514 [==============================] - 0s 177us/step - loss: 0.6261 - accuracy: 0.6654 - val_loss: 0.6136 - val_accuracy: 0.6890\n",
            "Epoch 12/150\n",
            "514/514 [==============================] - 0s 172us/step - loss: 0.6247 - accuracy: 0.6848 - val_loss: 0.5980 - val_accuracy: 0.6890\n",
            "Epoch 13/150\n",
            "514/514 [==============================] - 0s 180us/step - loss: 0.6195 - accuracy: 0.6809 - val_loss: 0.5930 - val_accuracy: 0.6969\n",
            "Epoch 14/150\n",
            "514/514 [==============================] - 0s 174us/step - loss: 0.6130 - accuracy: 0.6634 - val_loss: 0.5896 - val_accuracy: 0.6969\n",
            "Epoch 15/150\n",
            "514/514 [==============================] - 0s 178us/step - loss: 0.6083 - accuracy: 0.6770 - val_loss: 0.5867 - val_accuracy: 0.7008\n",
            "Epoch 16/150\n",
            "514/514 [==============================] - 0s 196us/step - loss: 0.6151 - accuracy: 0.6693 - val_loss: 0.5817 - val_accuracy: 0.7126\n",
            "Epoch 17/150\n",
            "514/514 [==============================] - 0s 199us/step - loss: 0.6119 - accuracy: 0.6712 - val_loss: 0.5795 - val_accuracy: 0.6890\n",
            "Epoch 18/150\n",
            "514/514 [==============================] - 0s 233us/step - loss: 0.6022 - accuracy: 0.6946 - val_loss: 0.5789 - val_accuracy: 0.7126\n",
            "Epoch 19/150\n",
            "514/514 [==============================] - 0s 196us/step - loss: 0.6130 - accuracy: 0.6751 - val_loss: 0.5778 - val_accuracy: 0.7087\n",
            "Epoch 20/150\n",
            "514/514 [==============================] - 0s 192us/step - loss: 0.6054 - accuracy: 0.6984 - val_loss: 0.5778 - val_accuracy: 0.6969\n",
            "Epoch 21/150\n",
            "514/514 [==============================] - 0s 198us/step - loss: 0.6009 - accuracy: 0.6946 - val_loss: 0.5737 - val_accuracy: 0.7205\n",
            "Epoch 22/150\n",
            "514/514 [==============================] - 0s 200us/step - loss: 0.5967 - accuracy: 0.6984 - val_loss: 0.5736 - val_accuracy: 0.7402\n",
            "Epoch 23/150\n",
            "514/514 [==============================] - 0s 198us/step - loss: 0.5984 - accuracy: 0.6829 - val_loss: 0.5719 - val_accuracy: 0.7205\n",
            "Epoch 24/150\n",
            "514/514 [==============================] - 0s 207us/step - loss: 0.5910 - accuracy: 0.6848 - val_loss: 0.5709 - val_accuracy: 0.7008\n",
            "Epoch 25/150\n",
            "514/514 [==============================] - 0s 198us/step - loss: 0.5947 - accuracy: 0.7004 - val_loss: 0.5699 - val_accuracy: 0.6929\n",
            "Epoch 26/150\n",
            "514/514 [==============================] - 0s 202us/step - loss: 0.5926 - accuracy: 0.6907 - val_loss: 0.5749 - val_accuracy: 0.7008\n",
            "Epoch 27/150\n",
            "514/514 [==============================] - 0s 201us/step - loss: 0.5886 - accuracy: 0.7140 - val_loss: 0.5773 - val_accuracy: 0.6969\n",
            "Epoch 28/150\n",
            "514/514 [==============================] - 0s 200us/step - loss: 0.5912 - accuracy: 0.7062 - val_loss: 0.6603 - val_accuracy: 0.5630\n",
            "Epoch 29/150\n",
            "514/514 [==============================] - 0s 212us/step - loss: 0.5955 - accuracy: 0.6848 - val_loss: 0.5806 - val_accuracy: 0.7008\n",
            "Epoch 30/150\n",
            "514/514 [==============================] - 0s 196us/step - loss: 0.5926 - accuracy: 0.6946 - val_loss: 0.5734 - val_accuracy: 0.7008\n",
            "Epoch 31/150\n",
            "514/514 [==============================] - 0s 202us/step - loss: 0.5889 - accuracy: 0.6926 - val_loss: 0.5621 - val_accuracy: 0.7205\n",
            "Epoch 32/150\n",
            "514/514 [==============================] - 0s 204us/step - loss: 0.5976 - accuracy: 0.6868 - val_loss: 0.5791 - val_accuracy: 0.7165\n",
            "Epoch 33/150\n",
            "514/514 [==============================] - 0s 192us/step - loss: 0.5917 - accuracy: 0.6926 - val_loss: 0.5701 - val_accuracy: 0.7087\n",
            "Epoch 34/150\n",
            "514/514 [==============================] - 0s 197us/step - loss: 0.5847 - accuracy: 0.7179 - val_loss: 0.5630 - val_accuracy: 0.7205\n",
            "Epoch 35/150\n",
            "514/514 [==============================] - 0s 213us/step - loss: 0.5843 - accuracy: 0.7101 - val_loss: 0.5640 - val_accuracy: 0.7047\n",
            "Epoch 36/150\n",
            "514/514 [==============================] - 0s 227us/step - loss: 0.5855 - accuracy: 0.7160 - val_loss: 0.5589 - val_accuracy: 0.7087\n",
            "Epoch 37/150\n",
            "514/514 [==============================] - 0s 207us/step - loss: 0.5817 - accuracy: 0.7062 - val_loss: 0.5662 - val_accuracy: 0.6969\n",
            "Epoch 38/150\n",
            "514/514 [==============================] - 0s 203us/step - loss: 0.5825 - accuracy: 0.7218 - val_loss: 0.5593 - val_accuracy: 0.7087\n",
            "Epoch 39/150\n",
            "514/514 [==============================] - 0s 200us/step - loss: 0.5883 - accuracy: 0.6809 - val_loss: 0.5588 - val_accuracy: 0.7283\n",
            "Epoch 40/150\n",
            "514/514 [==============================] - 0s 196us/step - loss: 0.5785 - accuracy: 0.7257 - val_loss: 0.5552 - val_accuracy: 0.7244\n",
            "Epoch 41/150\n",
            "514/514 [==============================] - 0s 211us/step - loss: 0.5828 - accuracy: 0.7140 - val_loss: 0.5555 - val_accuracy: 0.7205\n",
            "Epoch 42/150\n",
            "514/514 [==============================] - 0s 204us/step - loss: 0.5817 - accuracy: 0.7023 - val_loss: 0.5671 - val_accuracy: 0.6969\n",
            "Epoch 43/150\n",
            "514/514 [==============================] - 0s 203us/step - loss: 0.5832 - accuracy: 0.7043 - val_loss: 0.5557 - val_accuracy: 0.7126\n",
            "Epoch 44/150\n",
            "514/514 [==============================] - 0s 220us/step - loss: 0.5764 - accuracy: 0.7062 - val_loss: 0.5523 - val_accuracy: 0.7165\n",
            "Epoch 45/150\n",
            "514/514 [==============================] - 0s 203us/step - loss: 0.5767 - accuracy: 0.7160 - val_loss: 0.5740 - val_accuracy: 0.6929\n",
            "Epoch 46/150\n",
            "514/514 [==============================] - 0s 208us/step - loss: 0.5795 - accuracy: 0.7140 - val_loss: 0.5527 - val_accuracy: 0.7205\n",
            "Epoch 47/150\n",
            "514/514 [==============================] - 0s 205us/step - loss: 0.5778 - accuracy: 0.7023 - val_loss: 0.5731 - val_accuracy: 0.6969\n",
            "Epoch 48/150\n",
            "514/514 [==============================] - 0s 200us/step - loss: 0.5770 - accuracy: 0.7101 - val_loss: 0.5549 - val_accuracy: 0.7008\n",
            "Epoch 49/150\n",
            "514/514 [==============================] - 0s 200us/step - loss: 0.5751 - accuracy: 0.7121 - val_loss: 0.5503 - val_accuracy: 0.7087\n",
            "Epoch 50/150\n",
            "514/514 [==============================] - 0s 195us/step - loss: 0.5725 - accuracy: 0.7160 - val_loss: 0.5556 - val_accuracy: 0.7165\n",
            "Epoch 51/150\n",
            "514/514 [==============================] - 0s 206us/step - loss: 0.5691 - accuracy: 0.7315 - val_loss: 0.5507 - val_accuracy: 0.7205\n",
            "Epoch 52/150\n",
            "514/514 [==============================] - 0s 229us/step - loss: 0.5741 - accuracy: 0.7218 - val_loss: 0.5516 - val_accuracy: 0.7126\n",
            "Epoch 53/150\n",
            "514/514 [==============================] - 0s 210us/step - loss: 0.5674 - accuracy: 0.7198 - val_loss: 0.5504 - val_accuracy: 0.7165\n",
            "Epoch 54/150\n",
            "514/514 [==============================] - 0s 198us/step - loss: 0.5667 - accuracy: 0.7160 - val_loss: 0.5523 - val_accuracy: 0.7047\n",
            "Epoch 55/150\n",
            "514/514 [==============================] - 0s 202us/step - loss: 0.5664 - accuracy: 0.7140 - val_loss: 0.5492 - val_accuracy: 0.7126\n",
            "Epoch 56/150\n",
            "514/514 [==============================] - 0s 206us/step - loss: 0.5649 - accuracy: 0.7179 - val_loss: 0.5631 - val_accuracy: 0.7244\n",
            "Epoch 57/150\n",
            "514/514 [==============================] - 0s 219us/step - loss: 0.5680 - accuracy: 0.7082 - val_loss: 0.5621 - val_accuracy: 0.7165\n",
            "Epoch 58/150\n",
            "514/514 [==============================] - 0s 191us/step - loss: 0.5664 - accuracy: 0.7160 - val_loss: 0.5514 - val_accuracy: 0.7087\n",
            "Epoch 59/150\n",
            "514/514 [==============================] - 0s 197us/step - loss: 0.5630 - accuracy: 0.7160 - val_loss: 0.5462 - val_accuracy: 0.7244\n",
            "Epoch 60/150\n",
            "514/514 [==============================] - 0s 189us/step - loss: 0.5641 - accuracy: 0.7198 - val_loss: 0.5505 - val_accuracy: 0.7283\n",
            "Epoch 61/150\n",
            "514/514 [==============================] - 0s 214us/step - loss: 0.5602 - accuracy: 0.7257 - val_loss: 0.5598 - val_accuracy: 0.7087\n",
            "Epoch 62/150\n",
            "514/514 [==============================] - 0s 193us/step - loss: 0.5676 - accuracy: 0.7140 - val_loss: 0.5538 - val_accuracy: 0.7165\n",
            "Epoch 63/150\n",
            "514/514 [==============================] - 0s 188us/step - loss: 0.5615 - accuracy: 0.7237 - val_loss: 0.5496 - val_accuracy: 0.7244\n",
            "Epoch 64/150\n",
            "514/514 [==============================] - 0s 228us/step - loss: 0.5602 - accuracy: 0.7237 - val_loss: 0.5422 - val_accuracy: 0.7323\n",
            "Epoch 65/150\n",
            "514/514 [==============================] - 0s 205us/step - loss: 0.5586 - accuracy: 0.7160 - val_loss: 0.5488 - val_accuracy: 0.7165\n",
            "Epoch 66/150\n",
            "514/514 [==============================] - 0s 197us/step - loss: 0.5579 - accuracy: 0.7315 - val_loss: 0.5484 - val_accuracy: 0.7205\n",
            "Epoch 67/150\n",
            "514/514 [==============================] - 0s 196us/step - loss: 0.5597 - accuracy: 0.7160 - val_loss: 0.5510 - val_accuracy: 0.7165\n",
            "Epoch 68/150\n",
            "514/514 [==============================] - 0s 199us/step - loss: 0.5593 - accuracy: 0.7140 - val_loss: 0.5662 - val_accuracy: 0.7087\n",
            "Epoch 69/150\n",
            "514/514 [==============================] - 0s 212us/step - loss: 0.5543 - accuracy: 0.7296 - val_loss: 0.5473 - val_accuracy: 0.7126\n",
            "Epoch 70/150\n",
            "514/514 [==============================] - 0s 197us/step - loss: 0.5585 - accuracy: 0.7198 - val_loss: 0.5419 - val_accuracy: 0.7126\n",
            "Epoch 71/150\n",
            "514/514 [==============================] - 0s 199us/step - loss: 0.5495 - accuracy: 0.7315 - val_loss: 0.5483 - val_accuracy: 0.7244\n",
            "Epoch 72/150\n",
            "514/514 [==============================] - 0s 193us/step - loss: 0.5478 - accuracy: 0.7218 - val_loss: 0.5412 - val_accuracy: 0.7244\n",
            "Epoch 73/150\n",
            "514/514 [==============================] - 0s 195us/step - loss: 0.5509 - accuracy: 0.7315 - val_loss: 0.5393 - val_accuracy: 0.7283\n",
            "Epoch 74/150\n",
            "514/514 [==============================] - 0s 219us/step - loss: 0.5427 - accuracy: 0.7354 - val_loss: 0.5422 - val_accuracy: 0.7126\n",
            "Epoch 75/150\n",
            "514/514 [==============================] - 0s 202us/step - loss: 0.5489 - accuracy: 0.7335 - val_loss: 0.5403 - val_accuracy: 0.7283\n",
            "Epoch 76/150\n",
            "514/514 [==============================] - 0s 226us/step - loss: 0.5463 - accuracy: 0.7412 - val_loss: 0.5413 - val_accuracy: 0.7165\n",
            "Epoch 77/150\n",
            "514/514 [==============================] - 0s 218us/step - loss: 0.5403 - accuracy: 0.7237 - val_loss: 0.5382 - val_accuracy: 0.7205\n",
            "Epoch 78/150\n",
            "514/514 [==============================] - 0s 204us/step - loss: 0.5398 - accuracy: 0.7296 - val_loss: 0.5380 - val_accuracy: 0.7362\n",
            "Epoch 79/150\n",
            "514/514 [==============================] - 0s 206us/step - loss: 0.5367 - accuracy: 0.7374 - val_loss: 0.5454 - val_accuracy: 0.7480\n",
            "Epoch 80/150\n",
            "514/514 [==============================] - 0s 196us/step - loss: 0.5369 - accuracy: 0.7451 - val_loss: 0.5398 - val_accuracy: 0.7165\n",
            "Epoch 81/150\n",
            "514/514 [==============================] - 0s 194us/step - loss: 0.5383 - accuracy: 0.7315 - val_loss: 0.5432 - val_accuracy: 0.7205\n",
            "Epoch 82/150\n",
            "514/514 [==============================] - 0s 201us/step - loss: 0.5300 - accuracy: 0.7354 - val_loss: 0.5356 - val_accuracy: 0.7323\n",
            "Epoch 83/150\n",
            "514/514 [==============================] - 0s 207us/step - loss: 0.5287 - accuracy: 0.7393 - val_loss: 0.5391 - val_accuracy: 0.7165\n",
            "Epoch 84/150\n",
            "514/514 [==============================] - 0s 206us/step - loss: 0.5315 - accuracy: 0.7451 - val_loss: 0.5381 - val_accuracy: 0.7165\n",
            "Epoch 85/150\n",
            "514/514 [==============================] - 0s 200us/step - loss: 0.5277 - accuracy: 0.7432 - val_loss: 0.5345 - val_accuracy: 0.7362\n",
            "Epoch 86/150\n",
            "514/514 [==============================] - 0s 206us/step - loss: 0.5275 - accuracy: 0.7276 - val_loss: 0.5432 - val_accuracy: 0.7520\n",
            "Epoch 87/150\n",
            "514/514 [==============================] - 0s 199us/step - loss: 0.5263 - accuracy: 0.7451 - val_loss: 0.5335 - val_accuracy: 0.7323\n",
            "Epoch 88/150\n",
            "514/514 [==============================] - 0s 185us/step - loss: 0.5222 - accuracy: 0.7510 - val_loss: 0.5367 - val_accuracy: 0.7638\n",
            "Epoch 89/150\n",
            "514/514 [==============================] - 0s 202us/step - loss: 0.5245 - accuracy: 0.7432 - val_loss: 0.5335 - val_accuracy: 0.7126\n",
            "Epoch 90/150\n",
            "514/514 [==============================] - 0s 199us/step - loss: 0.5261 - accuracy: 0.7529 - val_loss: 0.5347 - val_accuracy: 0.7205\n",
            "Epoch 91/150\n",
            "514/514 [==============================] - 0s 200us/step - loss: 0.5234 - accuracy: 0.7432 - val_loss: 0.5373 - val_accuracy: 0.7323\n",
            "Epoch 92/150\n",
            "514/514 [==============================] - 0s 195us/step - loss: 0.5259 - accuracy: 0.7432 - val_loss: 0.5336 - val_accuracy: 0.7362\n",
            "Epoch 93/150\n",
            "514/514 [==============================] - 0s 209us/step - loss: 0.5166 - accuracy: 0.7549 - val_loss: 0.5313 - val_accuracy: 0.7441\n",
            "Epoch 94/150\n",
            "514/514 [==============================] - 0s 204us/step - loss: 0.5265 - accuracy: 0.7451 - val_loss: 0.5320 - val_accuracy: 0.7480\n",
            "Epoch 95/150\n",
            "514/514 [==============================] - 0s 188us/step - loss: 0.5221 - accuracy: 0.7607 - val_loss: 0.5500 - val_accuracy: 0.6929\n",
            "Epoch 96/150\n",
            "514/514 [==============================] - 0s 190us/step - loss: 0.5232 - accuracy: 0.7510 - val_loss: 0.5407 - val_accuracy: 0.7283\n",
            "Epoch 97/150\n",
            "514/514 [==============================] - 0s 200us/step - loss: 0.5177 - accuracy: 0.7607 - val_loss: 0.5345 - val_accuracy: 0.7362\n",
            "Epoch 98/150\n",
            "514/514 [==============================] - 0s 205us/step - loss: 0.5247 - accuracy: 0.7412 - val_loss: 0.5351 - val_accuracy: 0.7402\n",
            "Epoch 99/150\n",
            "514/514 [==============================] - 0s 190us/step - loss: 0.5245 - accuracy: 0.7490 - val_loss: 0.5341 - val_accuracy: 0.7283\n",
            "Epoch 100/150\n",
            "514/514 [==============================] - 0s 198us/step - loss: 0.5145 - accuracy: 0.7529 - val_loss: 0.5272 - val_accuracy: 0.7480\n",
            "Epoch 101/150\n",
            "514/514 [==============================] - 0s 187us/step - loss: 0.5146 - accuracy: 0.7529 - val_loss: 0.5304 - val_accuracy: 0.7402\n",
            "Epoch 102/150\n",
            "514/514 [==============================] - 0s 189us/step - loss: 0.5147 - accuracy: 0.7685 - val_loss: 0.5296 - val_accuracy: 0.7520\n",
            "Epoch 103/150\n",
            "514/514 [==============================] - 0s 226us/step - loss: 0.5137 - accuracy: 0.7529 - val_loss: 0.5718 - val_accuracy: 0.6929\n",
            "Epoch 104/150\n",
            "514/514 [==============================] - 0s 194us/step - loss: 0.5193 - accuracy: 0.7588 - val_loss: 0.5277 - val_accuracy: 0.7598\n",
            "Epoch 105/150\n",
            "514/514 [==============================] - 0s 205us/step - loss: 0.5067 - accuracy: 0.7646 - val_loss: 0.5298 - val_accuracy: 0.7362\n",
            "Epoch 106/150\n",
            "514/514 [==============================] - 0s 196us/step - loss: 0.5145 - accuracy: 0.7335 - val_loss: 0.5257 - val_accuracy: 0.7520\n",
            "Epoch 107/150\n",
            "514/514 [==============================] - 0s 218us/step - loss: 0.5125 - accuracy: 0.7724 - val_loss: 0.5321 - val_accuracy: 0.7598\n",
            "Epoch 108/150\n",
            "514/514 [==============================] - 0s 216us/step - loss: 0.5121 - accuracy: 0.7607 - val_loss: 0.5306 - val_accuracy: 0.7638\n",
            "Epoch 109/150\n",
            "514/514 [==============================] - 0s 193us/step - loss: 0.5108 - accuracy: 0.7588 - val_loss: 0.5325 - val_accuracy: 0.7441\n",
            "Epoch 110/150\n",
            "514/514 [==============================] - 0s 185us/step - loss: 0.4987 - accuracy: 0.7743 - val_loss: 0.5451 - val_accuracy: 0.7480\n",
            "Epoch 111/150\n",
            "514/514 [==============================] - 0s 240us/step - loss: 0.5145 - accuracy: 0.7743 - val_loss: 0.5295 - val_accuracy: 0.7638\n",
            "Epoch 112/150\n",
            "514/514 [==============================] - 0s 225us/step - loss: 0.5028 - accuracy: 0.7626 - val_loss: 0.5307 - val_accuracy: 0.7480\n",
            "Epoch 113/150\n",
            "514/514 [==============================] - 0s 198us/step - loss: 0.5058 - accuracy: 0.7626 - val_loss: 0.5371 - val_accuracy: 0.7244\n",
            "Epoch 114/150\n",
            "514/514 [==============================] - 0s 174us/step - loss: 0.5019 - accuracy: 0.7529 - val_loss: 0.5352 - val_accuracy: 0.7244\n",
            "Epoch 115/150\n",
            "514/514 [==============================] - 0s 184us/step - loss: 0.5049 - accuracy: 0.7665 - val_loss: 0.5362 - val_accuracy: 0.7520\n",
            "Epoch 116/150\n",
            "514/514 [==============================] - 0s 188us/step - loss: 0.5044 - accuracy: 0.7607 - val_loss: 0.5268 - val_accuracy: 0.7717\n",
            "Epoch 117/150\n",
            "514/514 [==============================] - 0s 174us/step - loss: 0.5068 - accuracy: 0.7549 - val_loss: 0.5470 - val_accuracy: 0.7441\n",
            "Epoch 118/150\n",
            "514/514 [==============================] - 0s 183us/step - loss: 0.4965 - accuracy: 0.7626 - val_loss: 0.5352 - val_accuracy: 0.7520\n",
            "Epoch 119/150\n",
            "514/514 [==============================] - 0s 217us/step - loss: 0.5076 - accuracy: 0.7510 - val_loss: 0.5469 - val_accuracy: 0.7402\n",
            "Epoch 120/150\n",
            "514/514 [==============================] - 0s 172us/step - loss: 0.5053 - accuracy: 0.7626 - val_loss: 0.5242 - val_accuracy: 0.7598\n",
            "Epoch 121/150\n",
            "514/514 [==============================] - 0s 180us/step - loss: 0.4964 - accuracy: 0.7529 - val_loss: 0.5373 - val_accuracy: 0.7480\n",
            "Epoch 122/150\n",
            "514/514 [==============================] - 0s 189us/step - loss: 0.4993 - accuracy: 0.7471 - val_loss: 0.5309 - val_accuracy: 0.7520\n",
            "Epoch 123/150\n",
            "514/514 [==============================] - 0s 182us/step - loss: 0.4999 - accuracy: 0.7607 - val_loss: 0.5591 - val_accuracy: 0.7244\n",
            "Epoch 124/150\n",
            "514/514 [==============================] - 0s 190us/step - loss: 0.4950 - accuracy: 0.7685 - val_loss: 0.5233 - val_accuracy: 0.7598\n",
            "Epoch 125/150\n",
            "514/514 [==============================] - 0s 177us/step - loss: 0.4963 - accuracy: 0.7665 - val_loss: 0.5294 - val_accuracy: 0.7598\n",
            "Epoch 126/150\n",
            "514/514 [==============================] - 0s 180us/step - loss: 0.4874 - accuracy: 0.7568 - val_loss: 0.5533 - val_accuracy: 0.7402\n",
            "Epoch 127/150\n",
            "514/514 [==============================] - 0s 183us/step - loss: 0.4899 - accuracy: 0.7665 - val_loss: 0.5379 - val_accuracy: 0.7677\n",
            "Epoch 128/150\n",
            "514/514 [==============================] - 0s 179us/step - loss: 0.4921 - accuracy: 0.7646 - val_loss: 0.5522 - val_accuracy: 0.7402\n",
            "Epoch 129/150\n",
            "514/514 [==============================] - 0s 187us/step - loss: 0.4954 - accuracy: 0.7568 - val_loss: 0.5237 - val_accuracy: 0.7441\n",
            "Epoch 130/150\n",
            "514/514 [==============================] - 0s 179us/step - loss: 0.4968 - accuracy: 0.7529 - val_loss: 0.5308 - val_accuracy: 0.7520\n",
            "Epoch 131/150\n",
            "514/514 [==============================] - 0s 169us/step - loss: 0.4832 - accuracy: 0.7802 - val_loss: 0.5303 - val_accuracy: 0.7520\n",
            "Epoch 132/150\n",
            "514/514 [==============================] - 0s 182us/step - loss: 0.4977 - accuracy: 0.7626 - val_loss: 0.5444 - val_accuracy: 0.7559\n",
            "Epoch 133/150\n",
            "514/514 [==============================] - 0s 203us/step - loss: 0.4850 - accuracy: 0.7763 - val_loss: 0.5229 - val_accuracy: 0.7520\n",
            "Epoch 134/150\n",
            "514/514 [==============================] - 0s 182us/step - loss: 0.4835 - accuracy: 0.7665 - val_loss: 0.5291 - val_accuracy: 0.7638\n",
            "Epoch 135/150\n",
            "514/514 [==============================] - 0s 173us/step - loss: 0.4937 - accuracy: 0.7588 - val_loss: 0.5307 - val_accuracy: 0.7559\n",
            "Epoch 136/150\n",
            "514/514 [==============================] - 0s 172us/step - loss: 0.4905 - accuracy: 0.7704 - val_loss: 0.5266 - val_accuracy: 0.7520\n",
            "Epoch 137/150\n",
            "514/514 [==============================] - 0s 179us/step - loss: 0.4939 - accuracy: 0.7646 - val_loss: 0.5281 - val_accuracy: 0.7480\n",
            "Epoch 138/150\n",
            "514/514 [==============================] - 0s 173us/step - loss: 0.4864 - accuracy: 0.7782 - val_loss: 0.5290 - val_accuracy: 0.7677\n",
            "Epoch 139/150\n",
            "514/514 [==============================] - 0s 173us/step - loss: 0.4883 - accuracy: 0.7665 - val_loss: 0.5403 - val_accuracy: 0.7559\n",
            "Epoch 140/150\n",
            "514/514 [==============================] - 0s 180us/step - loss: 0.4794 - accuracy: 0.7724 - val_loss: 0.5260 - val_accuracy: 0.7559\n",
            "Epoch 141/150\n",
            "514/514 [==============================] - 0s 175us/step - loss: 0.4805 - accuracy: 0.7724 - val_loss: 0.5277 - val_accuracy: 0.7520\n",
            "Epoch 142/150\n",
            "514/514 [==============================] - 0s 172us/step - loss: 0.4783 - accuracy: 0.7626 - val_loss: 0.5253 - val_accuracy: 0.7520\n",
            "Epoch 143/150\n",
            "514/514 [==============================] - 0s 173us/step - loss: 0.4885 - accuracy: 0.7549 - val_loss: 0.5294 - val_accuracy: 0.7480\n",
            "Epoch 144/150\n",
            "514/514 [==============================] - 0s 184us/step - loss: 0.4833 - accuracy: 0.7763 - val_loss: 0.5340 - val_accuracy: 0.7520\n",
            "Epoch 145/150\n",
            "514/514 [==============================] - 0s 178us/step - loss: 0.4819 - accuracy: 0.7685 - val_loss: 0.5203 - val_accuracy: 0.7598\n",
            "Epoch 146/150\n",
            "514/514 [==============================] - 0s 198us/step - loss: 0.4775 - accuracy: 0.7802 - val_loss: 0.5292 - val_accuracy: 0.7520\n",
            "Epoch 147/150\n",
            "514/514 [==============================] - 0s 198us/step - loss: 0.4800 - accuracy: 0.7724 - val_loss: 0.5223 - val_accuracy: 0.7559\n",
            "Epoch 148/150\n",
            "514/514 [==============================] - 0s 180us/step - loss: 0.4861 - accuracy: 0.7704 - val_loss: 0.5368 - val_accuracy: 0.7638\n",
            "Epoch 149/150\n",
            "514/514 [==============================] - 0s 187us/step - loss: 0.4725 - accuracy: 0.7743 - val_loss: 0.5328 - val_accuracy: 0.7480\n",
            "Epoch 150/150\n",
            "514/514 [==============================] - 0s 179us/step - loss: 0.4724 - accuracy: 0.7782 - val_loss: 0.5250 - val_accuracy: 0.7598\n",
            "768/768 [==============================] - 0s 24us/step\n",
            "accuracy 77.08333134651184\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqOfYniPsiC1"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJ601DZrT7hO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APkxCCevNP6s"
      },
      "source": [
        "**Using  a Manual Verification  dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3O7Lkr7T7kA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6ca8a8c5-2466-41e5-cd54-5cffa4135074"
      },
      "source": [
        "#MLP with Manual Validation Dataset\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "#fix random seed for reproducibilty\n",
        "seed = 7\n",
        "np.random.seed(seed)\n",
        "\n",
        "#Load the Dataset\n",
        "dataset = pd.read_csv('/content/diabetes.csv')\n",
        "\n",
        "#Split the dataset into X and Y variables\n",
        "X = dataset.iloc[:, :8]\n",
        "Y = dataset.iloc[:, 8]\n",
        "\n",
        "#split into 67% train data and 33% into test data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state= seed)\n",
        "\n",
        "#Create-Define the model\n",
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim=8, kernel_initializer='uniform', activation='relu'))\n",
        "model.add(Dense(8, kernel_initializer='uniform', activation = 'relu'))\n",
        "model.add(Dense(1, kernel_initializer='uniform', activation = 'relu'))\n",
        "\n",
        "#Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer = 'adam', metrics=['accuracy'])\n",
        "\n",
        "#Fit the model on the dataset\n",
        "model.fit(X_train, y_train, validation_data =(X_test, y_test), epochs=150, batch_size=10)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 514 samples, validate on 254 samples\n",
            "Epoch 1/150\n",
            "514/514 [==============================] - 0s 485us/step - loss: 1.2948 - accuracy: 0.6576 - val_loss: 0.8611 - val_accuracy: 0.6378\n",
            "Epoch 2/150\n",
            "514/514 [==============================] - 0s 178us/step - loss: 0.7171 - accuracy: 0.6576 - val_loss: 0.6458 - val_accuracy: 0.6378\n",
            "Epoch 3/150\n",
            "514/514 [==============================] - 0s 180us/step - loss: 0.6133 - accuracy: 0.6693 - val_loss: 0.6080 - val_accuracy: 0.6654\n",
            "Epoch 4/150\n",
            "514/514 [==============================] - 0s 185us/step - loss: 0.6011 - accuracy: 0.6751 - val_loss: 0.6031 - val_accuracy: 0.6654\n",
            "Epoch 5/150\n",
            "514/514 [==============================] - 0s 199us/step - loss: 0.5988 - accuracy: 0.6751 - val_loss: 0.6018 - val_accuracy: 0.6614\n",
            "Epoch 6/150\n",
            "514/514 [==============================] - 0s 184us/step - loss: 0.5957 - accuracy: 0.6770 - val_loss: 0.6007 - val_accuracy: 0.6614\n",
            "Epoch 7/150\n",
            "514/514 [==============================] - 0s 180us/step - loss: 0.5940 - accuracy: 0.6809 - val_loss: 0.5996 - val_accuracy: 0.6496\n",
            "Epoch 8/150\n",
            "514/514 [==============================] - 0s 184us/step - loss: 0.5906 - accuracy: 0.6712 - val_loss: 0.5964 - val_accuracy: 0.6732\n",
            "Epoch 9/150\n",
            "514/514 [==============================] - 0s 181us/step - loss: 0.5887 - accuracy: 0.6751 - val_loss: 0.5946 - val_accuracy: 0.6772\n",
            "Epoch 10/150\n",
            "514/514 [==============================] - 0s 204us/step - loss: 0.5869 - accuracy: 0.7121 - val_loss: 0.6008 - val_accuracy: 0.6417\n",
            "Epoch 11/150\n",
            "514/514 [==============================] - 0s 222us/step - loss: 0.5852 - accuracy: 0.6595 - val_loss: 0.5928 - val_accuracy: 0.6496\n",
            "Epoch 12/150\n",
            "514/514 [==============================] - 0s 189us/step - loss: 0.5825 - accuracy: 0.7023 - val_loss: 0.5906 - val_accuracy: 0.6693\n",
            "Epoch 13/150\n",
            "514/514 [==============================] - 0s 181us/step - loss: 0.5809 - accuracy: 0.6984 - val_loss: 0.5898 - val_accuracy: 0.6496\n",
            "Epoch 14/150\n",
            "514/514 [==============================] - 0s 178us/step - loss: 0.5766 - accuracy: 0.6946 - val_loss: 0.5925 - val_accuracy: 0.6850\n",
            "Epoch 15/150\n",
            "514/514 [==============================] - 0s 179us/step - loss: 0.5740 - accuracy: 0.6926 - val_loss: 0.5816 - val_accuracy: 0.6890\n",
            "Epoch 16/150\n",
            "514/514 [==============================] - 0s 194us/step - loss: 0.5681 - accuracy: 0.6926 - val_loss: 0.5794 - val_accuracy: 0.7244\n",
            "Epoch 17/150\n",
            "514/514 [==============================] - 0s 199us/step - loss: 0.5674 - accuracy: 0.7160 - val_loss: 0.5834 - val_accuracy: 0.6614\n",
            "Epoch 18/150\n",
            "514/514 [==============================] - 0s 183us/step - loss: 0.5611 - accuracy: 0.6965 - val_loss: 0.5743 - val_accuracy: 0.7126\n",
            "Epoch 19/150\n",
            "514/514 [==============================] - 0s 183us/step - loss: 0.5576 - accuracy: 0.7043 - val_loss: 0.6221 - val_accuracy: 0.7244\n",
            "Epoch 20/150\n",
            "514/514 [==============================] - 0s 182us/step - loss: 0.5534 - accuracy: 0.7237 - val_loss: 0.5680 - val_accuracy: 0.7283\n",
            "Epoch 21/150\n",
            "514/514 [==============================] - 0s 176us/step - loss: 0.5488 - accuracy: 0.7374 - val_loss: 0.6138 - val_accuracy: 0.7205\n",
            "Epoch 22/150\n",
            "514/514 [==============================] - 0s 192us/step - loss: 0.5438 - accuracy: 0.7510 - val_loss: 0.6099 - val_accuracy: 0.7323\n",
            "Epoch 23/150\n",
            "514/514 [==============================] - 0s 183us/step - loss: 0.5416 - accuracy: 0.7374 - val_loss: 0.6056 - val_accuracy: 0.7402\n",
            "Epoch 24/150\n",
            "514/514 [==============================] - 0s 182us/step - loss: 0.5341 - accuracy: 0.7451 - val_loss: 0.6150 - val_accuracy: 0.7520\n",
            "Epoch 25/150\n",
            "514/514 [==============================] - 0s 187us/step - loss: 0.5546 - accuracy: 0.7588 - val_loss: 0.6093 - val_accuracy: 0.7205\n",
            "Epoch 26/150\n",
            "514/514 [==============================] - 0s 195us/step - loss: 0.5274 - accuracy: 0.7568 - val_loss: 0.6087 - val_accuracy: 0.7362\n",
            "Epoch 27/150\n",
            "514/514 [==============================] - 0s 192us/step - loss: 0.5511 - accuracy: 0.7607 - val_loss: 0.6452 - val_accuracy: 0.6850\n",
            "Epoch 28/150\n",
            "514/514 [==============================] - 0s 184us/step - loss: 0.5461 - accuracy: 0.7374 - val_loss: 0.6024 - val_accuracy: 0.7362\n",
            "Epoch 29/150\n",
            "514/514 [==============================] - 0s 181us/step - loss: 0.5361 - accuracy: 0.7412 - val_loss: 0.6003 - val_accuracy: 0.7205\n",
            "Epoch 30/150\n",
            "514/514 [==============================] - 0s 177us/step - loss: 0.5337 - accuracy: 0.7374 - val_loss: 0.6109 - val_accuracy: 0.7205\n",
            "Epoch 31/150\n",
            "514/514 [==============================] - 0s 179us/step - loss: 0.5308 - accuracy: 0.7490 - val_loss: 0.5478 - val_accuracy: 0.7126\n",
            "Epoch 32/150\n",
            "514/514 [==============================] - 0s 193us/step - loss: 0.5217 - accuracy: 0.7646 - val_loss: 0.5969 - val_accuracy: 0.7323\n",
            "Epoch 33/150\n",
            "514/514 [==============================] - 0s 182us/step - loss: 0.5175 - accuracy: 0.7626 - val_loss: 0.6013 - val_accuracy: 0.7244\n",
            "Epoch 34/150\n",
            "514/514 [==============================] - 0s 190us/step - loss: 0.5152 - accuracy: 0.7529 - val_loss: 0.5867 - val_accuracy: 0.7402\n",
            "Epoch 35/150\n",
            "514/514 [==============================] - 0s 187us/step - loss: 0.5122 - accuracy: 0.7588 - val_loss: 0.5873 - val_accuracy: 0.7362\n",
            "Epoch 36/150\n",
            "514/514 [==============================] - 0s 184us/step - loss: 0.5059 - accuracy: 0.7490 - val_loss: 0.5994 - val_accuracy: 0.7008\n",
            "Epoch 37/150\n",
            "514/514 [==============================] - 0s 184us/step - loss: 0.5028 - accuracy: 0.7626 - val_loss: 0.5892 - val_accuracy: 0.7244\n",
            "Epoch 38/150\n",
            "514/514 [==============================] - 0s 180us/step - loss: 0.5081 - accuracy: 0.7471 - val_loss: 0.6445 - val_accuracy: 0.7323\n",
            "Epoch 39/150\n",
            "514/514 [==============================] - 0s 177us/step - loss: 0.5055 - accuracy: 0.7490 - val_loss: 0.6020 - val_accuracy: 0.7362\n",
            "Epoch 40/150\n",
            "514/514 [==============================] - 0s 184us/step - loss: 0.5222 - accuracy: 0.7471 - val_loss: 0.5909 - val_accuracy: 0.7205\n",
            "Epoch 41/150\n",
            "514/514 [==============================] - 0s 191us/step - loss: 0.5054 - accuracy: 0.7529 - val_loss: 0.6000 - val_accuracy: 0.7165\n",
            "Epoch 42/150\n",
            "514/514 [==============================] - 0s 178us/step - loss: 0.5012 - accuracy: 0.7549 - val_loss: 0.6400 - val_accuracy: 0.7087\n",
            "Epoch 43/150\n",
            "514/514 [==============================] - 0s 200us/step - loss: 0.5000 - accuracy: 0.7451 - val_loss: 0.6731 - val_accuracy: 0.7323\n",
            "Epoch 44/150\n",
            "514/514 [==============================] - 0s 172us/step - loss: 0.5193 - accuracy: 0.7432 - val_loss: 0.6372 - val_accuracy: 0.7283\n",
            "Epoch 45/150\n",
            "514/514 [==============================] - 0s 187us/step - loss: 0.5020 - accuracy: 0.7549 - val_loss: 0.6529 - val_accuracy: 0.7087\n",
            "Epoch 46/150\n",
            "514/514 [==============================] - 0s 180us/step - loss: 0.4922 - accuracy: 0.7665 - val_loss: 0.6388 - val_accuracy: 0.7362\n",
            "Epoch 47/150\n",
            "514/514 [==============================] - 0s 201us/step - loss: 0.4924 - accuracy: 0.7529 - val_loss: 0.6476 - val_accuracy: 0.6969\n",
            "Epoch 48/150\n",
            "514/514 [==============================] - 0s 187us/step - loss: 0.4964 - accuracy: 0.7588 - val_loss: 0.7399 - val_accuracy: 0.7008\n",
            "Epoch 49/150\n",
            "514/514 [==============================] - 0s 188us/step - loss: 0.4943 - accuracy: 0.7568 - val_loss: 0.6930 - val_accuracy: 0.7480\n",
            "Epoch 50/150\n",
            "514/514 [==============================] - 0s 183us/step - loss: 0.4914 - accuracy: 0.7743 - val_loss: 0.6657 - val_accuracy: 0.7402\n",
            "Epoch 51/150\n",
            "514/514 [==============================] - 0s 177us/step - loss: 0.4893 - accuracy: 0.7568 - val_loss: 0.6355 - val_accuracy: 0.7087\n",
            "Epoch 52/150\n",
            "514/514 [==============================] - 0s 176us/step - loss: 0.4830 - accuracy: 0.7665 - val_loss: 0.7027 - val_accuracy: 0.7244\n",
            "Epoch 53/150\n",
            "514/514 [==============================] - 0s 199us/step - loss: 0.4978 - accuracy: 0.7549 - val_loss: 0.6961 - val_accuracy: 0.7362\n",
            "Epoch 54/150\n",
            "514/514 [==============================] - 0s 182us/step - loss: 0.5955 - accuracy: 0.7451 - val_loss: 0.6436 - val_accuracy: 0.7362\n",
            "Epoch 55/150\n",
            "514/514 [==============================] - 0s 190us/step - loss: 0.4953 - accuracy: 0.7704 - val_loss: 0.6354 - val_accuracy: 0.7205\n",
            "Epoch 56/150\n",
            "514/514 [==============================] - 0s 180us/step - loss: 0.5003 - accuracy: 0.7412 - val_loss: 0.6627 - val_accuracy: 0.6850\n",
            "Epoch 57/150\n",
            "514/514 [==============================] - 0s 184us/step - loss: 0.5010 - accuracy: 0.7393 - val_loss: 0.6449 - val_accuracy: 0.7087\n",
            "Epoch 58/150\n",
            "514/514 [==============================] - 0s 182us/step - loss: 0.4863 - accuracy: 0.7685 - val_loss: 0.6364 - val_accuracy: 0.7126\n",
            "Epoch 59/150\n",
            "514/514 [==============================] - 0s 179us/step - loss: 0.4813 - accuracy: 0.7626 - val_loss: 0.6917 - val_accuracy: 0.7323\n",
            "Epoch 60/150\n",
            "514/514 [==============================] - 0s 180us/step - loss: 0.4852 - accuracy: 0.7588 - val_loss: 0.6939 - val_accuracy: 0.7205\n",
            "Epoch 61/150\n",
            "514/514 [==============================] - 0s 192us/step - loss: 0.4882 - accuracy: 0.7588 - val_loss: 0.6860 - val_accuracy: 0.7362\n",
            "Epoch 62/150\n",
            "514/514 [==============================] - 0s 195us/step - loss: 0.4801 - accuracy: 0.7568 - val_loss: 0.6399 - val_accuracy: 0.7244\n",
            "Epoch 63/150\n",
            "514/514 [==============================] - 0s 182us/step - loss: 0.5178 - accuracy: 0.7665 - val_loss: 0.6811 - val_accuracy: 0.7244\n",
            "Epoch 64/150\n",
            "514/514 [==============================] - 0s 240us/step - loss: 0.4835 - accuracy: 0.7665 - val_loss: 0.6415 - val_accuracy: 0.7087\n",
            "Epoch 65/150\n",
            "514/514 [==============================] - 0s 179us/step - loss: 0.4872 - accuracy: 0.7646 - val_loss: 0.6912 - val_accuracy: 0.7480\n",
            "Epoch 66/150\n",
            "514/514 [==============================] - 0s 185us/step - loss: 0.6152 - accuracy: 0.7257 - val_loss: 0.7554 - val_accuracy: 0.6811\n",
            "Epoch 67/150\n",
            "514/514 [==============================] - 0s 185us/step - loss: 0.5276 - accuracy: 0.7510 - val_loss: 0.6992 - val_accuracy: 0.7362\n",
            "Epoch 68/150\n",
            "514/514 [==============================] - 0s 176us/step - loss: 0.5099 - accuracy: 0.7646 - val_loss: 0.6462 - val_accuracy: 0.7402\n",
            "Epoch 69/150\n",
            "514/514 [==============================] - 0s 182us/step - loss: 0.5015 - accuracy: 0.7588 - val_loss: 0.6943 - val_accuracy: 0.7323\n",
            "Epoch 70/150\n",
            "514/514 [==============================] - 0s 185us/step - loss: 0.4966 - accuracy: 0.7568 - val_loss: 0.6879 - val_accuracy: 0.7323\n",
            "Epoch 71/150\n",
            "514/514 [==============================] - 0s 183us/step - loss: 0.4874 - accuracy: 0.7646 - val_loss: 0.6831 - val_accuracy: 0.7283\n",
            "Epoch 72/150\n",
            "514/514 [==============================] - 0s 191us/step - loss: 0.4888 - accuracy: 0.7549 - val_loss: 0.7049 - val_accuracy: 0.7441\n",
            "Epoch 73/150\n",
            "514/514 [==============================] - 0s 184us/step - loss: 0.4798 - accuracy: 0.7646 - val_loss: 0.6820 - val_accuracy: 0.7126\n",
            "Epoch 74/150\n",
            "514/514 [==============================] - 0s 201us/step - loss: 0.4810 - accuracy: 0.7685 - val_loss: 0.6430 - val_accuracy: 0.6969\n",
            "Epoch 75/150\n",
            "514/514 [==============================] - 0s 183us/step - loss: 0.4925 - accuracy: 0.7588 - val_loss: 0.6847 - val_accuracy: 0.7126\n",
            "Epoch 76/150\n",
            "514/514 [==============================] - 0s 175us/step - loss: 0.4816 - accuracy: 0.7626 - val_loss: 0.6374 - val_accuracy: 0.7087\n",
            "Epoch 77/150\n",
            "514/514 [==============================] - 0s 183us/step - loss: 0.4832 - accuracy: 0.7412 - val_loss: 0.6776 - val_accuracy: 0.7441\n",
            "Epoch 78/150\n",
            "514/514 [==============================] - 0s 184us/step - loss: 0.5035 - accuracy: 0.7412 - val_loss: 0.5562 - val_accuracy: 0.6969\n",
            "Epoch 79/150\n",
            "514/514 [==============================] - 0s 186us/step - loss: 0.4880 - accuracy: 0.7626 - val_loss: 0.7037 - val_accuracy: 0.7205\n",
            "Epoch 80/150\n",
            "514/514 [==============================] - 0s 178us/step - loss: 0.4888 - accuracy: 0.7588 - val_loss: 0.6892 - val_accuracy: 0.7205\n",
            "Epoch 81/150\n",
            "514/514 [==============================] - 0s 186us/step - loss: 0.4811 - accuracy: 0.7665 - val_loss: 0.6792 - val_accuracy: 0.7165\n",
            "Epoch 82/150\n",
            "514/514 [==============================] - 0s 202us/step - loss: 0.4815 - accuracy: 0.7588 - val_loss: 0.6824 - val_accuracy: 0.7362\n",
            "Epoch 83/150\n",
            "514/514 [==============================] - 0s 191us/step - loss: 0.4878 - accuracy: 0.7568 - val_loss: 0.6569 - val_accuracy: 0.7047\n",
            "Epoch 84/150\n",
            "514/514 [==============================] - 0s 199us/step - loss: 0.4864 - accuracy: 0.7568 - val_loss: 0.6437 - val_accuracy: 0.7205\n",
            "Epoch 85/150\n",
            "514/514 [==============================] - 0s 191us/step - loss: 0.4780 - accuracy: 0.7529 - val_loss: 0.6769 - val_accuracy: 0.7244\n",
            "Epoch 86/150\n",
            "514/514 [==============================] - 0s 190us/step - loss: 0.4753 - accuracy: 0.7763 - val_loss: 0.6777 - val_accuracy: 0.7283\n",
            "Epoch 87/150\n",
            "514/514 [==============================] - 0s 191us/step - loss: 0.4733 - accuracy: 0.7607 - val_loss: 0.6780 - val_accuracy: 0.7323\n",
            "Epoch 88/150\n",
            "514/514 [==============================] - 0s 200us/step - loss: 0.4709 - accuracy: 0.7821 - val_loss: 0.6457 - val_accuracy: 0.7126\n",
            "Epoch 89/150\n",
            "514/514 [==============================] - 0s 213us/step - loss: 0.4751 - accuracy: 0.7588 - val_loss: 0.6781 - val_accuracy: 0.7323\n",
            "Epoch 90/150\n",
            "514/514 [==============================] - 0s 184us/step - loss: 0.4732 - accuracy: 0.7646 - val_loss: 0.6385 - val_accuracy: 0.7126\n",
            "Epoch 91/150\n",
            "514/514 [==============================] - 0s 183us/step - loss: 0.4722 - accuracy: 0.7646 - val_loss: 0.6794 - val_accuracy: 0.7165\n",
            "Epoch 92/150\n",
            "514/514 [==============================] - 0s 187us/step - loss: 0.4693 - accuracy: 0.7588 - val_loss: 0.6797 - val_accuracy: 0.7126\n",
            "Epoch 93/150\n",
            "514/514 [==============================] - 0s 186us/step - loss: 0.4666 - accuracy: 0.7665 - val_loss: 0.6851 - val_accuracy: 0.7244\n",
            "Epoch 94/150\n",
            "514/514 [==============================] - 0s 189us/step - loss: 0.4700 - accuracy: 0.7529 - val_loss: 0.6756 - val_accuracy: 0.7362\n",
            "Epoch 95/150\n",
            "514/514 [==============================] - 0s 186us/step - loss: 0.4636 - accuracy: 0.7626 - val_loss: 0.6356 - val_accuracy: 0.7047\n",
            "Epoch 96/150\n",
            "514/514 [==============================] - 0s 183us/step - loss: 0.4724 - accuracy: 0.7588 - val_loss: 0.6831 - val_accuracy: 0.7323\n",
            "Epoch 97/150\n",
            "514/514 [==============================] - 0s 185us/step - loss: 0.4652 - accuracy: 0.7646 - val_loss: 0.6769 - val_accuracy: 0.7362\n",
            "Epoch 98/150\n",
            "514/514 [==============================] - 0s 187us/step - loss: 0.4607 - accuracy: 0.7743 - val_loss: 0.8651 - val_accuracy: 0.7480\n",
            "Epoch 99/150\n",
            "514/514 [==============================] - 0s 191us/step - loss: 0.4572 - accuracy: 0.7646 - val_loss: 0.7667 - val_accuracy: 0.6969\n",
            "Epoch 100/150\n",
            "514/514 [==============================] - 0s 185us/step - loss: 0.4787 - accuracy: 0.7626 - val_loss: 0.6741 - val_accuracy: 0.7205\n",
            "Epoch 101/150\n",
            "514/514 [==============================] - 0s 181us/step - loss: 0.4644 - accuracy: 0.7685 - val_loss: 0.6403 - val_accuracy: 0.7165\n",
            "Epoch 102/150\n",
            "514/514 [==============================] - 0s 182us/step - loss: 0.4915 - accuracy: 0.7607 - val_loss: 0.6900 - val_accuracy: 0.7441\n",
            "Epoch 103/150\n",
            "514/514 [==============================] - 0s 181us/step - loss: 0.4782 - accuracy: 0.7685 - val_loss: 0.6739 - val_accuracy: 0.7244\n",
            "Epoch 104/150\n",
            "514/514 [==============================] - 0s 200us/step - loss: 0.4601 - accuracy: 0.7607 - val_loss: 0.6266 - val_accuracy: 0.7323\n",
            "Epoch 105/150\n",
            "514/514 [==============================] - 0s 244us/step - loss: 0.4582 - accuracy: 0.7685 - val_loss: 0.7375 - val_accuracy: 0.7323\n",
            "Epoch 106/150\n",
            "514/514 [==============================] - 0s 189us/step - loss: 0.4580 - accuracy: 0.7685 - val_loss: 0.6852 - val_accuracy: 0.7244\n",
            "Epoch 107/150\n",
            "514/514 [==============================] - 0s 180us/step - loss: 0.4589 - accuracy: 0.7704 - val_loss: 0.7248 - val_accuracy: 0.7402\n",
            "Epoch 108/150\n",
            "514/514 [==============================] - 0s 176us/step - loss: 0.5073 - accuracy: 0.7432 - val_loss: 0.9340 - val_accuracy: 0.7165\n",
            "Epoch 109/150\n",
            "514/514 [==============================] - 0s 183us/step - loss: 0.5152 - accuracy: 0.7588 - val_loss: 0.6214 - val_accuracy: 0.7323\n",
            "Epoch 110/150\n",
            "514/514 [==============================] - 0s 184us/step - loss: 0.4940 - accuracy: 0.7665 - val_loss: 0.6251 - val_accuracy: 0.7205\n",
            "Epoch 111/150\n",
            "514/514 [==============================] - 0s 184us/step - loss: 0.4613 - accuracy: 0.7704 - val_loss: 0.7329 - val_accuracy: 0.7283\n",
            "Epoch 112/150\n",
            "514/514 [==============================] - 0s 191us/step - loss: 0.4649 - accuracy: 0.7665 - val_loss: 0.6293 - val_accuracy: 0.7126\n",
            "Epoch 113/150\n",
            "514/514 [==============================] - 0s 196us/step - loss: 0.4563 - accuracy: 0.7743 - val_loss: 0.6991 - val_accuracy: 0.7323\n",
            "Epoch 114/150\n",
            "514/514 [==============================] - 0s 195us/step - loss: 0.4732 - accuracy: 0.7685 - val_loss: 0.6784 - val_accuracy: 0.7402\n",
            "Epoch 115/150\n",
            "514/514 [==============================] - 0s 195us/step - loss: 0.4592 - accuracy: 0.7704 - val_loss: 0.6282 - val_accuracy: 0.7205\n",
            "Epoch 116/150\n",
            "514/514 [==============================] - 0s 191us/step - loss: 0.4866 - accuracy: 0.7782 - val_loss: 0.6657 - val_accuracy: 0.7402\n",
            "Epoch 117/150\n",
            "514/514 [==============================] - 0s 184us/step - loss: 0.4533 - accuracy: 0.7821 - val_loss: 0.6665 - val_accuracy: 0.7362\n",
            "Epoch 118/150\n",
            "514/514 [==============================] - 0s 188us/step - loss: 0.4565 - accuracy: 0.7646 - val_loss: 0.6677 - val_accuracy: 0.7244\n",
            "Epoch 119/150\n",
            "514/514 [==============================] - 0s 184us/step - loss: 0.4566 - accuracy: 0.7646 - val_loss: 0.6867 - val_accuracy: 0.7402\n",
            "Epoch 120/150\n",
            "514/514 [==============================] - 0s 184us/step - loss: 0.4598 - accuracy: 0.7743 - val_loss: 0.6661 - val_accuracy: 0.7244\n",
            "Epoch 121/150\n",
            "514/514 [==============================] - 0s 187us/step - loss: 0.4527 - accuracy: 0.7607 - val_loss: 0.6696 - val_accuracy: 0.7362\n",
            "Epoch 122/150\n",
            "514/514 [==============================] - 0s 194us/step - loss: 0.5155 - accuracy: 0.7743 - val_loss: 0.7319 - val_accuracy: 0.7402\n",
            "Epoch 123/150\n",
            "514/514 [==============================] - 0s 177us/step - loss: 0.4701 - accuracy: 0.7588 - val_loss: 0.6729 - val_accuracy: 0.7362\n",
            "Epoch 124/150\n",
            "514/514 [==============================] - 0s 185us/step - loss: 0.4548 - accuracy: 0.7763 - val_loss: 0.6698 - val_accuracy: 0.7402\n",
            "Epoch 125/150\n",
            "514/514 [==============================] - 0s 196us/step - loss: 0.4862 - accuracy: 0.7743 - val_loss: 0.6397 - val_accuracy: 0.7402\n",
            "Epoch 126/150\n",
            "514/514 [==============================] - 0s 195us/step - loss: 0.4909 - accuracy: 0.7704 - val_loss: 0.6649 - val_accuracy: 0.7205\n",
            "Epoch 127/150\n",
            "514/514 [==============================] - 0s 199us/step - loss: 0.4555 - accuracy: 0.7782 - val_loss: 0.6738 - val_accuracy: 0.7323\n",
            "Epoch 128/150\n",
            "514/514 [==============================] - 0s 201us/step - loss: 0.4548 - accuracy: 0.7724 - val_loss: 0.6719 - val_accuracy: 0.7244\n",
            "Epoch 129/150\n",
            "514/514 [==============================] - 0s 208us/step - loss: 0.4545 - accuracy: 0.7802 - val_loss: 0.6553 - val_accuracy: 0.7165\n",
            "Epoch 130/150\n",
            "514/514 [==============================] - 0s 202us/step - loss: 2.2530 - accuracy: 0.6829 - val_loss: 1.1475 - val_accuracy: 0.6614\n",
            "Epoch 131/150\n",
            "514/514 [==============================] - 0s 198us/step - loss: 0.6552 - accuracy: 0.7296 - val_loss: 0.7109 - val_accuracy: 0.7087\n",
            "Epoch 132/150\n",
            "514/514 [==============================] - 0s 207us/step - loss: 0.5316 - accuracy: 0.7510 - val_loss: 0.6583 - val_accuracy: 0.7283\n",
            "Epoch 133/150\n",
            "514/514 [==============================] - 0s 192us/step - loss: 0.5062 - accuracy: 0.7665 - val_loss: 0.6738 - val_accuracy: 0.7126\n",
            "Epoch 134/150\n",
            "514/514 [==============================] - 0s 205us/step - loss: 0.5166 - accuracy: 0.7393 - val_loss: 0.7034 - val_accuracy: 0.7244\n",
            "Epoch 135/150\n",
            "514/514 [==============================] - 0s 227us/step - loss: 0.5055 - accuracy: 0.7588 - val_loss: 0.6950 - val_accuracy: 0.6890\n",
            "Epoch 136/150\n",
            "514/514 [==============================] - 0s 222us/step - loss: 0.5189 - accuracy: 0.7315 - val_loss: 0.6410 - val_accuracy: 0.7047\n",
            "Epoch 137/150\n",
            "514/514 [==============================] - 0s 242us/step - loss: 0.4985 - accuracy: 0.7412 - val_loss: 0.6282 - val_accuracy: 0.7165\n",
            "Epoch 138/150\n",
            "514/514 [==============================] - 0s 208us/step - loss: 0.4783 - accuracy: 0.7743 - val_loss: 0.6224 - val_accuracy: 0.7480\n",
            "Epoch 139/150\n",
            "514/514 [==============================] - 0s 205us/step - loss: 0.4746 - accuracy: 0.7782 - val_loss: 0.6759 - val_accuracy: 0.7480\n",
            "Epoch 140/150\n",
            "514/514 [==============================] - 0s 204us/step - loss: 0.4762 - accuracy: 0.7724 - val_loss: 0.6683 - val_accuracy: 0.7638\n",
            "Epoch 141/150\n",
            "514/514 [==============================] - 0s 213us/step - loss: 0.4675 - accuracy: 0.7782 - val_loss: 0.6757 - val_accuracy: 0.7362\n",
            "Epoch 142/150\n",
            "514/514 [==============================] - 0s 203us/step - loss: 0.4800 - accuracy: 0.7568 - val_loss: 0.6668 - val_accuracy: 0.7559\n",
            "Epoch 143/150\n",
            "514/514 [==============================] - 0s 206us/step - loss: 0.4705 - accuracy: 0.7763 - val_loss: 0.6215 - val_accuracy: 0.7559\n",
            "Epoch 144/150\n",
            "514/514 [==============================] - 0s 210us/step - loss: 0.4631 - accuracy: 0.7802 - val_loss: 0.6660 - val_accuracy: 0.7677\n",
            "Epoch 145/150\n",
            "514/514 [==============================] - 0s 215us/step - loss: 0.4645 - accuracy: 0.7840 - val_loss: 0.6160 - val_accuracy: 0.7362\n",
            "Epoch 146/150\n",
            "514/514 [==============================] - 0s 209us/step - loss: 0.4643 - accuracy: 0.7763 - val_loss: 0.6165 - val_accuracy: 0.7480\n",
            "Epoch 147/150\n",
            "514/514 [==============================] - 0s 208us/step - loss: 0.4644 - accuracy: 0.7782 - val_loss: 0.6615 - val_accuracy: 0.7559\n",
            "Epoch 148/150\n",
            "514/514 [==============================] - 0s 203us/step - loss: 0.4617 - accuracy: 0.7763 - val_loss: 0.6611 - val_accuracy: 0.7598\n",
            "Epoch 149/150\n",
            "514/514 [==============================] - 0s 197us/step - loss: 0.4623 - accuracy: 0.7840 - val_loss: 0.6218 - val_accuracy: 0.7480\n",
            "Epoch 150/150\n",
            "514/514 [==============================] - 0s 201us/step - loss: 0.4628 - accuracy: 0.7840 - val_loss: 0.6646 - val_accuracy: 0.7559\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f276a35b9e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xA6LEiSTT7mm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLFBBuHWXGW5"
      },
      "source": [
        "**Maual K-Fold Cross Validation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYYzx6LQSRck",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "dc2685f3-5cbb-4aa9-afdf-1f63ff463143"
      },
      "source": [
        "# MLP for Pima Indian Diabetic Dataset with k-fold Cross Validation\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "#fix the seed for reproducibility\n",
        "seed = 7\n",
        "np.random.seed(seed)\n",
        "\n",
        "\n",
        "#Load the dataset\n",
        "dataset = pd.read_csv(\"/content/diabetes.csv\")\n",
        "\n",
        "#Split the dataset into X and Y variables\n",
        "X = dataset.iloc[:, :8]\n",
        "Y = dataset.iloc[:, 8]\n",
        "\n",
        "#Define 10-fold cross validation harness\n",
        "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "cvscores = []\n",
        "\n",
        "for train, test in kfold.split(X, Y):\n",
        "    #create model\n",
        "    model = Sequential()\n",
        "    model.add(Dense(12, input_dim=8, kernel_initializer='uniform', activation='relu'))\n",
        "    model.add(Dense(8, kernel_initializer='uniform', activation='relu'))\n",
        "    model.add(Dense(1, kernel_initializer = 'uniform', activation ='sigmoid'))\n",
        "\n",
        "    #compile the model\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    #fit the model\n",
        "    model.fit(X[train], Y[train], epochs=150, batch_size=10, verbose=0)\n",
        "\n",
        "    #evaluate the model\n",
        "    scores = model.evaluate(X[test], Y[test], verbose=0)\n",
        "    print(model.metrics[1], scores[1]*100)\n",
        "    cvscores.append(scores[1]*100)\n",
        "\n",
        "print(np.mean(cvscores), np.std(cvscores))    \n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-557352456d86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;31m#fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;31m#evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2804\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2805\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2806\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2808\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         self._validate_read_indexer(\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m         )\n\u001b[1;32m   1555\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1638\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmissing\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1639\u001b[0m                 \u001b[0maxis_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1640\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1642\u001b[0m             \u001b[0;31m# We (temporarily) allow for some missing keys with .loc, except in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"None of [Int64Index([  0,   1,   2,   5,   6,   7,   8,   9,  10,  11,\\n            ...\\n            756, 757, 758, 760, 761, 762, 763, 764, 766, 767],\\n           dtype='int64', length=691)] are in the [columns]\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIvPiVJzSRiZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpwjCL-VSRl8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygtrxVfz7KAW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zE3aIa9k7KnA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVjzeXzGeVGn"
      },
      "source": [
        "# Chapter 9\n",
        "# Use Keras Models With Scikit-Learn\n",
        "# For General Machine Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yeVcZe19pjp0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isfSfv9XSRpO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvXNxw_mSRsU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5XVvKN-7QcN"
      },
      "source": [
        "**Evaluate Models with Cross Validation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiRRoXZ7SRv1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "512a6fda-9575-4013-c046-850bb7c6b5b7"
      },
      "source": [
        "#MLP for Pima Indians Diabetes with 10-fold cross validation \n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def create_model():\n",
        "\n",
        "  #create model\n",
        "  model = Sequential()\n",
        "  model.add(Dense(12, input_dim=8, kernel_initializer='uniform', activation='relu'))\n",
        "  model.add(Dense(8, kernel_initializer='uniform', activation='relu'))\n",
        "  model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
        "  \n",
        "  #compile the model\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "  return model\n",
        "\n",
        "#fix random seed for reproducibility\n",
        "seed = 7\n",
        "np.random.seed(seed)\n",
        "\n",
        "#Load the Pima Indian Diabetes dataset\n",
        "dataset = pd.read_csv('/content/datasets_228_482_diabetes.csv')\n",
        "\n",
        "#Split the dataset into X and Y variables\n",
        "X = dataset.iloc[:, :8]\n",
        "Y = dataset.iloc[:, 8]\n",
        "\n",
        "#Create the model\n",
        "model = KerasClassifier(build_fn=create_model, epochs=150, batch_size=10)\n",
        "\n",
        "#Evaluate using 10-fold Cross Validation\n",
        "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "results = cross_val_score(model, X, Y, cv=kfold)\n",
        "print(results.mean)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "691/691 [==============================] - 0s 589us/step - loss: 0.6742 - accuracy: 0.6454\n",
            "Epoch 2/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.6614 - accuracy: 0.6512\n",
            "Epoch 3/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.6521 - accuracy: 0.6541\n",
            "Epoch 4/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.6460 - accuracy: 0.6541\n",
            "Epoch 5/150\n",
            "691/691 [==============================] - 0s 119us/step - loss: 0.6384 - accuracy: 0.6614\n",
            "Epoch 6/150\n",
            "691/691 [==============================] - 0s 128us/step - loss: 0.6340 - accuracy: 0.6700\n",
            "Epoch 7/150\n",
            "691/691 [==============================] - 0s 115us/step - loss: 0.6239 - accuracy: 0.6802\n",
            "Epoch 8/150\n",
            "691/691 [==============================] - 0s 117us/step - loss: 0.6104 - accuracy: 0.6874\n",
            "Epoch 9/150\n",
            "691/691 [==============================] - 0s 140us/step - loss: 0.6060 - accuracy: 0.6918\n",
            "Epoch 10/150\n",
            "691/691 [==============================] - 0s 120us/step - loss: 0.5953 - accuracy: 0.6903\n",
            "Epoch 11/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.5988 - accuracy: 0.6729\n",
            "Epoch 12/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.5946 - accuracy: 0.6932\n",
            "Epoch 13/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.5920 - accuracy: 0.6932\n",
            "Epoch 14/150\n",
            "691/691 [==============================] - 0s 109us/step - loss: 0.5849 - accuracy: 0.6932\n",
            "Epoch 15/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.5876 - accuracy: 0.6946\n",
            "Epoch 16/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.5804 - accuracy: 0.7004\n",
            "Epoch 17/150\n",
            "691/691 [==============================] - 0s 110us/step - loss: 0.5793 - accuracy: 0.6946\n",
            "Epoch 18/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.5914 - accuracy: 0.6946\n",
            "Epoch 19/150\n",
            "691/691 [==============================] - 0s 117us/step - loss: 0.5861 - accuracy: 0.6845\n",
            "Epoch 20/150\n",
            "691/691 [==============================] - 0s 115us/step - loss: 0.5789 - accuracy: 0.6932\n",
            "Epoch 21/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.5760 - accuracy: 0.7048\n",
            "Epoch 22/150\n",
            "691/691 [==============================] - 0s 116us/step - loss: 0.5785 - accuracy: 0.6946\n",
            "Epoch 23/150\n",
            "691/691 [==============================] - 0s 121us/step - loss: 0.5753 - accuracy: 0.6946\n",
            "Epoch 24/150\n",
            "691/691 [==============================] - 0s 128us/step - loss: 0.5771 - accuracy: 0.6990\n",
            "Epoch 25/150\n",
            "691/691 [==============================] - 0s 129us/step - loss: 0.5714 - accuracy: 0.7062\n",
            "Epoch 26/150\n",
            "691/691 [==============================] - 0s 115us/step - loss: 0.5736 - accuracy: 0.7019\n",
            "Epoch 27/150\n",
            "691/691 [==============================] - 0s 119us/step - loss: 0.5736 - accuracy: 0.7019\n",
            "Epoch 28/150\n",
            "691/691 [==============================] - 0s 116us/step - loss: 0.5756 - accuracy: 0.7004\n",
            "Epoch 29/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.5725 - accuracy: 0.6932\n",
            "Epoch 30/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.5713 - accuracy: 0.7004\n",
            "Epoch 31/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.5728 - accuracy: 0.7077\n",
            "Epoch 32/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.5802 - accuracy: 0.6961\n",
            "Epoch 33/150\n",
            "691/691 [==============================] - 0s 108us/step - loss: 0.5713 - accuracy: 0.7120\n",
            "Epoch 34/150\n",
            "691/691 [==============================] - 0s 120us/step - loss: 0.5668 - accuracy: 0.7192\n",
            "Epoch 35/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.5668 - accuracy: 0.7091\n",
            "Epoch 36/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.5653 - accuracy: 0.7120\n",
            "Epoch 37/150\n",
            "691/691 [==============================] - 0s 120us/step - loss: 0.5647 - accuracy: 0.7120\n",
            "Epoch 38/150\n",
            "691/691 [==============================] - 0s 119us/step - loss: 0.5624 - accuracy: 0.7192\n",
            "Epoch 39/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.5579 - accuracy: 0.7106\n",
            "Epoch 40/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.5630 - accuracy: 0.7149\n",
            "Epoch 41/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.5599 - accuracy: 0.7149\n",
            "Epoch 42/150\n",
            "691/691 [==============================] - 0s 116us/step - loss: 0.5587 - accuracy: 0.7178\n",
            "Epoch 43/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.5581 - accuracy: 0.7236\n",
            "Epoch 44/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.5624 - accuracy: 0.7106\n",
            "Epoch 45/150\n",
            "691/691 [==============================] - 0s 124us/step - loss: 0.5548 - accuracy: 0.7135\n",
            "Epoch 46/150\n",
            "691/691 [==============================] - 0s 122us/step - loss: 0.5538 - accuracy: 0.7236\n",
            "Epoch 47/150\n",
            "691/691 [==============================] - 0s 115us/step - loss: 0.5582 - accuracy: 0.7120\n",
            "Epoch 48/150\n",
            "691/691 [==============================] - 0s 127us/step - loss: 0.5562 - accuracy: 0.7192\n",
            "Epoch 49/150\n",
            "691/691 [==============================] - 0s 120us/step - loss: 0.5540 - accuracy: 0.7279\n",
            "Epoch 50/150\n",
            "691/691 [==============================] - 0s 117us/step - loss: 0.5514 - accuracy: 0.7250\n",
            "Epoch 51/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.5528 - accuracy: 0.7279\n",
            "Epoch 52/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.5535 - accuracy: 0.7279\n",
            "Epoch 53/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.5562 - accuracy: 0.7265\n",
            "Epoch 54/150\n",
            "691/691 [==============================] - 0s 120us/step - loss: 0.5468 - accuracy: 0.7366\n",
            "Epoch 55/150\n",
            "691/691 [==============================] - 0s 130us/step - loss: 0.5448 - accuracy: 0.7308\n",
            "Epoch 56/150\n",
            "691/691 [==============================] - 0s 129us/step - loss: 0.5452 - accuracy: 0.7294\n",
            "Epoch 57/150\n",
            "691/691 [==============================] - 0s 118us/step - loss: 0.5464 - accuracy: 0.7352\n",
            "Epoch 58/150\n",
            "691/691 [==============================] - 0s 120us/step - loss: 0.5409 - accuracy: 0.7352\n",
            "Epoch 59/150\n",
            "691/691 [==============================] - 0s 115us/step - loss: 0.5420 - accuracy: 0.7381\n",
            "Epoch 60/150\n",
            "691/691 [==============================] - 0s 119us/step - loss: 0.5404 - accuracy: 0.7410\n",
            "Epoch 61/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.5459 - accuracy: 0.7438\n",
            "Epoch 62/150\n",
            "691/691 [==============================] - 0s 115us/step - loss: 0.5440 - accuracy: 0.7352\n",
            "Epoch 63/150\n",
            "691/691 [==============================] - 0s 115us/step - loss: 0.5368 - accuracy: 0.7337\n",
            "Epoch 64/150\n",
            "691/691 [==============================] - 0s 119us/step - loss: 0.5360 - accuracy: 0.7366\n",
            "Epoch 65/150\n",
            "691/691 [==============================] - 0s 115us/step - loss: 0.5438 - accuracy: 0.7308\n",
            "Epoch 66/150\n",
            "691/691 [==============================] - 0s 122us/step - loss: 0.5371 - accuracy: 0.7250\n",
            "Epoch 67/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.5302 - accuracy: 0.7569\n",
            "Epoch 68/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.5307 - accuracy: 0.7438\n",
            "Epoch 69/150\n",
            "691/691 [==============================] - 0s 116us/step - loss: 0.5371 - accuracy: 0.7381\n",
            "Epoch 70/150\n",
            "691/691 [==============================] - 0s 115us/step - loss: 0.5332 - accuracy: 0.7453\n",
            "Epoch 71/150\n",
            "691/691 [==============================] - 0s 126us/step - loss: 0.5257 - accuracy: 0.7482\n",
            "Epoch 72/150\n",
            "691/691 [==============================] - 0s 122us/step - loss: 0.5214 - accuracy: 0.7496\n",
            "Epoch 73/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.5317 - accuracy: 0.7337\n",
            "Epoch 74/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.5280 - accuracy: 0.7641\n",
            "Epoch 75/150\n",
            "691/691 [==============================] - 0s 121us/step - loss: 0.5236 - accuracy: 0.7583\n",
            "Epoch 76/150\n",
            "691/691 [==============================] - 0s 132us/step - loss: 0.5231 - accuracy: 0.7453\n",
            "Epoch 77/150\n",
            "691/691 [==============================] - 0s 133us/step - loss: 0.5243 - accuracy: 0.7453\n",
            "Epoch 78/150\n",
            "691/691 [==============================] - 0s 131us/step - loss: 0.5165 - accuracy: 0.7569\n",
            "Epoch 79/150\n",
            "691/691 [==============================] - 0s 130us/step - loss: 0.5151 - accuracy: 0.7583\n",
            "Epoch 80/150\n",
            "691/691 [==============================] - 0s 130us/step - loss: 0.5243 - accuracy: 0.7453\n",
            "Epoch 81/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.5166 - accuracy: 0.7598\n",
            "Epoch 82/150\n",
            "691/691 [==============================] - 0s 126us/step - loss: 0.5250 - accuracy: 0.7554\n",
            "Epoch 83/150\n",
            "691/691 [==============================] - 0s 109us/step - loss: 0.5127 - accuracy: 0.7656\n",
            "Epoch 84/150\n",
            "691/691 [==============================] - 0s 116us/step - loss: 0.5143 - accuracy: 0.7612\n",
            "Epoch 85/150\n",
            "691/691 [==============================] - 0s 115us/step - loss: 0.5075 - accuracy: 0.7656\n",
            "Epoch 86/150\n",
            "691/691 [==============================] - 0s 117us/step - loss: 0.5078 - accuracy: 0.7612\n",
            "Epoch 87/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.5024 - accuracy: 0.7757\n",
            "Epoch 88/150\n",
            "691/691 [==============================] - 0s 120us/step - loss: 0.5265 - accuracy: 0.7540\n",
            "Epoch 89/150\n",
            "691/691 [==============================] - 0s 126us/step - loss: 0.5046 - accuracy: 0.7670\n",
            "Epoch 90/150\n",
            "691/691 [==============================] - 0s 116us/step - loss: 0.5050 - accuracy: 0.7641\n",
            "Epoch 91/150\n",
            "691/691 [==============================] - 0s 131us/step - loss: 0.4998 - accuracy: 0.7656\n",
            "Epoch 92/150\n",
            "691/691 [==============================] - 0s 126us/step - loss: 0.5122 - accuracy: 0.7598\n",
            "Epoch 93/150\n",
            "691/691 [==============================] - 0s 115us/step - loss: 0.5082 - accuracy: 0.7540\n",
            "Epoch 94/150\n",
            "691/691 [==============================] - 0s 117us/step - loss: 0.5109 - accuracy: 0.7569\n",
            "Epoch 95/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.4995 - accuracy: 0.7627\n",
            "Epoch 96/150\n",
            "691/691 [==============================] - 0s 118us/step - loss: 0.4995 - accuracy: 0.7670\n",
            "Epoch 97/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.4958 - accuracy: 0.7670\n",
            "Epoch 98/150\n",
            "691/691 [==============================] - 0s 119us/step - loss: 0.4978 - accuracy: 0.7641\n",
            "Epoch 99/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.4996 - accuracy: 0.7685\n",
            "Epoch 100/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.5024 - accuracy: 0.7627\n",
            "Epoch 101/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.4973 - accuracy: 0.7656\n",
            "Epoch 102/150\n",
            "691/691 [==============================] - 0s 121us/step - loss: 0.5037 - accuracy: 0.7525\n",
            "Epoch 103/150\n",
            "691/691 [==============================] - 0s 117us/step - loss: 0.4908 - accuracy: 0.7713\n",
            "Epoch 104/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.4903 - accuracy: 0.7713\n",
            "Epoch 105/150\n",
            "691/691 [==============================] - 0s 125us/step - loss: 0.4910 - accuracy: 0.7713\n",
            "Epoch 106/150\n",
            "691/691 [==============================] - 0s 117us/step - loss: 0.4887 - accuracy: 0.7641\n",
            "Epoch 107/150\n",
            "691/691 [==============================] - 0s 123us/step - loss: 0.4957 - accuracy: 0.7612\n",
            "Epoch 108/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.4875 - accuracy: 0.7670\n",
            "Epoch 109/150\n",
            "691/691 [==============================] - 0s 116us/step - loss: 0.5038 - accuracy: 0.7569\n",
            "Epoch 110/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.4841 - accuracy: 0.7728\n",
            "Epoch 111/150\n",
            "691/691 [==============================] - 0s 110us/step - loss: 0.4797 - accuracy: 0.7728\n",
            "Epoch 112/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.4830 - accuracy: 0.7757\n",
            "Epoch 113/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.4778 - accuracy: 0.7844\n",
            "Epoch 114/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.4868 - accuracy: 0.7627\n",
            "Epoch 115/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.4751 - accuracy: 0.7815\n",
            "Epoch 116/150\n",
            "691/691 [==============================] - 0s 109us/step - loss: 0.4828 - accuracy: 0.7656\n",
            "Epoch 117/150\n",
            "691/691 [==============================] - 0s 116us/step - loss: 0.4730 - accuracy: 0.7815\n",
            "Epoch 118/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.4752 - accuracy: 0.7786\n",
            "Epoch 119/150\n",
            "691/691 [==============================] - 0s 117us/step - loss: 0.4746 - accuracy: 0.7742\n",
            "Epoch 120/150\n",
            "691/691 [==============================] - 0s 139us/step - loss: 0.4806 - accuracy: 0.7699\n",
            "Epoch 121/150\n",
            "691/691 [==============================] - 0s 127us/step - loss: 0.4814 - accuracy: 0.7641\n",
            "Epoch 122/150\n",
            "691/691 [==============================] - 0s 130us/step - loss: 0.4712 - accuracy: 0.7685\n",
            "Epoch 123/150\n",
            "691/691 [==============================] - 0s 132us/step - loss: 0.4694 - accuracy: 0.7742\n",
            "Epoch 124/150\n",
            "691/691 [==============================] - 0s 132us/step - loss: 0.4708 - accuracy: 0.7713\n",
            "Epoch 125/150\n",
            "691/691 [==============================] - 0s 121us/step - loss: 0.4722 - accuracy: 0.7656\n",
            "Epoch 126/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.4785 - accuracy: 0.7699\n",
            "Epoch 127/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.4841 - accuracy: 0.7685\n",
            "Epoch 128/150\n",
            "691/691 [==============================] - 0s 115us/step - loss: 0.4692 - accuracy: 0.7728\n",
            "Epoch 129/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.4688 - accuracy: 0.7670\n",
            "Epoch 130/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.4683 - accuracy: 0.7699\n",
            "Epoch 131/150\n",
            "691/691 [==============================] - 0s 120us/step - loss: 0.4866 - accuracy: 0.7670\n",
            "Epoch 132/150\n",
            "691/691 [==============================] - 0s 110us/step - loss: 0.4645 - accuracy: 0.7873\n",
            "Epoch 133/150\n",
            "691/691 [==============================] - 0s 116us/step - loss: 0.4838 - accuracy: 0.7670\n",
            "Epoch 134/150\n",
            "691/691 [==============================] - 0s 110us/step - loss: 0.4743 - accuracy: 0.7742\n",
            "Epoch 135/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.4764 - accuracy: 0.7844\n",
            "Epoch 136/150\n",
            "691/691 [==============================] - 0s 147us/step - loss: 0.4693 - accuracy: 0.7771\n",
            "Epoch 137/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.4735 - accuracy: 0.7699\n",
            "Epoch 138/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.4691 - accuracy: 0.7641\n",
            "Epoch 139/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.4767 - accuracy: 0.7641\n",
            "Epoch 140/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.4694 - accuracy: 0.7641\n",
            "Epoch 141/150\n",
            "691/691 [==============================] - 0s 116us/step - loss: 0.4706 - accuracy: 0.7786\n",
            "Epoch 142/150\n",
            "691/691 [==============================] - 0s 116us/step - loss: 0.4760 - accuracy: 0.7670\n",
            "Epoch 143/150\n",
            "691/691 [==============================] - 0s 116us/step - loss: 0.4653 - accuracy: 0.7771\n",
            "Epoch 144/150\n",
            "691/691 [==============================] - 0s 117us/step - loss: 0.4644 - accuracy: 0.7728\n",
            "Epoch 145/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.4720 - accuracy: 0.7670\n",
            "Epoch 146/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.4606 - accuracy: 0.7815\n",
            "Epoch 147/150\n",
            "691/691 [==============================] - 0s 115us/step - loss: 0.4584 - accuracy: 0.7815\n",
            "Epoch 148/150\n",
            "691/691 [==============================] - 0s 109us/step - loss: 0.4579 - accuracy: 0.7829\n",
            "Epoch 149/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.4672 - accuracy: 0.7902\n",
            "Epoch 150/150\n",
            "691/691 [==============================] - 0s 115us/step - loss: 0.4604 - accuracy: 0.7699\n",
            "77/77 [==============================] - 0s 348us/step\n",
            "Epoch 1/150\n",
            "691/691 [==============================] - 0s 237us/step - loss: 0.6880 - accuracy: 0.6078\n",
            "Epoch 2/150\n",
            "691/691 [==============================] - 0s 109us/step - loss: 0.6684 - accuracy: 0.6512\n",
            "Epoch 3/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.6633 - accuracy: 0.6512\n",
            "Epoch 4/150\n",
            "691/691 [==============================] - 0s 116us/step - loss: 0.6539 - accuracy: 0.6527\n",
            "Epoch 5/150\n",
            "691/691 [==============================] - 0s 122us/step - loss: 0.6417 - accuracy: 0.6512\n",
            "Epoch 6/150\n",
            "691/691 [==============================] - 0s 129us/step - loss: 0.6328 - accuracy: 0.6657\n",
            "Epoch 7/150\n",
            "691/691 [==============================] - 0s 129us/step - loss: 0.6151 - accuracy: 0.6744\n",
            "Epoch 8/150\n",
            "691/691 [==============================] - 0s 126us/step - loss: 0.6089 - accuracy: 0.6715\n",
            "Epoch 9/150\n",
            "691/691 [==============================] - 0s 120us/step - loss: 0.6146 - accuracy: 0.6802\n",
            "Epoch 10/150\n",
            "691/691 [==============================] - 0s 135us/step - loss: 0.6063 - accuracy: 0.6845\n",
            "Epoch 11/150\n",
            "691/691 [==============================] - 0s 127us/step - loss: 0.5971 - accuracy: 0.6874\n",
            "Epoch 12/150\n",
            "691/691 [==============================] - 0s 117us/step - loss: 0.5937 - accuracy: 0.6932\n",
            "Epoch 13/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.5915 - accuracy: 0.6975\n",
            "Epoch 14/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.5900 - accuracy: 0.7048\n",
            "Epoch 15/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.6017 - accuracy: 0.6831\n",
            "Epoch 16/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.5863 - accuracy: 0.6975\n",
            "Epoch 17/150\n",
            "691/691 [==============================] - 0s 121us/step - loss: 0.5869 - accuracy: 0.6889\n",
            "Epoch 18/150\n",
            "691/691 [==============================] - 0s 132us/step - loss: 0.5820 - accuracy: 0.6946\n",
            "Epoch 19/150\n",
            "691/691 [==============================] - 0s 130us/step - loss: 0.5801 - accuracy: 0.7077\n",
            "Epoch 20/150\n",
            "691/691 [==============================] - 0s 116us/step - loss: 0.5766 - accuracy: 0.7004\n",
            "Epoch 21/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.5797 - accuracy: 0.7062\n",
            "Epoch 22/150\n",
            "691/691 [==============================] - 0s 115us/step - loss: 0.5767 - accuracy: 0.7004\n",
            "Epoch 23/150\n",
            "691/691 [==============================] - 0s 117us/step - loss: 0.5801 - accuracy: 0.6874\n",
            "Epoch 24/150\n",
            "691/691 [==============================] - 0s 110us/step - loss: 0.5741 - accuracy: 0.6946\n",
            "Epoch 25/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.5764 - accuracy: 0.7077\n",
            "Epoch 26/150\n",
            "691/691 [==============================] - 0s 108us/step - loss: 0.5725 - accuracy: 0.7062\n",
            "Epoch 27/150\n",
            "691/691 [==============================] - 0s 108us/step - loss: 0.5779 - accuracy: 0.6975\n",
            "Epoch 28/150\n",
            "691/691 [==============================] - 0s 124us/step - loss: 0.5787 - accuracy: 0.6903\n",
            "Epoch 29/150\n",
            "691/691 [==============================] - 0s 116us/step - loss: 0.5745 - accuracy: 0.7091\n",
            "Epoch 30/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.5743 - accuracy: 0.7106\n",
            "Epoch 31/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.5628 - accuracy: 0.7236\n",
            "Epoch 32/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.5670 - accuracy: 0.7135\n",
            "Epoch 33/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.5682 - accuracy: 0.7135\n",
            "Epoch 34/150\n",
            "691/691 [==============================] - 0s 117us/step - loss: 0.5600 - accuracy: 0.7164\n",
            "Epoch 35/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.5619 - accuracy: 0.7164\n",
            "Epoch 36/150\n",
            "691/691 [==============================] - 0s 119us/step - loss: 0.5630 - accuracy: 0.7192\n",
            "Epoch 37/150\n",
            "691/691 [==============================] - 0s 109us/step - loss: 0.5669 - accuracy: 0.7221\n",
            "Epoch 38/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.5656 - accuracy: 0.7062\n",
            "Epoch 39/150\n",
            "691/691 [==============================] - 0s 110us/step - loss: 0.5577 - accuracy: 0.7279\n",
            "Epoch 40/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.5629 - accuracy: 0.7207\n",
            "Epoch 41/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.5557 - accuracy: 0.7207\n",
            "Epoch 42/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.5621 - accuracy: 0.7250\n",
            "Epoch 43/150\n",
            "691/691 [==============================] - 0s 124us/step - loss: 0.5600 - accuracy: 0.7149\n",
            "Epoch 44/150\n",
            "691/691 [==============================] - 0s 131us/step - loss: 0.5546 - accuracy: 0.7236\n",
            "Epoch 45/150\n",
            "691/691 [==============================] - 0s 122us/step - loss: 0.5608 - accuracy: 0.7381\n",
            "Epoch 46/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.5514 - accuracy: 0.7250\n",
            "Epoch 47/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.5521 - accuracy: 0.7236\n",
            "Epoch 48/150\n",
            "691/691 [==============================] - 0s 121us/step - loss: 0.5529 - accuracy: 0.7294\n",
            "Epoch 49/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.5506 - accuracy: 0.7279\n",
            "Epoch 50/150\n",
            "691/691 [==============================] - 0s 115us/step - loss: 0.5551 - accuracy: 0.7164\n",
            "Epoch 51/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.5432 - accuracy: 0.7352\n",
            "Epoch 52/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.5511 - accuracy: 0.7308\n",
            "Epoch 53/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.5413 - accuracy: 0.7337\n",
            "Epoch 54/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.5470 - accuracy: 0.7207\n",
            "Epoch 55/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.5376 - accuracy: 0.7366\n",
            "Epoch 56/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.5378 - accuracy: 0.7453\n",
            "Epoch 57/150\n",
            "691/691 [==============================] - 0s 119us/step - loss: 0.5417 - accuracy: 0.7381\n",
            "Epoch 58/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.5425 - accuracy: 0.7250\n",
            "Epoch 59/150\n",
            "691/691 [==============================] - 0s 123us/step - loss: 0.5352 - accuracy: 0.7453\n",
            "Epoch 60/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.5334 - accuracy: 0.7395\n",
            "Epoch 61/150\n",
            "691/691 [==============================] - 0s 118us/step - loss: 0.5355 - accuracy: 0.7453\n",
            "Epoch 62/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.5314 - accuracy: 0.7438\n",
            "Epoch 63/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.5338 - accuracy: 0.7554\n",
            "Epoch 64/150\n",
            "691/691 [==============================] - 0s 109us/step - loss: 0.5336 - accuracy: 0.7381\n",
            "Epoch 65/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.5401 - accuracy: 0.7221\n",
            "Epoch 66/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.5308 - accuracy: 0.7467\n",
            "Epoch 67/150\n",
            "691/691 [==============================] - 0s 118us/step - loss: 0.5425 - accuracy: 0.7308\n",
            "Epoch 68/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.5279 - accuracy: 0.7467\n",
            "Epoch 69/150\n",
            "691/691 [==============================] - 0s 109us/step - loss: 0.5252 - accuracy: 0.7467\n",
            "Epoch 70/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.5301 - accuracy: 0.7337\n",
            "Epoch 71/150\n",
            "691/691 [==============================] - 0s 115us/step - loss: 0.5238 - accuracy: 0.7482\n",
            "Epoch 72/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.5240 - accuracy: 0.7410\n",
            "Epoch 73/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.5295 - accuracy: 0.7323\n",
            "Epoch 74/150\n",
            "691/691 [==============================] - 0s 125us/step - loss: 0.5212 - accuracy: 0.7569\n",
            "Epoch 75/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.5177 - accuracy: 0.7453\n",
            "Epoch 76/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.5219 - accuracy: 0.7467\n",
            "Epoch 77/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.5218 - accuracy: 0.7482\n",
            "Epoch 78/150\n",
            "691/691 [==============================] - 0s 124us/step - loss: 0.5151 - accuracy: 0.7511\n",
            "Epoch 79/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.5149 - accuracy: 0.7540\n",
            "Epoch 80/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.5129 - accuracy: 0.7540\n",
            "Epoch 81/150\n",
            "691/691 [==============================] - 0s 116us/step - loss: 0.5176 - accuracy: 0.7482\n",
            "Epoch 82/150\n",
            "691/691 [==============================] - 0s 118us/step - loss: 0.5267 - accuracy: 0.7467\n",
            "Epoch 83/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.5098 - accuracy: 0.7540\n",
            "Epoch 84/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.5151 - accuracy: 0.7482\n",
            "Epoch 85/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.5102 - accuracy: 0.7467\n",
            "Epoch 86/150\n",
            "691/691 [==============================] - 0s 119us/step - loss: 0.5094 - accuracy: 0.7598\n",
            "Epoch 87/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.5097 - accuracy: 0.7438\n",
            "Epoch 88/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.5092 - accuracy: 0.7540\n",
            "Epoch 89/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.5026 - accuracy: 0.7612\n",
            "Epoch 90/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.5397 - accuracy: 0.7395\n",
            "Epoch 91/150\n",
            "691/691 [==============================] - 0s 123us/step - loss: 0.5031 - accuracy: 0.7641\n",
            "Epoch 92/150\n",
            "691/691 [==============================] - 0s 124us/step - loss: 0.5000 - accuracy: 0.7569\n",
            "Epoch 93/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.5062 - accuracy: 0.7453\n",
            "Epoch 94/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.5146 - accuracy: 0.7424\n",
            "Epoch 95/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.4976 - accuracy: 0.7598\n",
            "Epoch 96/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.5227 - accuracy: 0.7395\n",
            "Epoch 97/150\n",
            "691/691 [==============================] - 0s 116us/step - loss: 0.4948 - accuracy: 0.7728\n",
            "Epoch 98/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.4982 - accuracy: 0.7598\n",
            "Epoch 99/150\n",
            "691/691 [==============================] - 0s 124us/step - loss: 0.4916 - accuracy: 0.7627\n",
            "Epoch 100/150\n",
            "691/691 [==============================] - 0s 132us/step - loss: 0.4934 - accuracy: 0.7656\n",
            "Epoch 101/150\n",
            "691/691 [==============================] - 0s 130us/step - loss: 0.4899 - accuracy: 0.7713\n",
            "Epoch 102/150\n",
            "691/691 [==============================] - 0s 130us/step - loss: 0.4932 - accuracy: 0.7656\n",
            "Epoch 103/150\n",
            "691/691 [==============================] - 0s 130us/step - loss: 0.4993 - accuracy: 0.7583\n",
            "Epoch 104/150\n",
            "691/691 [==============================] - 0s 133us/step - loss: 0.4958 - accuracy: 0.7641\n",
            "Epoch 105/150\n",
            "691/691 [==============================] - 0s 131us/step - loss: 0.4879 - accuracy: 0.7612\n",
            "Epoch 106/150\n",
            "691/691 [==============================] - 0s 123us/step - loss: 0.4870 - accuracy: 0.7670\n",
            "Epoch 107/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.4936 - accuracy: 0.7569\n",
            "Epoch 108/150\n",
            "691/691 [==============================] - 0s 117us/step - loss: 0.4868 - accuracy: 0.7525\n",
            "Epoch 109/150\n",
            "691/691 [==============================] - 0s 125us/step - loss: 0.4974 - accuracy: 0.7569\n",
            "Epoch 110/150\n",
            "691/691 [==============================] - 0s 117us/step - loss: 0.4865 - accuracy: 0.7612\n",
            "Epoch 111/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.4861 - accuracy: 0.7641\n",
            "Epoch 112/150\n",
            "691/691 [==============================] - 0s 115us/step - loss: 0.4920 - accuracy: 0.7685\n",
            "Epoch 113/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.4867 - accuracy: 0.7757\n",
            "Epoch 114/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.4819 - accuracy: 0.7771\n",
            "Epoch 115/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.4798 - accuracy: 0.7598\n",
            "Epoch 116/150\n",
            "691/691 [==============================] - 0s 109us/step - loss: 0.4785 - accuracy: 0.7713\n",
            "Epoch 117/150\n",
            "691/691 [==============================] - 0s 110us/step - loss: 0.4879 - accuracy: 0.7583\n",
            "Epoch 118/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.4821 - accuracy: 0.7612\n",
            "Epoch 119/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.4889 - accuracy: 0.7612\n",
            "Epoch 120/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.4771 - accuracy: 0.7641\n",
            "Epoch 121/150\n",
            "691/691 [==============================] - 0s 115us/step - loss: 0.4827 - accuracy: 0.7598\n",
            "Epoch 122/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.4813 - accuracy: 0.7583\n",
            "Epoch 123/150\n",
            "691/691 [==============================] - 0s 117us/step - loss: 0.4729 - accuracy: 0.7728\n",
            "Epoch 124/150\n",
            "691/691 [==============================] - 0s 110us/step - loss: 0.4780 - accuracy: 0.7670\n",
            "Epoch 125/150\n",
            "691/691 [==============================] - 0s 119us/step - loss: 0.4842 - accuracy: 0.7670\n",
            "Epoch 126/150\n",
            "691/691 [==============================] - 0s 119us/step - loss: 0.4794 - accuracy: 0.7569\n",
            "Epoch 127/150\n",
            "691/691 [==============================] - 0s 124us/step - loss: 0.4953 - accuracy: 0.7641\n",
            "Epoch 128/150\n",
            "691/691 [==============================] - 0s 117us/step - loss: 0.4715 - accuracy: 0.7670\n",
            "Epoch 129/150\n",
            "691/691 [==============================] - 0s 132us/step - loss: 0.4799 - accuracy: 0.7670\n",
            "Epoch 130/150\n",
            "691/691 [==============================] - 0s 120us/step - loss: 0.4789 - accuracy: 0.7670\n",
            "Epoch 131/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.4788 - accuracy: 0.7699\n",
            "Epoch 132/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.4868 - accuracy: 0.7583\n",
            "Epoch 133/150\n",
            "691/691 [==============================] - 0s 116us/step - loss: 0.4780 - accuracy: 0.7670\n",
            "Epoch 134/150\n",
            "691/691 [==============================] - 0s 116us/step - loss: 0.4715 - accuracy: 0.7771\n",
            "Epoch 135/150\n",
            "691/691 [==============================] - 0s 118us/step - loss: 0.4695 - accuracy: 0.7742\n",
            "Epoch 136/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.4766 - accuracy: 0.7641\n",
            "Epoch 137/150\n",
            "691/691 [==============================] - 0s 109us/step - loss: 0.4808 - accuracy: 0.7670\n",
            "Epoch 138/150\n",
            "691/691 [==============================] - 0s 109us/step - loss: 0.4718 - accuracy: 0.7627\n",
            "Epoch 139/150\n",
            "691/691 [==============================] - 0s 110us/step - loss: 0.4766 - accuracy: 0.7612\n",
            "Epoch 140/150\n",
            "691/691 [==============================] - 0s 109us/step - loss: 0.4787 - accuracy: 0.7583\n",
            "Epoch 141/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.4725 - accuracy: 0.7757\n",
            "Epoch 142/150\n",
            "691/691 [==============================] - 0s 107us/step - loss: 0.4757 - accuracy: 0.7685\n",
            "Epoch 143/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.4707 - accuracy: 0.7757\n",
            "Epoch 144/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.4814 - accuracy: 0.7713\n",
            "Epoch 145/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.4806 - accuracy: 0.7656\n",
            "Epoch 146/150\n",
            "691/691 [==============================] - 0s 110us/step - loss: 0.4714 - accuracy: 0.7757\n",
            "Epoch 147/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.4678 - accuracy: 0.7742\n",
            "Epoch 148/150\n",
            "691/691 [==============================] - 0s 118us/step - loss: 0.4727 - accuracy: 0.7699\n",
            "Epoch 149/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.4663 - accuracy: 0.7771\n",
            "Epoch 150/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.4701 - accuracy: 0.7612\n",
            "77/77 [==============================] - 0s 273us/step\n",
            "Epoch 1/150\n",
            "691/691 [==============================] - 0s 240us/step - loss: 0.6839 - accuracy: 0.6208\n",
            "Epoch 2/150\n",
            "691/691 [==============================] - 0s 123us/step - loss: 0.6663 - accuracy: 0.6512\n",
            "Epoch 3/150\n",
            "691/691 [==============================] - 0s 117us/step - loss: 0.6580 - accuracy: 0.6512\n",
            "Epoch 4/150\n",
            "691/691 [==============================] - 0s 118us/step - loss: 0.6474 - accuracy: 0.6643\n",
            "Epoch 5/150\n",
            "691/691 [==============================] - 0s 116us/step - loss: 0.6395 - accuracy: 0.6498\n",
            "Epoch 6/150\n",
            "691/691 [==============================] - 0s 110us/step - loss: 0.6291 - accuracy: 0.6541\n",
            "Epoch 7/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.6136 - accuracy: 0.6816\n",
            "Epoch 8/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.6084 - accuracy: 0.6715\n",
            "Epoch 9/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.6092 - accuracy: 0.6729\n",
            "Epoch 10/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.5992 - accuracy: 0.6903\n",
            "Epoch 11/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.5996 - accuracy: 0.6773\n",
            "Epoch 12/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.5952 - accuracy: 0.6903\n",
            "Epoch 13/150\n",
            "691/691 [==============================] - 0s 123us/step - loss: 0.5907 - accuracy: 0.6946\n",
            "Epoch 14/150\n",
            "691/691 [==============================] - 0s 134us/step - loss: 0.5865 - accuracy: 0.6816\n",
            "Epoch 15/150\n",
            "691/691 [==============================] - 0s 133us/step - loss: 0.5808 - accuracy: 0.7019\n",
            "Epoch 16/150\n",
            "691/691 [==============================] - 0s 139us/step - loss: 0.5858 - accuracy: 0.6845\n",
            "Epoch 17/150\n",
            "691/691 [==============================] - 0s 128us/step - loss: 0.5883 - accuracy: 0.6860\n",
            "Epoch 18/150\n",
            "691/691 [==============================] - 0s 132us/step - loss: 0.5789 - accuracy: 0.6874\n",
            "Epoch 19/150\n",
            "691/691 [==============================] - 0s 131us/step - loss: 0.5845 - accuracy: 0.6918\n",
            "Epoch 20/150\n",
            "691/691 [==============================] - 0s 135us/step - loss: 0.5808 - accuracy: 0.7048\n",
            "Epoch 21/150\n",
            "691/691 [==============================] - 0s 132us/step - loss: 0.5725 - accuracy: 0.7048\n",
            "Epoch 22/150\n",
            "691/691 [==============================] - 0s 120us/step - loss: 0.5791 - accuracy: 0.7033\n",
            "Epoch 23/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.5758 - accuracy: 0.6946\n",
            "Epoch 24/150\n",
            "691/691 [==============================] - 0s 118us/step - loss: 0.5727 - accuracy: 0.7091\n",
            "Epoch 25/150\n",
            "691/691 [==============================] - 0s 127us/step - loss: 0.5752 - accuracy: 0.7135\n",
            "Epoch 26/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.5707 - accuracy: 0.7077\n",
            "Epoch 27/150\n",
            "691/691 [==============================] - 0s 120us/step - loss: 0.5629 - accuracy: 0.7192\n",
            "Epoch 28/150\n",
            "691/691 [==============================] - 0s 110us/step - loss: 0.5666 - accuracy: 0.7106\n",
            "Epoch 29/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.5636 - accuracy: 0.7077\n",
            "Epoch 30/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.5624 - accuracy: 0.7164\n",
            "Epoch 31/150\n",
            "691/691 [==============================] - 0s 119us/step - loss: 0.5547 - accuracy: 0.7236\n",
            "Epoch 32/150\n",
            "691/691 [==============================] - 0s 109us/step - loss: 0.5583 - accuracy: 0.7164\n",
            "Epoch 33/150\n",
            "691/691 [==============================] - 0s 109us/step - loss: 0.5537 - accuracy: 0.7120\n",
            "Epoch 34/150\n",
            "691/691 [==============================] - 0s 110us/step - loss: 0.5497 - accuracy: 0.7236\n",
            "Epoch 35/150\n",
            "691/691 [==============================] - 0s 110us/step - loss: 0.5494 - accuracy: 0.7236\n",
            "Epoch 36/150\n",
            "691/691 [==============================] - 0s 110us/step - loss: 0.5501 - accuracy: 0.7279\n",
            "Epoch 37/150\n",
            "691/691 [==============================] - 0s 123us/step - loss: 0.5435 - accuracy: 0.7366\n",
            "Epoch 38/150\n",
            "691/691 [==============================] - 0s 128us/step - loss: 0.5495 - accuracy: 0.7337\n",
            "Epoch 39/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.5455 - accuracy: 0.7192\n",
            "Epoch 40/150\n",
            "691/691 [==============================] - 0s 119us/step - loss: 0.5483 - accuracy: 0.7323\n",
            "Epoch 41/150\n",
            "691/691 [==============================] - 0s 121us/step - loss: 0.5411 - accuracy: 0.7395\n",
            "Epoch 42/150\n",
            "691/691 [==============================] - 0s 131us/step - loss: 0.5471 - accuracy: 0.7236\n",
            "Epoch 43/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.5430 - accuracy: 0.7265\n",
            "Epoch 44/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.5349 - accuracy: 0.7308\n",
            "Epoch 45/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.5462 - accuracy: 0.7236\n",
            "Epoch 46/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.5464 - accuracy: 0.7279\n",
            "Epoch 47/150\n",
            "691/691 [==============================] - 0s 116us/step - loss: 0.5384 - accuracy: 0.7453\n",
            "Epoch 48/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.5408 - accuracy: 0.7395\n",
            "Epoch 49/150\n",
            "691/691 [==============================] - 0s 118us/step - loss: 0.5305 - accuracy: 0.7453\n",
            "Epoch 50/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.5323 - accuracy: 0.7496\n",
            "Epoch 51/150\n",
            "691/691 [==============================] - 0s 117us/step - loss: 0.5327 - accuracy: 0.7352\n",
            "Epoch 52/150\n",
            "691/691 [==============================] - 0s 139us/step - loss: 0.5293 - accuracy: 0.7467\n",
            "Epoch 53/150\n",
            "691/691 [==============================] - 0s 133us/step - loss: 0.5290 - accuracy: 0.7424\n",
            "Epoch 54/150\n",
            "691/691 [==============================] - 0s 128us/step - loss: 0.5398 - accuracy: 0.7410\n",
            "Epoch 55/150\n",
            "691/691 [==============================] - 0s 128us/step - loss: 0.5222 - accuracy: 0.7381\n",
            "Epoch 56/150\n",
            "691/691 [==============================] - 0s 117us/step - loss: 0.5303 - accuracy: 0.7525\n",
            "Epoch 57/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.5181 - accuracy: 0.7410\n",
            "Epoch 58/150\n",
            "691/691 [==============================] - 0s 115us/step - loss: 0.5228 - accuracy: 0.7482\n",
            "Epoch 59/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.5177 - accuracy: 0.7525\n",
            "Epoch 60/150\n",
            "691/691 [==============================] - 0s 125us/step - loss: 0.5152 - accuracy: 0.7554\n",
            "Epoch 61/150\n",
            "691/691 [==============================] - 0s 128us/step - loss: 0.5135 - accuracy: 0.7554\n",
            "Epoch 62/150\n",
            "691/691 [==============================] - 0s 119us/step - loss: 0.5140 - accuracy: 0.7685\n",
            "Epoch 63/150\n",
            "691/691 [==============================] - 0s 116us/step - loss: 0.5046 - accuracy: 0.7583\n",
            "Epoch 64/150\n",
            "691/691 [==============================] - 0s 125us/step - loss: 0.5142 - accuracy: 0.7569\n",
            "Epoch 65/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.5092 - accuracy: 0.7583\n",
            "Epoch 66/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.5084 - accuracy: 0.7482\n",
            "Epoch 67/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.5005 - accuracy: 0.7540\n",
            "Epoch 68/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.5030 - accuracy: 0.7598\n",
            "Epoch 69/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.5065 - accuracy: 0.7569\n",
            "Epoch 70/150\n",
            "691/691 [==============================] - 0s 123us/step - loss: 0.5020 - accuracy: 0.7713\n",
            "Epoch 71/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.4963 - accuracy: 0.7685\n",
            "Epoch 72/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.5020 - accuracy: 0.7728\n",
            "Epoch 73/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.4939 - accuracy: 0.7713\n",
            "Epoch 74/150\n",
            "691/691 [==============================] - 0s 109us/step - loss: 0.5017 - accuracy: 0.7554\n",
            "Epoch 75/150\n",
            "691/691 [==============================] - 0s 109us/step - loss: 0.4982 - accuracy: 0.7554\n",
            "Epoch 76/150\n",
            "691/691 [==============================] - 0s 110us/step - loss: 0.4928 - accuracy: 0.7670\n",
            "Epoch 77/150\n",
            "691/691 [==============================] - 0s 117us/step - loss: 0.4961 - accuracy: 0.7670\n",
            "Epoch 78/150\n",
            "691/691 [==============================] - 0s 110us/step - loss: 0.4898 - accuracy: 0.7713\n",
            "Epoch 79/150\n",
            "691/691 [==============================] - 0s 121us/step - loss: 0.4988 - accuracy: 0.7612\n",
            "Epoch 80/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.4904 - accuracy: 0.7627\n",
            "Epoch 81/150\n",
            "691/691 [==============================] - 0s 117us/step - loss: 0.4886 - accuracy: 0.7656\n",
            "Epoch 82/150\n",
            "691/691 [==============================] - 0s 122us/step - loss: 0.4974 - accuracy: 0.7554\n",
            "Epoch 83/150\n",
            "691/691 [==============================] - 0s 118us/step - loss: 0.4933 - accuracy: 0.7641\n",
            "Epoch 84/150\n",
            "691/691 [==============================] - 0s 117us/step - loss: 0.4953 - accuracy: 0.7757\n",
            "Epoch 85/150\n",
            "691/691 [==============================] - 0s 115us/step - loss: 0.4914 - accuracy: 0.7699\n",
            "Epoch 86/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.4850 - accuracy: 0.7771\n",
            "Epoch 87/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.4871 - accuracy: 0.7713\n",
            "Epoch 88/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.5019 - accuracy: 0.7540\n",
            "Epoch 89/150\n",
            "691/691 [==============================] - 0s 122us/step - loss: 0.4859 - accuracy: 0.7656\n",
            "Epoch 90/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.4830 - accuracy: 0.7800\n",
            "Epoch 91/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.4787 - accuracy: 0.7685\n",
            "Epoch 92/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.4833 - accuracy: 0.7685\n",
            "Epoch 93/150\n",
            "691/691 [==============================] - 0s 110us/step - loss: 0.4765 - accuracy: 0.7786\n",
            "Epoch 94/150\n",
            "691/691 [==============================] - 0s 110us/step - loss: 0.4903 - accuracy: 0.7670\n",
            "Epoch 95/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.4774 - accuracy: 0.7786\n",
            "Epoch 96/150\n",
            "691/691 [==============================] - 0s 124us/step - loss: 0.4838 - accuracy: 0.7540\n",
            "Epoch 97/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.5036 - accuracy: 0.7554\n",
            "Epoch 98/150\n",
            "691/691 [==============================] - 0s 137us/step - loss: 0.4787 - accuracy: 0.7699\n",
            "Epoch 99/150\n",
            "691/691 [==============================] - 0s 117us/step - loss: 0.4761 - accuracy: 0.7757\n",
            "Epoch 100/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.4885 - accuracy: 0.7713\n",
            "Epoch 101/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.4773 - accuracy: 0.7815\n",
            "Epoch 102/150\n",
            "691/691 [==============================] - 0s 117us/step - loss: 0.4750 - accuracy: 0.7699\n",
            "Epoch 103/150\n",
            "691/691 [==============================] - 0s 135us/step - loss: 0.4784 - accuracy: 0.7685\n",
            "Epoch 104/150\n",
            "691/691 [==============================] - 0s 115us/step - loss: 0.4710 - accuracy: 0.7771\n",
            "Epoch 105/150\n",
            "691/691 [==============================] - 0s 118us/step - loss: 0.4765 - accuracy: 0.7800\n",
            "Epoch 106/150\n",
            "691/691 [==============================] - 0s 131us/step - loss: 0.4764 - accuracy: 0.7757\n",
            "Epoch 107/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.4696 - accuracy: 0.7699\n",
            "Epoch 108/150\n",
            "691/691 [==============================] - 0s 123us/step - loss: 0.4767 - accuracy: 0.7656\n",
            "Epoch 109/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.4776 - accuracy: 0.7713\n",
            "Epoch 110/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.4758 - accuracy: 0.7728\n",
            "Epoch 111/150\n",
            "691/691 [==============================] - 0s 118us/step - loss: 0.4761 - accuracy: 0.7742\n",
            "Epoch 112/150\n",
            "691/691 [==============================] - 0s 122us/step - loss: 0.4702 - accuracy: 0.7728\n",
            "Epoch 113/150\n",
            "691/691 [==============================] - 0s 132us/step - loss: 0.4754 - accuracy: 0.7656\n",
            "Epoch 114/150\n",
            "691/691 [==============================] - 0s 131us/step - loss: 0.4687 - accuracy: 0.7829\n",
            "Epoch 115/150\n",
            "691/691 [==============================] - 0s 132us/step - loss: 0.4670 - accuracy: 0.7800\n",
            "Epoch 116/150\n",
            "691/691 [==============================] - 0s 132us/step - loss: 0.4664 - accuracy: 0.7742\n",
            "Epoch 117/150\n",
            "691/691 [==============================] - 0s 134us/step - loss: 0.4737 - accuracy: 0.7641\n",
            "Epoch 118/150\n",
            "691/691 [==============================] - 0s 136us/step - loss: 0.4664 - accuracy: 0.7757\n",
            "Epoch 119/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.4758 - accuracy: 0.7873\n",
            "Epoch 120/150\n",
            "691/691 [==============================] - 0s 116us/step - loss: 0.4653 - accuracy: 0.7959\n",
            "Epoch 121/150\n",
            "691/691 [==============================] - 0s 116us/step - loss: 0.4598 - accuracy: 0.7815\n",
            "Epoch 122/150\n",
            "691/691 [==============================] - 0s 116us/step - loss: 0.4637 - accuracy: 0.7829\n",
            "Epoch 123/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.4756 - accuracy: 0.7829\n",
            "Epoch 124/150\n",
            "691/691 [==============================] - 0s 115us/step - loss: 0.4664 - accuracy: 0.7757\n",
            "Epoch 125/150\n",
            "691/691 [==============================] - 0s 121us/step - loss: 0.4633 - accuracy: 0.7742\n",
            "Epoch 126/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.4698 - accuracy: 0.7800\n",
            "Epoch 127/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.4689 - accuracy: 0.7858\n",
            "Epoch 128/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.4638 - accuracy: 0.7800\n",
            "Epoch 129/150\n",
            "691/691 [==============================] - 0s 138us/step - loss: 0.4651 - accuracy: 0.7786\n",
            "Epoch 130/150\n",
            "691/691 [==============================] - 0s 133us/step - loss: 0.4719 - accuracy: 0.7627\n",
            "Epoch 131/150\n",
            "691/691 [==============================] - 0s 120us/step - loss: 0.4749 - accuracy: 0.7742\n",
            "Epoch 132/150\n",
            "691/691 [==============================] - 0s 120us/step - loss: 0.4616 - accuracy: 0.7829\n",
            "Epoch 133/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.4593 - accuracy: 0.7815\n",
            "Epoch 134/150\n",
            "691/691 [==============================] - 0s 122us/step - loss: 0.4653 - accuracy: 0.7771\n",
            "Epoch 135/150\n",
            "691/691 [==============================] - 0s 110us/step - loss: 0.4600 - accuracy: 0.7858\n",
            "Epoch 136/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.4595 - accuracy: 0.7800\n",
            "Epoch 137/150\n",
            "691/691 [==============================] - 0s 129us/step - loss: 0.4643 - accuracy: 0.7786\n",
            "Epoch 138/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.4626 - accuracy: 0.7713\n",
            "Epoch 139/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.4604 - accuracy: 0.7815\n",
            "Epoch 140/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.4620 - accuracy: 0.7771\n",
            "Epoch 141/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.4607 - accuracy: 0.7757\n",
            "Epoch 142/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.4616 - accuracy: 0.7728\n",
            "Epoch 143/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.4604 - accuracy: 0.7641\n",
            "Epoch 144/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.4510 - accuracy: 0.7771\n",
            "Epoch 145/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.4555 - accuracy: 0.7800\n",
            "Epoch 146/150\n",
            "691/691 [==============================] - 0s 116us/step - loss: 0.4567 - accuracy: 0.7699\n",
            "Epoch 147/150\n",
            "691/691 [==============================] - 0s 118us/step - loss: 0.4552 - accuracy: 0.7887\n",
            "Epoch 148/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.4599 - accuracy: 0.7713\n",
            "Epoch 149/150\n",
            "691/691 [==============================] - 0s 121us/step - loss: 0.4549 - accuracy: 0.7931\n",
            "Epoch 150/150\n",
            "691/691 [==============================] - 0s 118us/step - loss: 0.4556 - accuracy: 0.7873\n",
            "77/77 [==============================] - 0s 285us/step\n",
            "Epoch 1/150\n",
            "691/691 [==============================] - 0s 255us/step - loss: 0.6857 - accuracy: 0.6440\n",
            "Epoch 2/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.6677 - accuracy: 0.6512\n",
            "Epoch 3/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.6585 - accuracy: 0.6512\n",
            "Epoch 4/150\n",
            "691/691 [==============================] - 0s 125us/step - loss: 0.6477 - accuracy: 0.6527\n",
            "Epoch 5/150\n",
            "691/691 [==============================] - 0s 134us/step - loss: 0.6423 - accuracy: 0.6657\n",
            "Epoch 6/150\n",
            "691/691 [==============================] - 0s 128us/step - loss: 0.6294 - accuracy: 0.6527\n",
            "Epoch 7/150\n",
            "691/691 [==============================] - 0s 135us/step - loss: 0.6169 - accuracy: 0.6729\n",
            "Epoch 8/150\n",
            "691/691 [==============================] - 0s 128us/step - loss: 0.6067 - accuracy: 0.6831\n",
            "Epoch 9/150\n",
            "691/691 [==============================] - 0s 125us/step - loss: 0.5967 - accuracy: 0.6802\n",
            "Epoch 10/150\n",
            "691/691 [==============================] - 0s 110us/step - loss: 0.6054 - accuracy: 0.6918\n",
            "Epoch 11/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.5951 - accuracy: 0.6787\n",
            "Epoch 12/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.5928 - accuracy: 0.6816\n",
            "Epoch 13/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.5953 - accuracy: 0.6787\n",
            "Epoch 14/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.5867 - accuracy: 0.6990\n",
            "Epoch 15/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.5829 - accuracy: 0.7004\n",
            "Epoch 16/150\n",
            "691/691 [==============================] - 0s 109us/step - loss: 0.5851 - accuracy: 0.6758\n",
            "Epoch 17/150\n",
            "691/691 [==============================] - 0s 118us/step - loss: 0.5870 - accuracy: 0.6903\n",
            "Epoch 18/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.5757 - accuracy: 0.7048\n",
            "Epoch 19/150\n",
            "691/691 [==============================] - 0s 109us/step - loss: 0.5808 - accuracy: 0.7019\n",
            "Epoch 20/150\n",
            "691/691 [==============================] - 0s 110us/step - loss: 0.5808 - accuracy: 0.7004\n",
            "Epoch 21/150\n",
            "691/691 [==============================] - 0s 116us/step - loss: 0.5731 - accuracy: 0.6961\n",
            "Epoch 22/150\n",
            "691/691 [==============================] - 0s 119us/step - loss: 0.5682 - accuracy: 0.7048\n",
            "Epoch 23/150\n",
            "691/691 [==============================] - 0s 109us/step - loss: 0.5759 - accuracy: 0.6990\n",
            "Epoch 24/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.5696 - accuracy: 0.7048\n",
            "Epoch 25/150\n",
            "691/691 [==============================] - 0s 117us/step - loss: 0.5637 - accuracy: 0.7106\n",
            "Epoch 26/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.5763 - accuracy: 0.7135\n",
            "Epoch 27/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.5708 - accuracy: 0.7236\n",
            "Epoch 28/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.5661 - accuracy: 0.7077\n",
            "Epoch 29/150\n",
            "691/691 [==============================] - 0s 120us/step - loss: 0.5685 - accuracy: 0.7120\n",
            "Epoch 30/150\n",
            "691/691 [==============================] - 0s 125us/step - loss: 0.5651 - accuracy: 0.7091\n",
            "Epoch 31/150\n",
            "691/691 [==============================] - 0s 116us/step - loss: 0.5587 - accuracy: 0.7221\n",
            "Epoch 32/150\n",
            "691/691 [==============================] - 0s 110us/step - loss: 0.5587 - accuracy: 0.7149\n",
            "Epoch 33/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.5586 - accuracy: 0.7164\n",
            "Epoch 34/150\n",
            "691/691 [==============================] - 0s 116us/step - loss: 0.5649 - accuracy: 0.7077\n",
            "Epoch 35/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.5572 - accuracy: 0.7192\n",
            "Epoch 36/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.5600 - accuracy: 0.7250\n",
            "Epoch 37/150\n",
            "691/691 [==============================] - 0s 118us/step - loss: 0.5602 - accuracy: 0.7077\n",
            "Epoch 38/150\n",
            "691/691 [==============================] - 0s 130us/step - loss: 0.5574 - accuracy: 0.7250\n",
            "Epoch 39/150\n",
            "691/691 [==============================] - 0s 141us/step - loss: 0.5645 - accuracy: 0.7164\n",
            "Epoch 40/150\n",
            "691/691 [==============================] - 0s 135us/step - loss: 0.5501 - accuracy: 0.7178\n",
            "Epoch 41/150\n",
            "691/691 [==============================] - 0s 130us/step - loss: 0.5606 - accuracy: 0.7178\n",
            "Epoch 42/150\n",
            "691/691 [==============================] - 0s 140us/step - loss: 0.5517 - accuracy: 0.7279\n",
            "Epoch 43/150\n",
            "691/691 [==============================] - 0s 129us/step - loss: 0.5544 - accuracy: 0.7221\n",
            "Epoch 44/150\n",
            "691/691 [==============================] - 0s 141us/step - loss: 0.5521 - accuracy: 0.7221\n",
            "Epoch 45/150\n",
            "691/691 [==============================] - 0s 128us/step - loss: 0.5481 - accuracy: 0.7265\n",
            "Epoch 46/150\n",
            "691/691 [==============================] - 0s 115us/step - loss: 0.5443 - accuracy: 0.7265\n",
            "Epoch 47/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.5557 - accuracy: 0.7250\n",
            "Epoch 48/150\n",
            "691/691 [==============================] - 0s 127us/step - loss: 0.5507 - accuracy: 0.7308\n",
            "Epoch 49/150\n",
            "691/691 [==============================] - 0s 115us/step - loss: 0.5442 - accuracy: 0.7279\n",
            "Epoch 50/150\n",
            "691/691 [==============================] - 0s 116us/step - loss: 0.5486 - accuracy: 0.7019\n",
            "Epoch 51/150\n",
            "691/691 [==============================] - 0s 131us/step - loss: 0.5477 - accuracy: 0.7467\n",
            "Epoch 52/150\n",
            "691/691 [==============================] - 0s 110us/step - loss: 0.5444 - accuracy: 0.7337\n",
            "Epoch 53/150\n",
            "691/691 [==============================] - 0s 119us/step - loss: 0.5428 - accuracy: 0.7265\n",
            "Epoch 54/150\n",
            "691/691 [==============================] - 0s 116us/step - loss: 0.5387 - accuracy: 0.7221\n",
            "Epoch 55/150\n",
            "691/691 [==============================] - 0s 115us/step - loss: 0.5348 - accuracy: 0.7308\n",
            "Epoch 56/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.5484 - accuracy: 0.7207\n",
            "Epoch 57/150\n",
            "691/691 [==============================] - 0s 116us/step - loss: 0.5411 - accuracy: 0.7323\n",
            "Epoch 58/150\n",
            "691/691 [==============================] - 0s 115us/step - loss: 0.5353 - accuracy: 0.7467\n",
            "Epoch 59/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.5342 - accuracy: 0.7410\n",
            "Epoch 60/150\n",
            "691/691 [==============================] - 0s 116us/step - loss: 0.5308 - accuracy: 0.7265\n",
            "Epoch 61/150\n",
            "691/691 [==============================] - 0s 120us/step - loss: 0.5351 - accuracy: 0.7381\n",
            "Epoch 62/150\n",
            "691/691 [==============================] - 0s 117us/step - loss: 0.5371 - accuracy: 0.7352\n",
            "Epoch 63/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.5325 - accuracy: 0.7438\n",
            "Epoch 64/150\n",
            "691/691 [==============================] - 0s 115us/step - loss: 0.5402 - accuracy: 0.7323\n",
            "Epoch 65/150\n",
            "691/691 [==============================] - 0s 115us/step - loss: 0.5320 - accuracy: 0.7279\n",
            "Epoch 66/150\n",
            "691/691 [==============================] - 0s 119us/step - loss: 0.5327 - accuracy: 0.7366\n",
            "Epoch 67/150\n",
            "691/691 [==============================] - 0s 115us/step - loss: 0.5274 - accuracy: 0.7410\n",
            "Epoch 68/150\n",
            "691/691 [==============================] - 0s 120us/step - loss: 0.5211 - accuracy: 0.7525\n",
            "Epoch 69/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.5210 - accuracy: 0.7496\n",
            "Epoch 70/150\n",
            "691/691 [==============================] - 0s 116us/step - loss: 0.5285 - accuracy: 0.7337\n",
            "Epoch 71/150\n",
            "691/691 [==============================] - 0s 128us/step - loss: 0.5253 - accuracy: 0.7366\n",
            "Epoch 72/150\n",
            "691/691 [==============================] - 0s 122us/step - loss: 0.5191 - accuracy: 0.7467\n",
            "Epoch 73/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.5350 - accuracy: 0.7410\n",
            "Epoch 74/150\n",
            "691/691 [==============================] - 0s 116us/step - loss: 0.5261 - accuracy: 0.7496\n",
            "Epoch 75/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.5166 - accuracy: 0.7511\n",
            "Epoch 76/150\n",
            "691/691 [==============================] - 0s 125us/step - loss: 0.5161 - accuracy: 0.7554\n",
            "Epoch 77/150\n",
            "691/691 [==============================] - 0s 121us/step - loss: 0.5173 - accuracy: 0.7424\n",
            "Epoch 78/150\n",
            "691/691 [==============================] - 0s 118us/step - loss: 0.5171 - accuracy: 0.7511\n",
            "Epoch 79/150\n",
            "691/691 [==============================] - 0s 115us/step - loss: 0.5179 - accuracy: 0.7381\n",
            "Epoch 80/150\n",
            "691/691 [==============================] - 0s 116us/step - loss: 0.5101 - accuracy: 0.7554\n",
            "Epoch 81/150\n",
            "691/691 [==============================] - 0s 116us/step - loss: 0.5157 - accuracy: 0.7598\n",
            "Epoch 82/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.5122 - accuracy: 0.7410\n",
            "Epoch 83/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.5155 - accuracy: 0.7424\n",
            "Epoch 84/150\n",
            "691/691 [==============================] - 0s 120us/step - loss: 0.5199 - accuracy: 0.7496\n",
            "Epoch 85/150\n",
            "691/691 [==============================] - 0s 126us/step - loss: 0.5134 - accuracy: 0.7569\n",
            "Epoch 86/150\n",
            "691/691 [==============================] - 0s 117us/step - loss: 0.5095 - accuracy: 0.7496\n",
            "Epoch 87/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.5033 - accuracy: 0.7627\n",
            "Epoch 88/150\n",
            "691/691 [==============================] - 0s 115us/step - loss: 0.5054 - accuracy: 0.7598\n",
            "Epoch 89/150\n",
            "691/691 [==============================] - 0s 115us/step - loss: 0.5035 - accuracy: 0.7670\n",
            "Epoch 90/150\n",
            "691/691 [==============================] - 0s 120us/step - loss: 0.5070 - accuracy: 0.7381\n",
            "Epoch 91/150\n",
            "691/691 [==============================] - 0s 110us/step - loss: 0.5019 - accuracy: 0.7583\n",
            "Epoch 92/150\n",
            "691/691 [==============================] - 0s 117us/step - loss: 0.5025 - accuracy: 0.7641\n",
            "Epoch 93/150\n",
            "691/691 [==============================] - 0s 116us/step - loss: 0.5021 - accuracy: 0.7525\n",
            "Epoch 94/150\n",
            "691/691 [==============================] - 0s 117us/step - loss: 0.5051 - accuracy: 0.7699\n",
            "Epoch 95/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.5039 - accuracy: 0.7554\n",
            "Epoch 96/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.5009 - accuracy: 0.7728\n",
            "Epoch 97/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.4983 - accuracy: 0.7641\n",
            "Epoch 98/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.5199 - accuracy: 0.7395\n",
            "Epoch 99/150\n",
            "691/691 [==============================] - 0s 117us/step - loss: 0.4937 - accuracy: 0.7685\n",
            "Epoch 100/150\n",
            "691/691 [==============================] - 0s 117us/step - loss: 0.5073 - accuracy: 0.7699\n",
            "Epoch 101/150\n",
            "691/691 [==============================] - 0s 115us/step - loss: 0.4963 - accuracy: 0.7598\n",
            "Epoch 102/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.4952 - accuracy: 0.7728\n",
            "Epoch 103/150\n",
            "691/691 [==============================] - 0s 120us/step - loss: 0.4908 - accuracy: 0.7742\n",
            "Epoch 104/150\n",
            "691/691 [==============================] - 0s 115us/step - loss: 0.5120 - accuracy: 0.7728\n",
            "Epoch 105/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.4942 - accuracy: 0.7641\n",
            "Epoch 106/150\n",
            "691/691 [==============================] - 0s 118us/step - loss: 0.4912 - accuracy: 0.7786\n",
            "Epoch 107/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.5019 - accuracy: 0.7742\n",
            "Epoch 108/150\n",
            "691/691 [==============================] - 0s 118us/step - loss: 0.4997 - accuracy: 0.7641\n",
            "Epoch 109/150\n",
            "691/691 [==============================] - 0s 124us/step - loss: 0.5031 - accuracy: 0.7511\n",
            "Epoch 110/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.5021 - accuracy: 0.7786\n",
            "Epoch 111/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.4897 - accuracy: 0.7641\n",
            "Epoch 112/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.4853 - accuracy: 0.7728\n",
            "Epoch 113/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.4941 - accuracy: 0.7612\n",
            "Epoch 114/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.4919 - accuracy: 0.7670\n",
            "Epoch 115/150\n",
            "691/691 [==============================] - 0s 118us/step - loss: 0.5028 - accuracy: 0.7525\n",
            "Epoch 116/150\n",
            "691/691 [==============================] - 0s 118us/step - loss: 0.4858 - accuracy: 0.7699\n",
            "Epoch 117/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.4944 - accuracy: 0.7627\n",
            "Epoch 118/150\n",
            "691/691 [==============================] - 0s 115us/step - loss: 0.4815 - accuracy: 0.7742\n",
            "Epoch 119/150\n",
            "691/691 [==============================] - 0s 127us/step - loss: 0.4916 - accuracy: 0.7685\n",
            "Epoch 120/150\n",
            "691/691 [==============================] - 0s 139us/step - loss: 0.4842 - accuracy: 0.7742\n",
            "Epoch 121/150\n",
            "691/691 [==============================] - 0s 115us/step - loss: 0.4895 - accuracy: 0.7612\n",
            "Epoch 122/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.4850 - accuracy: 0.7685\n",
            "Epoch 123/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.4857 - accuracy: 0.7699\n",
            "Epoch 124/150\n",
            "691/691 [==============================] - 0s 116us/step - loss: 0.4795 - accuracy: 0.7771\n",
            "Epoch 125/150\n",
            "691/691 [==============================] - 0s 115us/step - loss: 0.4779 - accuracy: 0.7829\n",
            "Epoch 126/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.4875 - accuracy: 0.7699\n",
            "Epoch 127/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.4882 - accuracy: 0.7713\n",
            "Epoch 128/150\n",
            "691/691 [==============================] - 0s 119us/step - loss: 0.4704 - accuracy: 0.7815\n",
            "Epoch 129/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.4841 - accuracy: 0.7757\n",
            "Epoch 130/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.4818 - accuracy: 0.7786\n",
            "Epoch 131/150\n",
            "691/691 [==============================] - 0s 118us/step - loss: 0.4787 - accuracy: 0.7656\n",
            "Epoch 132/150\n",
            "691/691 [==============================] - 0s 122us/step - loss: 0.4790 - accuracy: 0.7757\n",
            "Epoch 133/150\n",
            "691/691 [==============================] - 0s 117us/step - loss: 0.4866 - accuracy: 0.7713\n",
            "Epoch 134/150\n",
            "691/691 [==============================] - 0s 133us/step - loss: 0.4935 - accuracy: 0.7569\n",
            "Epoch 135/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.4703 - accuracy: 0.7656\n",
            "Epoch 136/150\n",
            "691/691 [==============================] - 0s 115us/step - loss: 0.4751 - accuracy: 0.7685\n",
            "Epoch 137/150\n",
            "691/691 [==============================] - 0s 117us/step - loss: 0.4941 - accuracy: 0.7627\n",
            "Epoch 138/150\n",
            "691/691 [==============================] - 0s 119us/step - loss: 0.4717 - accuracy: 0.7786\n",
            "Epoch 139/150\n",
            "691/691 [==============================] - 0s 124us/step - loss: 0.4775 - accuracy: 0.7786\n",
            "Epoch 140/150\n",
            "691/691 [==============================] - 0s 117us/step - loss: 0.4698 - accuracy: 0.7742\n",
            "Epoch 141/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.4695 - accuracy: 0.7887\n",
            "Epoch 142/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.4884 - accuracy: 0.7771\n",
            "Epoch 143/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.4743 - accuracy: 0.7786\n",
            "Epoch 144/150\n",
            "691/691 [==============================] - 0s 115us/step - loss: 0.4748 - accuracy: 0.7627\n",
            "Epoch 145/150\n",
            "691/691 [==============================] - 0s 117us/step - loss: 0.4690 - accuracy: 0.7887\n",
            "Epoch 146/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.4793 - accuracy: 0.7699\n",
            "Epoch 147/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.4752 - accuracy: 0.7829\n",
            "Epoch 148/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.4797 - accuracy: 0.7728\n",
            "Epoch 149/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.4677 - accuracy: 0.7858\n",
            "Epoch 150/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.4630 - accuracy: 0.7844\n",
            "77/77 [==============================] - 0s 310us/step\n",
            "Epoch 1/150\n",
            "691/691 [==============================] - 0s 244us/step - loss: 0.6862 - accuracy: 0.6223\n",
            "Epoch 2/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.6681 - accuracy: 0.6512\n",
            "Epoch 3/150\n",
            "691/691 [==============================] - 0s 110us/step - loss: 0.6617 - accuracy: 0.6512\n",
            "Epoch 4/150\n",
            "691/691 [==============================] - 0s 109us/step - loss: 0.6560 - accuracy: 0.6512\n",
            "Epoch 5/150\n",
            "691/691 [==============================] - 0s 106us/step - loss: 0.6496 - accuracy: 0.6498\n",
            "Epoch 6/150\n",
            "691/691 [==============================] - 0s 116us/step - loss: 0.6397 - accuracy: 0.6758\n",
            "Epoch 7/150\n",
            "691/691 [==============================] - 0s 110us/step - loss: 0.6252 - accuracy: 0.6715\n",
            "Epoch 8/150\n",
            "691/691 [==============================] - 0s 108us/step - loss: 0.6207 - accuracy: 0.6758\n",
            "Epoch 9/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.6086 - accuracy: 0.6628\n",
            "Epoch 10/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.5994 - accuracy: 0.6932\n",
            "Epoch 11/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.5993 - accuracy: 0.6816\n",
            "Epoch 12/150\n",
            "691/691 [==============================] - 0s 131us/step - loss: 0.5920 - accuracy: 0.6932\n",
            "Epoch 13/150\n",
            "691/691 [==============================] - 0s 119us/step - loss: 0.5851 - accuracy: 0.6961\n",
            "Epoch 14/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.6007 - accuracy: 0.6816\n",
            "Epoch 15/150\n",
            "691/691 [==============================] - 0s 115us/step - loss: 0.5803 - accuracy: 0.7062\n",
            "Epoch 16/150\n",
            "691/691 [==============================] - 0s 110us/step - loss: 0.5781 - accuracy: 0.7033\n",
            "Epoch 17/150\n",
            "691/691 [==============================] - 0s 110us/step - loss: 0.5777 - accuracy: 0.7019\n",
            "Epoch 18/150\n",
            "691/691 [==============================] - 0s 109us/step - loss: 0.5818 - accuracy: 0.7091\n",
            "Epoch 19/150\n",
            "691/691 [==============================] - 0s 122us/step - loss: 0.5744 - accuracy: 0.6990\n",
            "Epoch 20/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.5796 - accuracy: 0.6961\n",
            "Epoch 21/150\n",
            "691/691 [==============================] - 0s 120us/step - loss: 0.5666 - accuracy: 0.7135\n",
            "Epoch 22/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.5754 - accuracy: 0.7019\n",
            "Epoch 23/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.5679 - accuracy: 0.7192\n",
            "Epoch 24/150\n",
            "691/691 [==============================] - 0s 117us/step - loss: 0.5735 - accuracy: 0.7207\n",
            "Epoch 25/150\n",
            "691/691 [==============================] - 0s 130us/step - loss: 0.5695 - accuracy: 0.7250\n",
            "Epoch 26/150\n",
            "691/691 [==============================] - 0s 121us/step - loss: 0.5630 - accuracy: 0.7120\n",
            "Epoch 27/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.5596 - accuracy: 0.7207\n",
            "Epoch 28/150\n",
            "691/691 [==============================] - 0s 115us/step - loss: 0.5614 - accuracy: 0.7106\n",
            "Epoch 29/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.5568 - accuracy: 0.7164\n",
            "Epoch 30/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.5620 - accuracy: 0.7135\n",
            "Epoch 31/150\n",
            "691/691 [==============================] - 0s 118us/step - loss: 0.5614 - accuracy: 0.7106\n",
            "Epoch 32/150\n",
            "691/691 [==============================] - 0s 117us/step - loss: 0.5566 - accuracy: 0.7192\n",
            "Epoch 33/150\n",
            "691/691 [==============================] - 0s 117us/step - loss: 0.5632 - accuracy: 0.7178\n",
            "Epoch 34/150\n",
            "691/691 [==============================] - 0s 132us/step - loss: 0.5521 - accuracy: 0.7265\n",
            "Epoch 35/150\n",
            "691/691 [==============================] - 0s 125us/step - loss: 0.5562 - accuracy: 0.7323\n",
            "Epoch 36/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.5505 - accuracy: 0.7438\n",
            "Epoch 37/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.5618 - accuracy: 0.7337\n",
            "Epoch 38/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.5512 - accuracy: 0.7178\n",
            "Epoch 39/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.5502 - accuracy: 0.7323\n",
            "Epoch 40/150\n",
            "691/691 [==============================] - 0s 120us/step - loss: 0.5482 - accuracy: 0.7410\n",
            "Epoch 41/150\n",
            "691/691 [==============================] - 0s 115us/step - loss: 0.5444 - accuracy: 0.7236\n",
            "Epoch 42/150\n",
            "691/691 [==============================] - 0s 115us/step - loss: 0.5439 - accuracy: 0.7236\n",
            "Epoch 43/150\n",
            "691/691 [==============================] - 0s 136us/step - loss: 0.5429 - accuracy: 0.7496\n",
            "Epoch 44/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.5439 - accuracy: 0.7323\n",
            "Epoch 45/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.5460 - accuracy: 0.7337\n",
            "Epoch 46/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.5406 - accuracy: 0.7410\n",
            "Epoch 47/150\n",
            "691/691 [==============================] - 0s 119us/step - loss: 0.5431 - accuracy: 0.7467\n",
            "Epoch 48/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.5387 - accuracy: 0.7554\n",
            "Epoch 49/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.5395 - accuracy: 0.7381\n",
            "Epoch 50/150\n",
            "691/691 [==============================] - 0s 123us/step - loss: 0.5332 - accuracy: 0.7265\n",
            "Epoch 51/150\n",
            "691/691 [==============================] - 0s 129us/step - loss: 0.5347 - accuracy: 0.7453\n",
            "Epoch 52/150\n",
            "691/691 [==============================] - 0s 134us/step - loss: 0.5361 - accuracy: 0.7496\n",
            "Epoch 53/150\n",
            "691/691 [==============================] - 0s 132us/step - loss: 0.5344 - accuracy: 0.7525\n",
            "Epoch 54/150\n",
            "691/691 [==============================] - 0s 132us/step - loss: 0.5368 - accuracy: 0.7308\n",
            "Epoch 55/150\n",
            "691/691 [==============================] - 0s 138us/step - loss: 0.5281 - accuracy: 0.7410\n",
            "Epoch 56/150\n",
            "691/691 [==============================] - 0s 132us/step - loss: 0.5312 - accuracy: 0.7395\n",
            "Epoch 57/150\n",
            "691/691 [==============================] - 0s 117us/step - loss: 0.5318 - accuracy: 0.7366\n",
            "Epoch 58/150\n",
            "691/691 [==============================] - 0s 119us/step - loss: 0.5296 - accuracy: 0.7467\n",
            "Epoch 59/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.5304 - accuracy: 0.7583\n",
            "Epoch 60/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.5259 - accuracy: 0.7467\n",
            "Epoch 61/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.5284 - accuracy: 0.7583\n",
            "Epoch 62/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.5281 - accuracy: 0.7453\n",
            "Epoch 63/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.5226 - accuracy: 0.7612\n",
            "Epoch 64/150\n",
            "691/691 [==============================] - 0s 110us/step - loss: 0.5203 - accuracy: 0.7496\n",
            "Epoch 65/150\n",
            "691/691 [==============================] - 0s 122us/step - loss: 0.5177 - accuracy: 0.7641\n",
            "Epoch 66/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.5186 - accuracy: 0.7525\n",
            "Epoch 67/150\n",
            "691/691 [==============================] - 0s 119us/step - loss: 0.5194 - accuracy: 0.7496\n",
            "Epoch 68/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.5180 - accuracy: 0.7670\n",
            "Epoch 69/150\n",
            "691/691 [==============================] - 0s 116us/step - loss: 0.5161 - accuracy: 0.7598\n",
            "Epoch 70/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.5204 - accuracy: 0.7540\n",
            "Epoch 71/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.5136 - accuracy: 0.7685\n",
            "Epoch 72/150\n",
            "691/691 [==============================] - 0s 121us/step - loss: 0.5110 - accuracy: 0.7713\n",
            "Epoch 73/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.5109 - accuracy: 0.7641\n",
            "Epoch 74/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.5181 - accuracy: 0.7583\n",
            "Epoch 75/150\n",
            "691/691 [==============================] - 0s 110us/step - loss: 0.5138 - accuracy: 0.7540\n",
            "Epoch 76/150\n",
            "691/691 [==============================] - 0s 110us/step - loss: 0.5112 - accuracy: 0.7540\n",
            "Epoch 77/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.5084 - accuracy: 0.7569\n",
            "Epoch 78/150\n",
            "691/691 [==============================] - 0s 117us/step - loss: 0.5072 - accuracy: 0.7685\n",
            "Epoch 79/150\n",
            "691/691 [==============================] - 0s 132us/step - loss: 0.5074 - accuracy: 0.7656\n",
            "Epoch 80/150\n",
            "691/691 [==============================] - 0s 163us/step - loss: 0.5010 - accuracy: 0.7728\n",
            "Epoch 81/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.4987 - accuracy: 0.7685\n",
            "Epoch 82/150\n",
            "691/691 [==============================] - 0s 130us/step - loss: 0.4970 - accuracy: 0.7699\n",
            "Epoch 83/150\n",
            "691/691 [==============================] - 0s 122us/step - loss: 0.5034 - accuracy: 0.7728\n",
            "Epoch 84/150\n",
            "691/691 [==============================] - 0s 115us/step - loss: 0.4905 - accuracy: 0.7844\n",
            "Epoch 85/150\n",
            "691/691 [==============================] - 0s 121us/step - loss: 0.4959 - accuracy: 0.7757\n",
            "Epoch 86/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.4978 - accuracy: 0.7612\n",
            "Epoch 87/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.4928 - accuracy: 0.7612\n",
            "Epoch 88/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.4880 - accuracy: 0.7728\n",
            "Epoch 89/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.4929 - accuracy: 0.7742\n",
            "Epoch 90/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.4881 - accuracy: 0.7829\n",
            "Epoch 91/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.4815 - accuracy: 0.7873\n",
            "Epoch 92/150\n",
            "691/691 [==============================] - 0s 118us/step - loss: 0.4867 - accuracy: 0.7670\n",
            "Epoch 93/150\n",
            "691/691 [==============================] - 0s 120us/step - loss: 0.4851 - accuracy: 0.7800\n",
            "Epoch 94/150\n",
            "691/691 [==============================] - 0s 129us/step - loss: 0.4872 - accuracy: 0.7771\n",
            "Epoch 95/150\n",
            "691/691 [==============================] - 0s 117us/step - loss: 0.4837 - accuracy: 0.7685\n",
            "Epoch 96/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.4838 - accuracy: 0.7699\n",
            "Epoch 97/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.4823 - accuracy: 0.7713\n",
            "Epoch 98/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.4763 - accuracy: 0.7858\n",
            "Epoch 99/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.4744 - accuracy: 0.7988\n",
            "Epoch 100/150\n",
            "691/691 [==============================] - 0s 110us/step - loss: 0.4773 - accuracy: 0.7757\n",
            "Epoch 101/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.4728 - accuracy: 0.7902\n",
            "Epoch 102/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.4751 - accuracy: 0.7742\n",
            "Epoch 103/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.4741 - accuracy: 0.7757\n",
            "Epoch 104/150\n",
            "691/691 [==============================] - 0s 117us/step - loss: 0.4686 - accuracy: 0.7858\n",
            "Epoch 105/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.4687 - accuracy: 0.7858\n",
            "Epoch 106/150\n",
            "691/691 [==============================] - 0s 115us/step - loss: 0.4850 - accuracy: 0.7713\n",
            "Epoch 107/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.4705 - accuracy: 0.7786\n",
            "Epoch 108/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.4785 - accuracy: 0.7757\n",
            "Epoch 109/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.4734 - accuracy: 0.7786\n",
            "Epoch 110/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.4688 - accuracy: 0.7844\n",
            "Epoch 111/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.4664 - accuracy: 0.7873\n",
            "Epoch 112/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.4730 - accuracy: 0.7757\n",
            "Epoch 113/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.4694 - accuracy: 0.7815\n",
            "Epoch 114/150\n",
            "691/691 [==============================] - 0s 110us/step - loss: 0.4673 - accuracy: 0.7916\n",
            "Epoch 115/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.4750 - accuracy: 0.7800\n",
            "Epoch 116/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.4629 - accuracy: 0.7858\n",
            "Epoch 117/150\n",
            "691/691 [==============================] - 0s 125us/step - loss: 0.4579 - accuracy: 0.7974\n",
            "Epoch 118/150\n",
            "691/691 [==============================] - 0s 108us/step - loss: 0.4834 - accuracy: 0.7656\n",
            "Epoch 119/150\n",
            "691/691 [==============================] - 0s 116us/step - loss: 0.4662 - accuracy: 0.7844\n",
            "Epoch 120/150\n",
            "691/691 [==============================] - 0s 124us/step - loss: 0.4534 - accuracy: 0.7931\n",
            "Epoch 121/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.4616 - accuracy: 0.7959\n",
            "Epoch 122/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.4674 - accuracy: 0.7829\n",
            "Epoch 123/150\n",
            "691/691 [==============================] - 0s 118us/step - loss: 0.4551 - accuracy: 0.7873\n",
            "Epoch 124/150\n",
            "691/691 [==============================] - 0s 116us/step - loss: 0.4633 - accuracy: 0.7902\n",
            "Epoch 125/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.4575 - accuracy: 0.7873\n",
            "Epoch 126/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.4559 - accuracy: 0.7902\n",
            "Epoch 127/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.4657 - accuracy: 0.7844\n",
            "Epoch 128/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.4498 - accuracy: 0.7887\n",
            "Epoch 129/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.4542 - accuracy: 0.7931\n",
            "Epoch 130/150\n",
            "691/691 [==============================] - 0s 119us/step - loss: 0.4483 - accuracy: 0.8090\n",
            "Epoch 131/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.4526 - accuracy: 0.7931\n",
            "Epoch 132/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.4460 - accuracy: 0.8003\n",
            "Epoch 133/150\n",
            "691/691 [==============================] - 0s 123us/step - loss: 0.4514 - accuracy: 0.7945\n",
            "Epoch 134/150\n",
            "691/691 [==============================] - 0s 110us/step - loss: 0.4542 - accuracy: 0.7742\n",
            "Epoch 135/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.4416 - accuracy: 0.8017\n",
            "Epoch 136/150\n",
            "691/691 [==============================] - 0s 110us/step - loss: 0.4526 - accuracy: 0.7829\n",
            "Epoch 137/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.4517 - accuracy: 0.7887\n",
            "Epoch 138/150\n",
            "691/691 [==============================] - 0s 117us/step - loss: 0.4495 - accuracy: 0.7974\n",
            "Epoch 139/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.4414 - accuracy: 0.7988\n",
            "Epoch 140/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.4499 - accuracy: 0.8003\n",
            "Epoch 141/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.4568 - accuracy: 0.7786\n",
            "Epoch 142/150\n",
            "691/691 [==============================] - 0s 120us/step - loss: 0.4489 - accuracy: 0.7902\n",
            "Epoch 143/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.4478 - accuracy: 0.7974\n",
            "Epoch 144/150\n",
            "691/691 [==============================] - 0s 117us/step - loss: 0.4424 - accuracy: 0.7959\n",
            "Epoch 145/150\n",
            "691/691 [==============================] - 0s 115us/step - loss: 0.4470 - accuracy: 0.7931\n",
            "Epoch 146/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.4439 - accuracy: 0.7858\n",
            "Epoch 147/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.4456 - accuracy: 0.7858\n",
            "Epoch 148/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.4458 - accuracy: 0.7873\n",
            "Epoch 149/150\n",
            "691/691 [==============================] - 0s 123us/step - loss: 0.4450 - accuracy: 0.7829\n",
            "Epoch 150/150\n",
            "691/691 [==============================] - 0s 118us/step - loss: 0.4400 - accuracy: 0.7988\n",
            "77/77 [==============================] - 0s 297us/step\n",
            "Epoch 1/150\n",
            "691/691 [==============================] - 0s 260us/step - loss: 0.6775 - accuracy: 0.6512\n",
            "Epoch 2/150\n",
            "691/691 [==============================] - 0s 110us/step - loss: 0.6648 - accuracy: 0.6512\n",
            "Epoch 3/150\n",
            "691/691 [==============================] - 0s 109us/step - loss: 0.6570 - accuracy: 0.6512\n",
            "Epoch 4/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.6485 - accuracy: 0.6512\n",
            "Epoch 5/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.6365 - accuracy: 0.6512\n",
            "Epoch 6/150\n",
            "691/691 [==============================] - 0s 109us/step - loss: 0.6156 - accuracy: 0.6816\n",
            "Epoch 7/150\n",
            "691/691 [==============================] - 0s 110us/step - loss: 0.6151 - accuracy: 0.6758\n",
            "Epoch 8/150\n",
            "691/691 [==============================] - 0s 119us/step - loss: 0.5933 - accuracy: 0.6990\n",
            "Epoch 9/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.5991 - accuracy: 0.6903\n",
            "Epoch 10/150\n",
            "691/691 [==============================] - 0s 119us/step - loss: 0.5836 - accuracy: 0.7019\n",
            "Epoch 11/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.5759 - accuracy: 0.7178\n",
            "Epoch 12/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.5745 - accuracy: 0.7033\n",
            "Epoch 13/150\n",
            "691/691 [==============================] - 0s 131us/step - loss: 0.5737 - accuracy: 0.7091\n",
            "Epoch 14/150\n",
            "691/691 [==============================] - 0s 125us/step - loss: 0.5691 - accuracy: 0.7033\n",
            "Epoch 15/150\n",
            "691/691 [==============================] - 0s 117us/step - loss: 0.5630 - accuracy: 0.7164\n",
            "Epoch 16/150\n",
            "691/691 [==============================] - 0s 115us/step - loss: 0.5672 - accuracy: 0.7120\n",
            "Epoch 17/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.5715 - accuracy: 0.7033\n",
            "Epoch 18/150\n",
            "691/691 [==============================] - 0s 109us/step - loss: 0.5634 - accuracy: 0.6990\n",
            "Epoch 19/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.5649 - accuracy: 0.6990\n",
            "Epoch 20/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.5629 - accuracy: 0.7178\n",
            "Epoch 21/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.5592 - accuracy: 0.7221\n",
            "Epoch 22/150\n",
            "691/691 [==============================] - 0s 115us/step - loss: 0.5618 - accuracy: 0.7178\n",
            "Epoch 23/150\n",
            "691/691 [==============================] - 0s 115us/step - loss: 0.5557 - accuracy: 0.7048\n",
            "Epoch 24/150\n",
            "691/691 [==============================] - 0s 118us/step - loss: 0.5544 - accuracy: 0.7236\n",
            "Epoch 25/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.5672 - accuracy: 0.7207\n",
            "Epoch 26/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.5544 - accuracy: 0.7149\n",
            "Epoch 27/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.5536 - accuracy: 0.7077\n",
            "Epoch 28/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.5556 - accuracy: 0.7106\n",
            "Epoch 29/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.5486 - accuracy: 0.7164\n",
            "Epoch 30/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.5503 - accuracy: 0.7135\n",
            "Epoch 31/150\n",
            "691/691 [==============================] - 0s 119us/step - loss: 0.5485 - accuracy: 0.7236\n",
            "Epoch 32/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.5435 - accuracy: 0.7308\n",
            "Epoch 33/150\n",
            "691/691 [==============================] - 0s 110us/step - loss: 0.5406 - accuracy: 0.7236\n",
            "Epoch 34/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.5487 - accuracy: 0.7120\n",
            "Epoch 35/150\n",
            "691/691 [==============================] - 0s 118us/step - loss: 0.5470 - accuracy: 0.7221\n",
            "Epoch 36/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.5401 - accuracy: 0.7250\n",
            "Epoch 37/150\n",
            "691/691 [==============================] - 0s 119us/step - loss: 0.5493 - accuracy: 0.7033\n",
            "Epoch 38/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.5466 - accuracy: 0.7294\n",
            "Epoch 39/150\n",
            "691/691 [==============================] - 0s 116us/step - loss: 0.5347 - accuracy: 0.7467\n",
            "Epoch 40/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.5411 - accuracy: 0.7221\n",
            "Epoch 41/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.5365 - accuracy: 0.7352\n",
            "Epoch 42/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.5349 - accuracy: 0.7352\n",
            "Epoch 43/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.5375 - accuracy: 0.7410\n",
            "Epoch 44/150\n",
            "691/691 [==============================] - 0s 115us/step - loss: 0.5282 - accuracy: 0.7438\n",
            "Epoch 45/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.5354 - accuracy: 0.7453\n",
            "Epoch 46/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.5387 - accuracy: 0.7221\n",
            "Epoch 47/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.5276 - accuracy: 0.7467\n",
            "Epoch 48/150\n",
            "691/691 [==============================] - 0s 120us/step - loss: 0.5266 - accuracy: 0.7366\n",
            "Epoch 49/150\n",
            "691/691 [==============================] - 0s 116us/step - loss: 0.5299 - accuracy: 0.7352\n",
            "Epoch 50/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.5249 - accuracy: 0.7467\n",
            "Epoch 51/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.5237 - accuracy: 0.7424\n",
            "Epoch 52/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.5287 - accuracy: 0.7337\n",
            "Epoch 53/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.5199 - accuracy: 0.7482\n",
            "Epoch 54/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.5386 - accuracy: 0.7221\n",
            "Epoch 55/150\n",
            "691/691 [==============================] - 0s 119us/step - loss: 0.5192 - accuracy: 0.7525\n",
            "Epoch 56/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.5150 - accuracy: 0.7410\n",
            "Epoch 57/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.5166 - accuracy: 0.7598\n",
            "Epoch 58/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.5204 - accuracy: 0.7438\n",
            "Epoch 59/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.5082 - accuracy: 0.7496\n",
            "Epoch 60/150\n",
            "691/691 [==============================] - 0s 121us/step - loss: 0.5221 - accuracy: 0.7482\n",
            "Epoch 61/150\n",
            "691/691 [==============================] - 0s 121us/step - loss: 0.5215 - accuracy: 0.7438\n",
            "Epoch 62/150\n",
            "691/691 [==============================] - 0s 119us/step - loss: 0.5164 - accuracy: 0.7511\n",
            "Epoch 63/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.5067 - accuracy: 0.7627\n",
            "Epoch 64/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.5092 - accuracy: 0.7540\n",
            "Epoch 65/150\n",
            "691/691 [==============================] - 0s 109us/step - loss: 0.5154 - accuracy: 0.7496\n",
            "Epoch 66/150\n",
            "691/691 [==============================] - 0s 110us/step - loss: 0.5133 - accuracy: 0.7496\n",
            "Epoch 67/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.5126 - accuracy: 0.7511\n",
            "Epoch 68/150\n",
            "691/691 [==============================] - 0s 110us/step - loss: 0.5087 - accuracy: 0.7583\n",
            "Epoch 69/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.5043 - accuracy: 0.7598\n",
            "Epoch 70/150\n",
            "691/691 [==============================] - 0s 116us/step - loss: 0.5041 - accuracy: 0.7656\n",
            "Epoch 71/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.5207 - accuracy: 0.7569\n",
            "Epoch 72/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.5033 - accuracy: 0.7598\n",
            "Epoch 73/150\n",
            "691/691 [==============================] - 0s 124us/step - loss: 0.5091 - accuracy: 0.7612\n",
            "Epoch 74/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.4980 - accuracy: 0.7569\n",
            "Epoch 75/150\n",
            "691/691 [==============================] - 0s 129us/step - loss: 0.4982 - accuracy: 0.7612\n",
            "Epoch 76/150\n",
            "691/691 [==============================] - 0s 123us/step - loss: 0.5059 - accuracy: 0.7699\n",
            "Epoch 77/150\n",
            "691/691 [==============================] - 0s 109us/step - loss: 0.4957 - accuracy: 0.7757\n",
            "Epoch 78/150\n",
            "691/691 [==============================] - 0s 108us/step - loss: 0.5064 - accuracy: 0.7641\n",
            "Epoch 79/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.5022 - accuracy: 0.7525\n",
            "Epoch 80/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.5042 - accuracy: 0.7699\n",
            "Epoch 81/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.5029 - accuracy: 0.7569\n",
            "Epoch 82/150\n",
            "691/691 [==============================] - 0s 109us/step - loss: 0.4952 - accuracy: 0.7583\n",
            "Epoch 83/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.4983 - accuracy: 0.7627\n",
            "Epoch 84/150\n",
            "691/691 [==============================] - 0s 110us/step - loss: 0.4970 - accuracy: 0.7656\n",
            "Epoch 85/150\n",
            "691/691 [==============================] - 0s 110us/step - loss: 0.4906 - accuracy: 0.7656\n",
            "Epoch 86/150\n",
            "691/691 [==============================] - 0s 120us/step - loss: 0.4939 - accuracy: 0.7583\n",
            "Epoch 87/150\n",
            "691/691 [==============================] - 0s 117us/step - loss: 0.4950 - accuracy: 0.7713\n",
            "Epoch 88/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.4946 - accuracy: 0.7598\n",
            "Epoch 89/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.4873 - accuracy: 0.7670\n",
            "Epoch 90/150\n",
            "691/691 [==============================] - 0s 110us/step - loss: 0.4880 - accuracy: 0.7728\n",
            "Epoch 91/150\n",
            "691/691 [==============================] - 0s 115us/step - loss: 0.4947 - accuracy: 0.7742\n",
            "Epoch 92/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.4892 - accuracy: 0.7583\n",
            "Epoch 93/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.4826 - accuracy: 0.7757\n",
            "Epoch 94/150\n",
            "691/691 [==============================] - 0s 110us/step - loss: 0.4834 - accuracy: 0.7771\n",
            "Epoch 95/150\n",
            "691/691 [==============================] - 0s 116us/step - loss: 0.4917 - accuracy: 0.7627\n",
            "Epoch 96/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.4877 - accuracy: 0.7670\n",
            "Epoch 97/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.4933 - accuracy: 0.7800\n",
            "Epoch 98/150\n",
            "691/691 [==============================] - 0s 115us/step - loss: 0.4930 - accuracy: 0.7656\n",
            "Epoch 99/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.4835 - accuracy: 0.7771\n",
            "Epoch 100/150\n",
            "691/691 [==============================] - 0s 115us/step - loss: 0.4838 - accuracy: 0.7583\n",
            "Epoch 101/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.4813 - accuracy: 0.7728\n",
            "Epoch 102/150\n",
            "691/691 [==============================] - 0s 119us/step - loss: 0.4873 - accuracy: 0.7800\n",
            "Epoch 103/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.4824 - accuracy: 0.7713\n",
            "Epoch 104/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.4746 - accuracy: 0.7829\n",
            "Epoch 105/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.4972 - accuracy: 0.7670\n",
            "Epoch 106/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.4815 - accuracy: 0.7786\n",
            "Epoch 107/150\n",
            "691/691 [==============================] - 0s 128us/step - loss: 0.4750 - accuracy: 0.7873\n",
            "Epoch 108/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.4722 - accuracy: 0.7742\n",
            "Epoch 109/150\n",
            "691/691 [==============================] - 0s 126us/step - loss: 0.4740 - accuracy: 0.7757\n",
            "Epoch 110/150\n",
            "691/691 [==============================] - 0s 120us/step - loss: 0.4836 - accuracy: 0.7598\n",
            "Epoch 111/150\n",
            "691/691 [==============================] - 0s 116us/step - loss: 0.4722 - accuracy: 0.7858\n",
            "Epoch 112/150\n",
            "691/691 [==============================] - 0s 123us/step - loss: 0.4798 - accuracy: 0.7699\n",
            "Epoch 113/150\n",
            "691/691 [==============================] - 0s 129us/step - loss: 0.4853 - accuracy: 0.7540\n",
            "Epoch 114/150\n",
            "691/691 [==============================] - 0s 118us/step - loss: 0.4766 - accuracy: 0.7902\n",
            "Epoch 115/150\n",
            "691/691 [==============================] - 0s 118us/step - loss: 0.4731 - accuracy: 0.7699\n",
            "Epoch 116/150\n",
            "691/691 [==============================] - 0s 135us/step - loss: 0.4858 - accuracy: 0.7656\n",
            "Epoch 117/150\n",
            "691/691 [==============================] - 0s 131us/step - loss: 0.4767 - accuracy: 0.7800\n",
            "Epoch 118/150\n",
            "691/691 [==============================] - 0s 130us/step - loss: 0.4780 - accuracy: 0.7728\n",
            "Epoch 119/150\n",
            "691/691 [==============================] - 0s 136us/step - loss: 0.4703 - accuracy: 0.7728\n",
            "Epoch 120/150\n",
            "691/691 [==============================] - 0s 136us/step - loss: 0.4830 - accuracy: 0.7699\n",
            "Epoch 121/150\n",
            "691/691 [==============================] - 0s 121us/step - loss: 0.4727 - accuracy: 0.7742\n",
            "Epoch 122/150\n",
            "691/691 [==============================] - 0s 131us/step - loss: 0.4702 - accuracy: 0.7844\n",
            "Epoch 123/150\n",
            "691/691 [==============================] - 0s 120us/step - loss: 0.4688 - accuracy: 0.7771\n",
            "Epoch 124/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.4742 - accuracy: 0.7742\n",
            "Epoch 125/150\n",
            "691/691 [==============================] - 0s 110us/step - loss: 0.4687 - accuracy: 0.7786\n",
            "Epoch 126/150\n",
            "691/691 [==============================] - 0s 116us/step - loss: 0.4753 - accuracy: 0.7713\n",
            "Epoch 127/150\n",
            "691/691 [==============================] - 0s 115us/step - loss: 0.4688 - accuracy: 0.7728\n",
            "Epoch 128/150\n",
            "691/691 [==============================] - 0s 117us/step - loss: 0.4732 - accuracy: 0.7815\n",
            "Epoch 129/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.4670 - accuracy: 0.7713\n",
            "Epoch 130/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.4666 - accuracy: 0.7873\n",
            "Epoch 131/150\n",
            "691/691 [==============================] - 0s 115us/step - loss: 0.4694 - accuracy: 0.7800\n",
            "Epoch 132/150\n",
            "691/691 [==============================] - 0s 132us/step - loss: 0.4632 - accuracy: 0.7844\n",
            "Epoch 133/150\n",
            "691/691 [==============================] - 0s 117us/step - loss: 0.4659 - accuracy: 0.7771\n",
            "Epoch 134/150\n",
            "691/691 [==============================] - 0s 122us/step - loss: 0.4630 - accuracy: 0.7844\n",
            "Epoch 135/150\n",
            "691/691 [==============================] - 0s 115us/step - loss: 0.4681 - accuracy: 0.7699\n",
            "Epoch 136/150\n",
            "691/691 [==============================] - 0s 115us/step - loss: 0.4654 - accuracy: 0.7641\n",
            "Epoch 137/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.4613 - accuracy: 0.7800\n",
            "Epoch 138/150\n",
            "691/691 [==============================] - 0s 116us/step - loss: 0.4664 - accuracy: 0.7685\n",
            "Epoch 139/150\n",
            "691/691 [==============================] - 0s 121us/step - loss: 0.4604 - accuracy: 0.7757\n",
            "Epoch 140/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.4637 - accuracy: 0.7728\n",
            "Epoch 141/150\n",
            "691/691 [==============================] - 0s 110us/step - loss: 0.4751 - accuracy: 0.7757\n",
            "Epoch 142/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.4814 - accuracy: 0.7699\n",
            "Epoch 143/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.4622 - accuracy: 0.7858\n",
            "Epoch 144/150\n",
            "691/691 [==============================] - 0s 140us/step - loss: 0.4609 - accuracy: 0.7873\n",
            "Epoch 145/150\n",
            "691/691 [==============================] - 0s 125us/step - loss: 0.4568 - accuracy: 0.7873\n",
            "Epoch 146/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.4639 - accuracy: 0.7699\n",
            "Epoch 147/150\n",
            "691/691 [==============================] - 0s 122us/step - loss: 0.4554 - accuracy: 0.7771\n",
            "Epoch 148/150\n",
            "691/691 [==============================] - 0s 119us/step - loss: 0.4686 - accuracy: 0.7699\n",
            "Epoch 149/150\n",
            "691/691 [==============================] - 0s 118us/step - loss: 0.4593 - accuracy: 0.7742\n",
            "Epoch 150/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.4612 - accuracy: 0.7800\n",
            "77/77 [==============================] - 0s 285us/step\n",
            "Epoch 1/150\n",
            "691/691 [==============================] - 0s 238us/step - loss: 0.6795 - accuracy: 0.6512\n",
            "Epoch 2/150\n",
            "691/691 [==============================] - 0s 117us/step - loss: 0.6660 - accuracy: 0.6512\n",
            "Epoch 3/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.6621 - accuracy: 0.6512\n",
            "Epoch 4/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.6517 - accuracy: 0.6512\n",
            "Epoch 5/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.6418 - accuracy: 0.6512\n",
            "Epoch 6/150\n",
            "691/691 [==============================] - 0s 119us/step - loss: 0.6365 - accuracy: 0.6512\n",
            "Epoch 7/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.6269 - accuracy: 0.6512\n",
            "Epoch 8/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.6114 - accuracy: 0.6541\n",
            "Epoch 9/150\n",
            "691/691 [==============================] - 0s 110us/step - loss: 0.6172 - accuracy: 0.6570\n",
            "Epoch 10/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.6121 - accuracy: 0.6758\n",
            "Epoch 11/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.6031 - accuracy: 0.6715\n",
            "Epoch 12/150\n",
            "691/691 [==============================] - 0s 119us/step - loss: 0.5956 - accuracy: 0.6831\n",
            "Epoch 13/150\n",
            "691/691 [==============================] - 0s 110us/step - loss: 0.5904 - accuracy: 0.6874\n",
            "Epoch 14/150\n",
            "691/691 [==============================] - 0s 109us/step - loss: 0.5851 - accuracy: 0.6889\n",
            "Epoch 15/150\n",
            "691/691 [==============================] - 0s 122us/step - loss: 0.5879 - accuracy: 0.6946\n",
            "Epoch 16/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.5825 - accuracy: 0.7077\n",
            "Epoch 17/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.5877 - accuracy: 0.6932\n",
            "Epoch 18/150\n",
            "691/691 [==============================] - 0s 119us/step - loss: 0.5833 - accuracy: 0.6918\n",
            "Epoch 19/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.5833 - accuracy: 0.6961\n",
            "Epoch 20/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.5751 - accuracy: 0.6990\n",
            "Epoch 21/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.5820 - accuracy: 0.7048\n",
            "Epoch 22/150\n",
            "691/691 [==============================] - 0s 110us/step - loss: 0.5797 - accuracy: 0.6715\n",
            "Epoch 23/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.5817 - accuracy: 0.7048\n",
            "Epoch 24/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.5753 - accuracy: 0.6990\n",
            "Epoch 25/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.5747 - accuracy: 0.7149\n",
            "Epoch 26/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.5680 - accuracy: 0.7164\n",
            "Epoch 27/150\n",
            "691/691 [==============================] - 0s 128us/step - loss: 0.5701 - accuracy: 0.7062\n",
            "Epoch 28/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.5725 - accuracy: 0.6990\n",
            "Epoch 29/150\n",
            "691/691 [==============================] - 0s 116us/step - loss: 0.5708 - accuracy: 0.7120\n",
            "Epoch 30/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.5689 - accuracy: 0.6845\n",
            "Epoch 31/150\n",
            "691/691 [==============================] - 0s 115us/step - loss: 0.5695 - accuracy: 0.7048\n",
            "Epoch 32/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.5654 - accuracy: 0.6961\n",
            "Epoch 33/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.5745 - accuracy: 0.6975\n",
            "Epoch 34/150\n",
            "691/691 [==============================] - 0s 117us/step - loss: 0.5670 - accuracy: 0.7250\n",
            "Epoch 35/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.5600 - accuracy: 0.6975\n",
            "Epoch 36/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.5593 - accuracy: 0.7120\n",
            "Epoch 37/150\n",
            "691/691 [==============================] - 0s 119us/step - loss: 0.5614 - accuracy: 0.7178\n",
            "Epoch 38/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.5588 - accuracy: 0.7149\n",
            "Epoch 39/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.5620 - accuracy: 0.7048\n",
            "Epoch 40/150\n",
            "691/691 [==============================] - 0s 124us/step - loss: 0.5526 - accuracy: 0.7149\n",
            "Epoch 41/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.5520 - accuracy: 0.7381\n",
            "Epoch 42/150\n",
            "691/691 [==============================] - 0s 116us/step - loss: 0.5503 - accuracy: 0.7192\n",
            "Epoch 43/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.5464 - accuracy: 0.7424\n",
            "Epoch 44/150\n",
            "691/691 [==============================] - 0s 116us/step - loss: 0.5535 - accuracy: 0.7265\n",
            "Epoch 45/150\n",
            "691/691 [==============================] - 0s 116us/step - loss: 0.5470 - accuracy: 0.7424\n",
            "Epoch 46/150\n",
            "691/691 [==============================] - 0s 115us/step - loss: 0.5439 - accuracy: 0.7308\n",
            "Epoch 47/150\n",
            "691/691 [==============================] - 0s 122us/step - loss: 0.5447 - accuracy: 0.7308\n",
            "Epoch 48/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.5416 - accuracy: 0.7250\n",
            "Epoch 49/150\n",
            "691/691 [==============================] - 0s 115us/step - loss: 0.5393 - accuracy: 0.7308\n",
            "Epoch 50/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.5395 - accuracy: 0.7337\n",
            "Epoch 51/150\n",
            "691/691 [==============================] - 0s 117us/step - loss: 0.5470 - accuracy: 0.7366\n",
            "Epoch 52/150\n",
            "691/691 [==============================] - 0s 132us/step - loss: 0.5333 - accuracy: 0.7569\n",
            "Epoch 53/150\n",
            "691/691 [==============================] - 0s 121us/step - loss: 0.5377 - accuracy: 0.7294\n",
            "Epoch 54/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.5350 - accuracy: 0.7207\n",
            "Epoch 55/150\n",
            "691/691 [==============================] - 0s 120us/step - loss: 0.5403 - accuracy: 0.7381\n",
            "Epoch 56/150\n",
            "691/691 [==============================] - 0s 131us/step - loss: 0.5271 - accuracy: 0.7482\n",
            "Epoch 57/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.5319 - accuracy: 0.7337\n",
            "Epoch 58/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.5302 - accuracy: 0.7265\n",
            "Epoch 59/150\n",
            "691/691 [==============================] - 0s 117us/step - loss: 0.5306 - accuracy: 0.7337\n",
            "Epoch 60/150\n",
            "691/691 [==============================] - 0s 117us/step - loss: 0.5277 - accuracy: 0.7366\n",
            "Epoch 61/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.5351 - accuracy: 0.7308\n",
            "Epoch 62/150\n",
            "691/691 [==============================] - 0s 116us/step - loss: 0.5235 - accuracy: 0.7467\n",
            "Epoch 63/150\n",
            "691/691 [==============================] - 0s 115us/step - loss: 0.5257 - accuracy: 0.7438\n",
            "Epoch 64/150\n",
            "691/691 [==============================] - 0s 120us/step - loss: 0.5239 - accuracy: 0.7323\n",
            "Epoch 65/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.5215 - accuracy: 0.7496\n",
            "Epoch 66/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.5210 - accuracy: 0.7453\n",
            "Epoch 67/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.5240 - accuracy: 0.7337\n",
            "Epoch 68/150\n",
            "691/691 [==============================] - 0s 115us/step - loss: 0.5181 - accuracy: 0.7511\n",
            "Epoch 69/150\n",
            "691/691 [==============================] - 0s 116us/step - loss: 0.5135 - accuracy: 0.7424\n",
            "Epoch 70/150\n",
            "691/691 [==============================] - 0s 110us/step - loss: 0.5267 - accuracy: 0.7424\n",
            "Epoch 71/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.5163 - accuracy: 0.7453\n",
            "Epoch 72/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.5145 - accuracy: 0.7467\n",
            "Epoch 73/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.5132 - accuracy: 0.7453\n",
            "Epoch 74/150\n",
            "691/691 [==============================] - 0s 115us/step - loss: 0.5150 - accuracy: 0.7381\n",
            "Epoch 75/150\n",
            "691/691 [==============================] - 0s 116us/step - loss: 0.5131 - accuracy: 0.7482\n",
            "Epoch 76/150\n",
            "691/691 [==============================] - 0s 118us/step - loss: 0.5146 - accuracy: 0.7366\n",
            "Epoch 77/150\n",
            "691/691 [==============================] - 0s 119us/step - loss: 0.5123 - accuracy: 0.7583\n",
            "Epoch 78/150\n",
            "691/691 [==============================] - 0s 115us/step - loss: 0.5084 - accuracy: 0.7453\n",
            "Epoch 79/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.5068 - accuracy: 0.7525\n",
            "Epoch 80/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.5174 - accuracy: 0.7337\n",
            "Epoch 81/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.5078 - accuracy: 0.7424\n",
            "Epoch 82/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.5084 - accuracy: 0.7482\n",
            "Epoch 83/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.5075 - accuracy: 0.7525\n",
            "Epoch 84/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.5076 - accuracy: 0.7467\n",
            "Epoch 85/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.5091 - accuracy: 0.7381\n",
            "Epoch 86/150\n",
            "691/691 [==============================] - 0s 115us/step - loss: 0.4992 - accuracy: 0.7554\n",
            "Epoch 87/150\n",
            "691/691 [==============================] - 0s 117us/step - loss: 0.5068 - accuracy: 0.7482\n",
            "Epoch 88/150\n",
            "691/691 [==============================] - 0s 115us/step - loss: 0.5099 - accuracy: 0.7525\n",
            "Epoch 89/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.4997 - accuracy: 0.7525\n",
            "Epoch 90/150\n",
            "691/691 [==============================] - 0s 125us/step - loss: 0.4962 - accuracy: 0.7598\n",
            "Epoch 91/150\n",
            "691/691 [==============================] - 0s 124us/step - loss: 0.5063 - accuracy: 0.7395\n",
            "Epoch 92/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.4965 - accuracy: 0.7699\n",
            "Epoch 93/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.4963 - accuracy: 0.7554\n",
            "Epoch 94/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.4985 - accuracy: 0.7569\n",
            "Epoch 95/150\n",
            "691/691 [==============================] - 0s 118us/step - loss: 0.4947 - accuracy: 0.7583\n",
            "Epoch 96/150\n",
            "691/691 [==============================] - 0s 108us/step - loss: 0.4976 - accuracy: 0.7612\n",
            "Epoch 97/150\n",
            "691/691 [==============================] - 0s 120us/step - loss: 0.4954 - accuracy: 0.7627\n",
            "Epoch 98/150\n",
            "691/691 [==============================] - 0s 118us/step - loss: 0.4959 - accuracy: 0.7569\n",
            "Epoch 99/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.5009 - accuracy: 0.7496\n",
            "Epoch 100/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.4932 - accuracy: 0.7641\n",
            "Epoch 101/150\n",
            "691/691 [==============================] - 0s 133us/step - loss: 0.4875 - accuracy: 0.7598\n",
            "Epoch 102/150\n",
            "691/691 [==============================] - 0s 132us/step - loss: 0.4963 - accuracy: 0.7656\n",
            "Epoch 103/150\n",
            "691/691 [==============================] - 0s 122us/step - loss: 0.5036 - accuracy: 0.7554\n",
            "Epoch 104/150\n",
            "691/691 [==============================] - 0s 126us/step - loss: 0.4969 - accuracy: 0.7540\n",
            "Epoch 105/150\n",
            "691/691 [==============================] - 0s 118us/step - loss: 0.4902 - accuracy: 0.7583\n",
            "Epoch 106/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.4923 - accuracy: 0.7540\n",
            "Epoch 107/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.4889 - accuracy: 0.7670\n",
            "Epoch 108/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.4839 - accuracy: 0.7757\n",
            "Epoch 109/150\n",
            "691/691 [==============================] - 0s 117us/step - loss: 0.4893 - accuracy: 0.7656\n",
            "Epoch 110/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.4846 - accuracy: 0.7728\n",
            "Epoch 111/150\n",
            "691/691 [==============================] - 0s 115us/step - loss: 0.4844 - accuracy: 0.7656\n",
            "Epoch 112/150\n",
            "691/691 [==============================] - 0s 124us/step - loss: 0.4891 - accuracy: 0.7699\n",
            "Epoch 113/150\n",
            "691/691 [==============================] - 0s 124us/step - loss: 0.4855 - accuracy: 0.7685\n",
            "Epoch 114/150\n",
            "691/691 [==============================] - 0s 149us/step - loss: 0.4815 - accuracy: 0.7569\n",
            "Epoch 115/150\n",
            "691/691 [==============================] - 0s 125us/step - loss: 0.4821 - accuracy: 0.7540\n",
            "Epoch 116/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.4805 - accuracy: 0.7627\n",
            "Epoch 117/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.4831 - accuracy: 0.7641\n",
            "Epoch 118/150\n",
            "691/691 [==============================] - 0s 116us/step - loss: 0.4786 - accuracy: 0.7699\n",
            "Epoch 119/150\n",
            "691/691 [==============================] - 0s 118us/step - loss: 0.4819 - accuracy: 0.7612\n",
            "Epoch 120/150\n",
            "691/691 [==============================] - 0s 120us/step - loss: 0.4787 - accuracy: 0.7598\n",
            "Epoch 121/150\n",
            "691/691 [==============================] - 0s 121us/step - loss: 0.4798 - accuracy: 0.7583\n",
            "Epoch 122/150\n",
            "691/691 [==============================] - 0s 115us/step - loss: 0.4891 - accuracy: 0.7612\n",
            "Epoch 123/150\n",
            "691/691 [==============================] - 0s 116us/step - loss: 0.4861 - accuracy: 0.7641\n",
            "Epoch 124/150\n",
            "691/691 [==============================] - 0s 116us/step - loss: 0.4829 - accuracy: 0.7598\n",
            "Epoch 125/150\n",
            "691/691 [==============================] - 0s 122us/step - loss: 0.4816 - accuracy: 0.7728\n",
            "Epoch 126/150\n",
            "691/691 [==============================] - 0s 119us/step - loss: 0.4886 - accuracy: 0.7467\n",
            "Epoch 127/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.4753 - accuracy: 0.7713\n",
            "Epoch 128/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.4742 - accuracy: 0.7641\n",
            "Epoch 129/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.4779 - accuracy: 0.7757\n",
            "Epoch 130/150\n",
            "691/691 [==============================] - 0s 115us/step - loss: 0.4723 - accuracy: 0.7656\n",
            "Epoch 131/150\n",
            "691/691 [==============================] - 0s 121us/step - loss: 0.4820 - accuracy: 0.7641\n",
            "Epoch 132/150\n",
            "691/691 [==============================] - 0s 115us/step - loss: 0.4996 - accuracy: 0.7612\n",
            "Epoch 133/150\n",
            "691/691 [==============================] - 0s 115us/step - loss: 0.4695 - accuracy: 0.7728\n",
            "Epoch 134/150\n",
            "691/691 [==============================] - 0s 116us/step - loss: 0.4794 - accuracy: 0.7627\n",
            "Epoch 135/150\n",
            "691/691 [==============================] - 0s 123us/step - loss: 0.4781 - accuracy: 0.7728\n",
            "Epoch 136/150\n",
            "691/691 [==============================] - 0s 122us/step - loss: 0.4743 - accuracy: 0.7728\n",
            "Epoch 137/150\n",
            "691/691 [==============================] - 0s 119us/step - loss: 0.4807 - accuracy: 0.7670\n",
            "Epoch 138/150\n",
            "691/691 [==============================] - 0s 128us/step - loss: 0.4771 - accuracy: 0.7670\n",
            "Epoch 139/150\n",
            "691/691 [==============================] - 0s 117us/step - loss: 0.4738 - accuracy: 0.7728\n",
            "Epoch 140/150\n",
            "691/691 [==============================] - 0s 116us/step - loss: 0.4634 - accuracy: 0.7728\n",
            "Epoch 141/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.4657 - accuracy: 0.7685\n",
            "Epoch 142/150\n",
            "691/691 [==============================] - 0s 116us/step - loss: 0.4695 - accuracy: 0.7829\n",
            "Epoch 143/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.4631 - accuracy: 0.7713\n",
            "Epoch 144/150\n",
            "691/691 [==============================] - 0s 129us/step - loss: 0.4643 - accuracy: 0.7887\n",
            "Epoch 145/150\n",
            "691/691 [==============================] - 0s 110us/step - loss: 0.4621 - accuracy: 0.7815\n",
            "Epoch 146/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.4695 - accuracy: 0.7728\n",
            "Epoch 147/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.4732 - accuracy: 0.7525\n",
            "Epoch 148/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.4673 - accuracy: 0.7641\n",
            "Epoch 149/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.4858 - accuracy: 0.7569\n",
            "Epoch 150/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.4684 - accuracy: 0.7670\n",
            "77/77 [==============================] - 0s 290us/step\n",
            "Epoch 1/150\n",
            "691/691 [==============================] - 0s 288us/step - loss: 0.6787 - accuracy: 0.6512\n",
            "Epoch 2/150\n",
            "691/691 [==============================] - 0s 116us/step - loss: 0.6648 - accuracy: 0.6512\n",
            "Epoch 3/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.6545 - accuracy: 0.6570\n",
            "Epoch 4/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.6464 - accuracy: 0.6512\n",
            "Epoch 5/150\n",
            "691/691 [==============================] - 0s 109us/step - loss: 0.6368 - accuracy: 0.6628\n",
            "Epoch 6/150\n",
            "691/691 [==============================] - 0s 110us/step - loss: 0.6263 - accuracy: 0.6700\n",
            "Epoch 7/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.6118 - accuracy: 0.6802\n",
            "Epoch 8/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.6227 - accuracy: 0.6903\n",
            "Epoch 9/150\n",
            "691/691 [==============================] - 0s 109us/step - loss: 0.6043 - accuracy: 0.6816\n",
            "Epoch 10/150\n",
            "691/691 [==============================] - 0s 109us/step - loss: 0.5971 - accuracy: 0.6903\n",
            "Epoch 11/150\n",
            "691/691 [==============================] - 0s 110us/step - loss: 0.6001 - accuracy: 0.6816\n",
            "Epoch 12/150\n",
            "691/691 [==============================] - 0s 107us/step - loss: 0.5896 - accuracy: 0.7077\n",
            "Epoch 13/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.5915 - accuracy: 0.6961\n",
            "Epoch 14/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.5954 - accuracy: 0.6918\n",
            "Epoch 15/150\n",
            "691/691 [==============================] - 0s 110us/step - loss: 0.5922 - accuracy: 0.6932\n",
            "Epoch 16/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.5868 - accuracy: 0.6918\n",
            "Epoch 17/150\n",
            "691/691 [==============================] - 0s 108us/step - loss: 0.5859 - accuracy: 0.6932\n",
            "Epoch 18/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.5911 - accuracy: 0.6918\n",
            "Epoch 19/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.5904 - accuracy: 0.6918\n",
            "Epoch 20/150\n",
            "691/691 [==============================] - 0s 109us/step - loss: 0.5803 - accuracy: 0.7077\n",
            "Epoch 21/150\n",
            "691/691 [==============================] - 0s 110us/step - loss: 0.5818 - accuracy: 0.7004\n",
            "Epoch 22/150\n",
            "691/691 [==============================] - 0s 109us/step - loss: 0.5697 - accuracy: 0.7164\n",
            "Epoch 23/150\n",
            "691/691 [==============================] - 0s 109us/step - loss: 0.5827 - accuracy: 0.7048\n",
            "Epoch 24/150\n",
            "691/691 [==============================] - 0s 110us/step - loss: 0.5773 - accuracy: 0.7019\n",
            "Epoch 25/150\n",
            "691/691 [==============================] - 0s 119us/step - loss: 0.5755 - accuracy: 0.7019\n",
            "Epoch 26/150\n",
            "691/691 [==============================] - 0s 120us/step - loss: 0.5745 - accuracy: 0.7077\n",
            "Epoch 27/150\n",
            "691/691 [==============================] - 0s 109us/step - loss: 0.5724 - accuracy: 0.7048\n",
            "Epoch 28/150\n",
            "691/691 [==============================] - 0s 109us/step - loss: 0.5719 - accuracy: 0.7048\n",
            "Epoch 29/150\n",
            "691/691 [==============================] - 0s 109us/step - loss: 0.5735 - accuracy: 0.7019\n",
            "Epoch 30/150\n",
            "691/691 [==============================] - 0s 107us/step - loss: 0.5726 - accuracy: 0.7019\n",
            "Epoch 31/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.5752 - accuracy: 0.6889\n",
            "Epoch 32/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.5729 - accuracy: 0.7178\n",
            "Epoch 33/150\n",
            "691/691 [==============================] - 0s 118us/step - loss: 0.5738 - accuracy: 0.6990\n",
            "Epoch 34/150\n",
            "691/691 [==============================] - 0s 109us/step - loss: 0.5655 - accuracy: 0.7294\n",
            "Epoch 35/150\n",
            "691/691 [==============================] - 0s 109us/step - loss: 0.5592 - accuracy: 0.7164\n",
            "Epoch 36/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.5696 - accuracy: 0.7077\n",
            "Epoch 37/150\n",
            "691/691 [==============================] - 0s 109us/step - loss: 0.5632 - accuracy: 0.7294\n",
            "Epoch 38/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.5552 - accuracy: 0.7337\n",
            "Epoch 39/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.5544 - accuracy: 0.7221\n",
            "Epoch 40/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.5549 - accuracy: 0.7192\n",
            "Epoch 41/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.5574 - accuracy: 0.7221\n",
            "Epoch 42/150\n",
            "691/691 [==============================] - 0s 115us/step - loss: 0.5524 - accuracy: 0.7366\n",
            "Epoch 43/150\n",
            "691/691 [==============================] - 0s 129us/step - loss: 0.5565 - accuracy: 0.7279\n",
            "Epoch 44/150\n",
            "691/691 [==============================] - 0s 129us/step - loss: 0.5509 - accuracy: 0.7323\n",
            "Epoch 45/150\n",
            "691/691 [==============================] - 0s 109us/step - loss: 0.5537 - accuracy: 0.7308\n",
            "Epoch 46/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.5443 - accuracy: 0.7438\n",
            "Epoch 47/150\n",
            "691/691 [==============================] - 0s 110us/step - loss: 0.5546 - accuracy: 0.7149\n",
            "Epoch 48/150\n",
            "691/691 [==============================] - 0s 109us/step - loss: 0.5436 - accuracy: 0.7410\n",
            "Epoch 49/150\n",
            "691/691 [==============================] - 0s 126us/step - loss: 0.5406 - accuracy: 0.7337\n",
            "Epoch 50/150\n",
            "691/691 [==============================] - 0s 109us/step - loss: 0.5336 - accuracy: 0.7467\n",
            "Epoch 51/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.5371 - accuracy: 0.7410\n",
            "Epoch 52/150\n",
            "691/691 [==============================] - 0s 115us/step - loss: 0.5329 - accuracy: 0.7410\n",
            "Epoch 53/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.5286 - accuracy: 0.7337\n",
            "Epoch 54/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.5327 - accuracy: 0.7569\n",
            "Epoch 55/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.5240 - accuracy: 0.7496\n",
            "Epoch 56/150\n",
            "691/691 [==============================] - 0s 110us/step - loss: 0.5251 - accuracy: 0.7438\n",
            "Epoch 57/150\n",
            "691/691 [==============================] - 0s 115us/step - loss: 0.5232 - accuracy: 0.7511\n",
            "Epoch 58/150\n",
            "691/691 [==============================] - 0s 109us/step - loss: 0.5258 - accuracy: 0.7438\n",
            "Epoch 59/150\n",
            "691/691 [==============================] - 0s 107us/step - loss: 0.5247 - accuracy: 0.7424\n",
            "Epoch 60/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.5182 - accuracy: 0.7525\n",
            "Epoch 61/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.5242 - accuracy: 0.7525\n",
            "Epoch 62/150\n",
            "691/691 [==============================] - 0s 108us/step - loss: 0.5223 - accuracy: 0.7424\n",
            "Epoch 63/150\n",
            "691/691 [==============================] - 0s 110us/step - loss: 0.5197 - accuracy: 0.7467\n",
            "Epoch 64/150\n",
            "691/691 [==============================] - 0s 110us/step - loss: 0.5182 - accuracy: 0.7482\n",
            "Epoch 65/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.5159 - accuracy: 0.7467\n",
            "Epoch 66/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.5121 - accuracy: 0.7554\n",
            "Epoch 67/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.5175 - accuracy: 0.7438\n",
            "Epoch 68/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.5155 - accuracy: 0.7511\n",
            "Epoch 69/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.5091 - accuracy: 0.7525\n",
            "Epoch 70/150\n",
            "691/691 [==============================] - 0s 117us/step - loss: 0.5105 - accuracy: 0.7525\n",
            "Epoch 71/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.5123 - accuracy: 0.7453\n",
            "Epoch 72/150\n",
            "691/691 [==============================] - 0s 123us/step - loss: 0.5017 - accuracy: 0.7482\n",
            "Epoch 73/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.5054 - accuracy: 0.7496\n",
            "Epoch 74/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.5067 - accuracy: 0.7496\n",
            "Epoch 75/150\n",
            "691/691 [==============================] - 0s 109us/step - loss: 0.5101 - accuracy: 0.7467\n",
            "Epoch 76/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.5280 - accuracy: 0.7395\n",
            "Epoch 77/150\n",
            "691/691 [==============================] - 0s 108us/step - loss: 0.5154 - accuracy: 0.7525\n",
            "Epoch 78/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.4978 - accuracy: 0.7598\n",
            "Epoch 79/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.5030 - accuracy: 0.7482\n",
            "Epoch 80/150\n",
            "691/691 [==============================] - 0s 115us/step - loss: 0.5007 - accuracy: 0.7627\n",
            "Epoch 81/150\n",
            "691/691 [==============================] - 0s 109us/step - loss: 0.4950 - accuracy: 0.7598\n",
            "Epoch 82/150\n",
            "691/691 [==============================] - 0s 131us/step - loss: 0.4940 - accuracy: 0.7554\n",
            "Epoch 83/150\n",
            "691/691 [==============================] - 0s 122us/step - loss: 0.4920 - accuracy: 0.7583\n",
            "Epoch 84/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.4998 - accuracy: 0.7583\n",
            "Epoch 85/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.4950 - accuracy: 0.7554\n",
            "Epoch 86/150\n",
            "691/691 [==============================] - 0s 118us/step - loss: 0.4897 - accuracy: 0.7656\n",
            "Epoch 87/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.4973 - accuracy: 0.7598\n",
            "Epoch 88/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.4903 - accuracy: 0.7569\n",
            "Epoch 89/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.4907 - accuracy: 0.7598\n",
            "Epoch 90/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.4885 - accuracy: 0.7742\n",
            "Epoch 91/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.4884 - accuracy: 0.7713\n",
            "Epoch 92/150\n",
            "691/691 [==============================] - 0s 123us/step - loss: 0.4941 - accuracy: 0.7670\n",
            "Epoch 93/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.4910 - accuracy: 0.7656\n",
            "Epoch 94/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.4834 - accuracy: 0.7656\n",
            "Epoch 95/150\n",
            "691/691 [==============================] - 0s 117us/step - loss: 0.4853 - accuracy: 0.7598\n",
            "Epoch 96/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.4895 - accuracy: 0.7685\n",
            "Epoch 97/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.4917 - accuracy: 0.7482\n",
            "Epoch 98/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.4868 - accuracy: 0.7569\n",
            "Epoch 99/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.4794 - accuracy: 0.7742\n",
            "Epoch 100/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.4775 - accuracy: 0.7656\n",
            "Epoch 101/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.4812 - accuracy: 0.7540\n",
            "Epoch 102/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.4762 - accuracy: 0.7757\n",
            "Epoch 103/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.4955 - accuracy: 0.7641\n",
            "Epoch 104/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.4855 - accuracy: 0.7699\n",
            "Epoch 105/150\n",
            "691/691 [==============================] - 0s 124us/step - loss: 0.4826 - accuracy: 0.7569\n",
            "Epoch 106/150\n",
            "691/691 [==============================] - 0s 132us/step - loss: 0.4837 - accuracy: 0.7627\n",
            "Epoch 107/150\n",
            "691/691 [==============================] - 0s 139us/step - loss: 0.4808 - accuracy: 0.7685\n",
            "Epoch 108/150\n",
            "691/691 [==============================] - 0s 115us/step - loss: 0.4725 - accuracy: 0.7685\n",
            "Epoch 109/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.4794 - accuracy: 0.7641\n",
            "Epoch 110/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.4997 - accuracy: 0.7424\n",
            "Epoch 111/150\n",
            "691/691 [==============================] - 0s 109us/step - loss: 0.4783 - accuracy: 0.7728\n",
            "Epoch 112/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.4846 - accuracy: 0.7627\n",
            "Epoch 113/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.4742 - accuracy: 0.7670\n",
            "Epoch 114/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.4889 - accuracy: 0.7540\n",
            "Epoch 115/150\n",
            "691/691 [==============================] - 0s 115us/step - loss: 0.4804 - accuracy: 0.7670\n",
            "Epoch 116/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.4820 - accuracy: 0.7598\n",
            "Epoch 117/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.4866 - accuracy: 0.7699\n",
            "Epoch 118/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.4681 - accuracy: 0.7699\n",
            "Epoch 119/150\n",
            "691/691 [==============================] - 0s 110us/step - loss: 0.4727 - accuracy: 0.7685\n",
            "Epoch 120/150\n",
            "691/691 [==============================] - 0s 118us/step - loss: 0.4664 - accuracy: 0.7786\n",
            "Epoch 121/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.4755 - accuracy: 0.7829\n",
            "Epoch 122/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.4727 - accuracy: 0.7771\n",
            "Epoch 123/150\n",
            "691/691 [==============================] - 0s 122us/step - loss: 0.4741 - accuracy: 0.7771\n",
            "Epoch 124/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.4667 - accuracy: 0.7771\n",
            "Epoch 125/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.4669 - accuracy: 0.7800\n",
            "Epoch 126/150\n",
            "691/691 [==============================] - 0s 135us/step - loss: 0.4717 - accuracy: 0.7786\n",
            "Epoch 127/150\n",
            "691/691 [==============================] - 0s 124us/step - loss: 0.4761 - accuracy: 0.7771\n",
            "Epoch 128/150\n",
            "691/691 [==============================] - 0s 116us/step - loss: 0.4704 - accuracy: 0.7815\n",
            "Epoch 129/150\n",
            "691/691 [==============================] - 0s 119us/step - loss: 0.4747 - accuracy: 0.7771\n",
            "Epoch 130/150\n",
            "691/691 [==============================] - 0s 110us/step - loss: 0.4597 - accuracy: 0.7815\n",
            "Epoch 131/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.4599 - accuracy: 0.7858\n",
            "Epoch 132/150\n",
            "691/691 [==============================] - 0s 117us/step - loss: 0.4691 - accuracy: 0.7742\n",
            "Epoch 133/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.4598 - accuracy: 0.7815\n",
            "Epoch 134/150\n",
            "691/691 [==============================] - 0s 111us/step - loss: 0.4654 - accuracy: 0.7887\n",
            "Epoch 135/150\n",
            "691/691 [==============================] - 0s 122us/step - loss: 0.4606 - accuracy: 0.7902\n",
            "Epoch 136/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.4567 - accuracy: 0.7858\n",
            "Epoch 137/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.4651 - accuracy: 0.7786\n",
            "Epoch 138/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.4722 - accuracy: 0.7771\n",
            "Epoch 139/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.4596 - accuracy: 0.7829\n",
            "Epoch 140/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.4598 - accuracy: 0.7742\n",
            "Epoch 141/150\n",
            "691/691 [==============================] - 0s 113us/step - loss: 0.4574 - accuracy: 0.7786\n",
            "Epoch 142/150\n",
            "691/691 [==============================] - 0s 118us/step - loss: 0.4548 - accuracy: 0.7858\n",
            "Epoch 143/150\n",
            "691/691 [==============================] - 0s 114us/step - loss: 0.4492 - accuracy: 0.7873\n",
            "Epoch 144/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.4550 - accuracy: 0.7858\n",
            "Epoch 145/150\n",
            "691/691 [==============================] - 0s 120us/step - loss: 0.4792 - accuracy: 0.7713\n",
            "Epoch 146/150\n",
            "691/691 [==============================] - 0s 115us/step - loss: 0.4501 - accuracy: 0.7916\n",
            "Epoch 147/150\n",
            "691/691 [==============================] - 0s 127us/step - loss: 0.4541 - accuracy: 0.7902\n",
            "Epoch 148/150\n",
            "691/691 [==============================] - 0s 124us/step - loss: 0.4519 - accuracy: 0.7931\n",
            "Epoch 149/150\n",
            "691/691 [==============================] - 0s 112us/step - loss: 0.4930 - accuracy: 0.7612\n",
            "Epoch 150/150\n",
            "691/691 [==============================] - 0s 117us/step - loss: 0.4541 - accuracy: 0.7887\n",
            "77/77 [==============================] - 0s 269us/step\n",
            "Epoch 1/150\n",
            "692/692 [==============================] - 0s 258us/step - loss: 0.6778 - accuracy: 0.6503\n",
            "Epoch 2/150\n",
            "692/692 [==============================] - 0s 108us/step - loss: 0.6666 - accuracy: 0.6503\n",
            "Epoch 3/150\n",
            "692/692 [==============================] - 0s 114us/step - loss: 0.6579 - accuracy: 0.6503\n",
            "Epoch 4/150\n",
            "692/692 [==============================] - 0s 117us/step - loss: 0.6432 - accuracy: 0.6503\n",
            "Epoch 5/150\n",
            "692/692 [==============================] - 0s 115us/step - loss: 0.6422 - accuracy: 0.6503\n",
            "Epoch 6/150\n",
            "692/692 [==============================] - 0s 121us/step - loss: 0.6232 - accuracy: 0.6503\n",
            "Epoch 7/150\n",
            "692/692 [==============================] - 0s 118us/step - loss: 0.6218 - accuracy: 0.6503\n",
            "Epoch 8/150\n",
            "692/692 [==============================] - 0s 118us/step - loss: 0.6145 - accuracy: 0.6503\n",
            "Epoch 9/150\n",
            "692/692 [==============================] - 0s 126us/step - loss: 0.6096 - accuracy: 0.6503\n",
            "Epoch 10/150\n",
            "692/692 [==============================] - 0s 123us/step - loss: 0.6088 - accuracy: 0.6503\n",
            "Epoch 11/150\n",
            "692/692 [==============================] - 0s 120us/step - loss: 0.6040 - accuracy: 0.6503\n",
            "Epoch 12/150\n",
            "692/692 [==============================] - 0s 132us/step - loss: 0.6021 - accuracy: 0.6503\n",
            "Epoch 13/150\n",
            "692/692 [==============================] - 0s 118us/step - loss: 0.6091 - accuracy: 0.6503\n",
            "Epoch 14/150\n",
            "692/692 [==============================] - 0s 122us/step - loss: 0.6014 - accuracy: 0.6503\n",
            "Epoch 15/150\n",
            "692/692 [==============================] - 0s 123us/step - loss: 0.6027 - accuracy: 0.6503\n",
            "Epoch 16/150\n",
            "692/692 [==============================] - 0s 119us/step - loss: 0.6046 - accuracy: 0.6503\n",
            "Epoch 17/150\n",
            "692/692 [==============================] - 0s 120us/step - loss: 0.6032 - accuracy: 0.6503\n",
            "Epoch 18/150\n",
            "692/692 [==============================] - 0s 122us/step - loss: 0.5991 - accuracy: 0.6503\n",
            "Epoch 19/150\n",
            "692/692 [==============================] - 0s 123us/step - loss: 0.6045 - accuracy: 0.6503\n",
            "Epoch 20/150\n",
            "692/692 [==============================] - 0s 120us/step - loss: 0.5989 - accuracy: 0.6503\n",
            "Epoch 21/150\n",
            "692/692 [==============================] - 0s 126us/step - loss: 0.5975 - accuracy: 0.6503\n",
            "Epoch 22/150\n",
            "692/692 [==============================] - 0s 120us/step - loss: 0.5977 - accuracy: 0.6503\n",
            "Epoch 23/150\n",
            "692/692 [==============================] - 0s 117us/step - loss: 0.5954 - accuracy: 0.6503\n",
            "Epoch 24/150\n",
            "692/692 [==============================] - 0s 125us/step - loss: 0.6020 - accuracy: 0.6503\n",
            "Epoch 25/150\n",
            "692/692 [==============================] - 0s 122us/step - loss: 0.5950 - accuracy: 0.6503\n",
            "Epoch 26/150\n",
            "692/692 [==============================] - 0s 118us/step - loss: 0.5973 - accuracy: 0.6503\n",
            "Epoch 27/150\n",
            "692/692 [==============================] - 0s 115us/step - loss: 0.5933 - accuracy: 0.6503\n",
            "Epoch 28/150\n",
            "692/692 [==============================] - 0s 118us/step - loss: 0.6016 - accuracy: 0.6503\n",
            "Epoch 29/150\n",
            "692/692 [==============================] - 0s 119us/step - loss: 0.5980 - accuracy: 0.6503\n",
            "Epoch 30/150\n",
            "692/692 [==============================] - 0s 136us/step - loss: 0.5916 - accuracy: 0.6503\n",
            "Epoch 31/150\n",
            "692/692 [==============================] - 0s 143us/step - loss: 0.5932 - accuracy: 0.6503\n",
            "Epoch 32/150\n",
            "692/692 [==============================] - 0s 119us/step - loss: 0.5892 - accuracy: 0.6503\n",
            "Epoch 33/150\n",
            "692/692 [==============================] - 0s 121us/step - loss: 0.5894 - accuracy: 0.6503\n",
            "Epoch 34/150\n",
            "692/692 [==============================] - 0s 118us/step - loss: 0.5875 - accuracy: 0.6503\n",
            "Epoch 35/150\n",
            "692/692 [==============================] - 0s 119us/step - loss: 0.5912 - accuracy: 0.6503\n",
            "Epoch 36/150\n",
            "692/692 [==============================] - 0s 118us/step - loss: 0.5957 - accuracy: 0.6503\n",
            "Epoch 37/150\n",
            "692/692 [==============================] - 0s 124us/step - loss: 0.5888 - accuracy: 0.6503\n",
            "Epoch 38/150\n",
            "692/692 [==============================] - 0s 121us/step - loss: 0.5905 - accuracy: 0.6503\n",
            "Epoch 39/150\n",
            "692/692 [==============================] - 0s 139us/step - loss: 0.5992 - accuracy: 0.6503\n",
            "Epoch 40/150\n",
            "692/692 [==============================] - 0s 121us/step - loss: 0.6034 - accuracy: 0.6503\n",
            "Epoch 41/150\n",
            "692/692 [==============================] - 0s 117us/step - loss: 0.6071 - accuracy: 0.6503\n",
            "Epoch 42/150\n",
            "692/692 [==============================] - 0s 121us/step - loss: 0.5838 - accuracy: 0.6503\n",
            "Epoch 43/150\n",
            "692/692 [==============================] - 0s 123us/step - loss: 0.5947 - accuracy: 0.6503\n",
            "Epoch 44/150\n",
            "692/692 [==============================] - 0s 123us/step - loss: 0.5869 - accuracy: 0.6503\n",
            "Epoch 45/150\n",
            "692/692 [==============================] - 0s 121us/step - loss: 0.5878 - accuracy: 0.6503\n",
            "Epoch 46/150\n",
            "692/692 [==============================] - 0s 132us/step - loss: 0.5838 - accuracy: 0.6503\n",
            "Epoch 47/150\n",
            "692/692 [==============================] - 0s 154us/step - loss: 0.5868 - accuracy: 0.6503\n",
            "Epoch 48/150\n",
            "692/692 [==============================] - 0s 136us/step - loss: 0.5849 - accuracy: 0.6503\n",
            "Epoch 49/150\n",
            "692/692 [==============================] - 0s 128us/step - loss: 0.5890 - accuracy: 0.6503\n",
            "Epoch 50/150\n",
            "692/692 [==============================] - 0s 131us/step - loss: 0.5829 - accuracy: 0.6503\n",
            "Epoch 51/150\n",
            "692/692 [==============================] - 0s 164us/step - loss: 0.5837 - accuracy: 0.6618\n",
            "Epoch 52/150\n",
            "692/692 [==============================] - 0s 132us/step - loss: 0.5870 - accuracy: 0.6850\n",
            "Epoch 53/150\n",
            "692/692 [==============================] - 0s 125us/step - loss: 0.5838 - accuracy: 0.7009\n",
            "Epoch 54/150\n",
            "692/692 [==============================] - 0s 123us/step - loss: 0.5825 - accuracy: 0.7052\n",
            "Epoch 55/150\n",
            "692/692 [==============================] - 0s 123us/step - loss: 0.5889 - accuracy: 0.6806\n",
            "Epoch 56/150\n",
            "692/692 [==============================] - 0s 121us/step - loss: 0.5922 - accuracy: 0.6951\n",
            "Epoch 57/150\n",
            "692/692 [==============================] - 0s 121us/step - loss: 0.5853 - accuracy: 0.6965\n",
            "Epoch 58/150\n",
            "692/692 [==============================] - 0s 123us/step - loss: 0.5828 - accuracy: 0.6980\n",
            "Epoch 59/150\n",
            "692/692 [==============================] - 0s 127us/step - loss: 0.5808 - accuracy: 0.6850\n",
            "Epoch 60/150\n",
            "692/692 [==============================] - 0s 120us/step - loss: 0.5981 - accuracy: 0.6705\n",
            "Epoch 61/150\n",
            "692/692 [==============================] - 0s 119us/step - loss: 0.5810 - accuracy: 0.7023\n",
            "Epoch 62/150\n",
            "692/692 [==============================] - 0s 121us/step - loss: 0.5832 - accuracy: 0.6936\n",
            "Epoch 63/150\n",
            "692/692 [==============================] - 0s 120us/step - loss: 0.5897 - accuracy: 0.6994\n",
            "Epoch 64/150\n",
            "692/692 [==============================] - 0s 123us/step - loss: 0.5827 - accuracy: 0.7023\n",
            "Epoch 65/150\n",
            "692/692 [==============================] - 0s 130us/step - loss: 0.5826 - accuracy: 0.7009\n",
            "Epoch 66/150\n",
            "692/692 [==============================] - 0s 127us/step - loss: 0.5803 - accuracy: 0.6936\n",
            "Epoch 67/150\n",
            "692/692 [==============================] - 0s 123us/step - loss: 0.5756 - accuracy: 0.7023\n",
            "Epoch 68/150\n",
            "692/692 [==============================] - 0s 122us/step - loss: 0.5822 - accuracy: 0.7052\n",
            "Epoch 69/150\n",
            "692/692 [==============================] - 0s 122us/step - loss: 0.5771 - accuracy: 0.7139\n",
            "Epoch 70/150\n",
            "692/692 [==============================] - 0s 138us/step - loss: 0.5811 - accuracy: 0.6980\n",
            "Epoch 71/150\n",
            "692/692 [==============================] - 0s 119us/step - loss: 0.5803 - accuracy: 0.7124\n",
            "Epoch 72/150\n",
            "692/692 [==============================] - 0s 119us/step - loss: 0.5785 - accuracy: 0.7066\n",
            "Epoch 73/150\n",
            "692/692 [==============================] - 0s 122us/step - loss: 0.5776 - accuracy: 0.7066\n",
            "Epoch 74/150\n",
            "692/692 [==============================] - 0s 125us/step - loss: 0.5761 - accuracy: 0.7168\n",
            "Epoch 75/150\n",
            "692/692 [==============================] - 0s 122us/step - loss: 0.5780 - accuracy: 0.7066\n",
            "Epoch 76/150\n",
            "692/692 [==============================] - 0s 141us/step - loss: 0.5727 - accuracy: 0.7153\n",
            "Epoch 77/150\n",
            "692/692 [==============================] - 0s 121us/step - loss: 0.5782 - accuracy: 0.7081\n",
            "Epoch 78/150\n",
            "692/692 [==============================] - 0s 124us/step - loss: 0.5748 - accuracy: 0.7124\n",
            "Epoch 79/150\n",
            "692/692 [==============================] - 0s 124us/step - loss: 0.5797 - accuracy: 0.7023\n",
            "Epoch 80/150\n",
            "692/692 [==============================] - 0s 124us/step - loss: 0.5768 - accuracy: 0.7081\n",
            "Epoch 81/150\n",
            "692/692 [==============================] - 0s 133us/step - loss: 0.5781 - accuracy: 0.6994\n",
            "Epoch 82/150\n",
            "692/692 [==============================] - 0s 127us/step - loss: 0.5739 - accuracy: 0.7052\n",
            "Epoch 83/150\n",
            "692/692 [==============================] - 0s 124us/step - loss: 0.5795 - accuracy: 0.6965\n",
            "Epoch 84/150\n",
            "692/692 [==============================] - 0s 135us/step - loss: 0.5739 - accuracy: 0.7182\n",
            "Epoch 85/150\n",
            "692/692 [==============================] - 0s 138us/step - loss: 0.5723 - accuracy: 0.7110\n",
            "Epoch 86/150\n",
            "692/692 [==============================] - 0s 143us/step - loss: 0.5702 - accuracy: 0.7182\n",
            "Epoch 87/150\n",
            "692/692 [==============================] - 0s 167us/step - loss: 0.5705 - accuracy: 0.7110\n",
            "Epoch 88/150\n",
            "692/692 [==============================] - 0s 133us/step - loss: 0.5693 - accuracy: 0.7139\n",
            "Epoch 89/150\n",
            "692/692 [==============================] - 0s 136us/step - loss: 0.5652 - accuracy: 0.7124\n",
            "Epoch 90/150\n",
            "692/692 [==============================] - 0s 137us/step - loss: 0.5687 - accuracy: 0.7095\n",
            "Epoch 91/150\n",
            "692/692 [==============================] - 0s 153us/step - loss: 0.5713 - accuracy: 0.7110\n",
            "Epoch 92/150\n",
            "692/692 [==============================] - 0s 149us/step - loss: 0.5702 - accuracy: 0.7240\n",
            "Epoch 93/150\n",
            "692/692 [==============================] - 0s 137us/step - loss: 0.5664 - accuracy: 0.7168\n",
            "Epoch 94/150\n",
            "692/692 [==============================] - 0s 141us/step - loss: 0.5646 - accuracy: 0.7110\n",
            "Epoch 95/150\n",
            "692/692 [==============================] - 0s 143us/step - loss: 0.5629 - accuracy: 0.7153\n",
            "Epoch 96/150\n",
            "692/692 [==============================] - 0s 143us/step - loss: 0.5618 - accuracy: 0.7197\n",
            "Epoch 97/150\n",
            "692/692 [==============================] - 0s 156us/step - loss: 0.5648 - accuracy: 0.7139\n",
            "Epoch 98/150\n",
            "692/692 [==============================] - 0s 147us/step - loss: 0.5685 - accuracy: 0.7009\n",
            "Epoch 99/150\n",
            "692/692 [==============================] - 0s 136us/step - loss: 0.5598 - accuracy: 0.7197\n",
            "Epoch 100/150\n",
            "692/692 [==============================] - 0s 141us/step - loss: 0.5632 - accuracy: 0.7283\n",
            "Epoch 101/150\n",
            "692/692 [==============================] - 0s 156us/step - loss: 0.5612 - accuracy: 0.7139\n",
            "Epoch 102/150\n",
            "692/692 [==============================] - 0s 137us/step - loss: 0.5618 - accuracy: 0.7153\n",
            "Epoch 103/150\n",
            "692/692 [==============================] - 0s 132us/step - loss: 0.5544 - accuracy: 0.7254\n",
            "Epoch 104/150\n",
            "692/692 [==============================] - 0s 138us/step - loss: 0.5569 - accuracy: 0.7254\n",
            "Epoch 105/150\n",
            "692/692 [==============================] - 0s 135us/step - loss: 0.5591 - accuracy: 0.7066\n",
            "Epoch 106/150\n",
            "692/692 [==============================] - 0s 145us/step - loss: 0.5537 - accuracy: 0.7211\n",
            "Epoch 107/150\n",
            "692/692 [==============================] - 0s 158us/step - loss: 0.5626 - accuracy: 0.7052\n",
            "Epoch 108/150\n",
            "692/692 [==============================] - 0s 147us/step - loss: 0.5536 - accuracy: 0.7225\n",
            "Epoch 109/150\n",
            "692/692 [==============================] - 0s 137us/step - loss: 0.5568 - accuracy: 0.7197\n",
            "Epoch 110/150\n",
            "692/692 [==============================] - 0s 149us/step - loss: 0.5503 - accuracy: 0.7168\n",
            "Epoch 111/150\n",
            "692/692 [==============================] - 0s 171us/step - loss: 0.5546 - accuracy: 0.7312\n",
            "Epoch 112/150\n",
            "692/692 [==============================] - 0s 139us/step - loss: 0.5534 - accuracy: 0.7211\n",
            "Epoch 113/150\n",
            "692/692 [==============================] - 0s 143us/step - loss: 0.5540 - accuracy: 0.7197\n",
            "Epoch 114/150\n",
            "692/692 [==============================] - 0s 143us/step - loss: 0.5521 - accuracy: 0.7168\n",
            "Epoch 115/150\n",
            "692/692 [==============================] - 0s 141us/step - loss: 0.5496 - accuracy: 0.7254\n",
            "Epoch 116/150\n",
            "692/692 [==============================] - 0s 146us/step - loss: 0.5656 - accuracy: 0.7009\n",
            "Epoch 117/150\n",
            "692/692 [==============================] - 0s 177us/step - loss: 0.5476 - accuracy: 0.7225\n",
            "Epoch 118/150\n",
            "692/692 [==============================] - 0s 138us/step - loss: 0.5473 - accuracy: 0.7269\n",
            "Epoch 119/150\n",
            "692/692 [==============================] - 0s 133us/step - loss: 0.5471 - accuracy: 0.7355\n",
            "Epoch 120/150\n",
            "692/692 [==============================] - 0s 135us/step - loss: 0.5454 - accuracy: 0.7341\n",
            "Epoch 121/150\n",
            "692/692 [==============================] - 0s 122us/step - loss: 0.5505 - accuracy: 0.7327\n",
            "Epoch 122/150\n",
            "692/692 [==============================] - 0s 126us/step - loss: 0.5463 - accuracy: 0.7240\n",
            "Epoch 123/150\n",
            "692/692 [==============================] - 0s 128us/step - loss: 0.5501 - accuracy: 0.7269\n",
            "Epoch 124/150\n",
            "692/692 [==============================] - 0s 120us/step - loss: 0.5373 - accuracy: 0.7428\n",
            "Epoch 125/150\n",
            "692/692 [==============================] - 0s 118us/step - loss: 0.5477 - accuracy: 0.7254\n",
            "Epoch 126/150\n",
            "692/692 [==============================] - 0s 120us/step - loss: 0.5458 - accuracy: 0.7341\n",
            "Epoch 127/150\n",
            "692/692 [==============================] - 0s 122us/step - loss: 0.5421 - accuracy: 0.7327\n",
            "Epoch 128/150\n",
            "692/692 [==============================] - 0s 124us/step - loss: 0.5391 - accuracy: 0.7399\n",
            "Epoch 129/150\n",
            "692/692 [==============================] - 0s 118us/step - loss: 0.5354 - accuracy: 0.7384\n",
            "Epoch 130/150\n",
            "692/692 [==============================] - 0s 122us/step - loss: 0.5374 - accuracy: 0.7384\n",
            "Epoch 131/150\n",
            "692/692 [==============================] - 0s 117us/step - loss: 0.5364 - accuracy: 0.7312\n",
            "Epoch 132/150\n",
            "692/692 [==============================] - 0s 121us/step - loss: 0.5399 - accuracy: 0.7355\n",
            "Epoch 133/150\n",
            "692/692 [==============================] - 0s 129us/step - loss: 0.5388 - accuracy: 0.7413\n",
            "Epoch 134/150\n",
            "692/692 [==============================] - 0s 118us/step - loss: 0.5452 - accuracy: 0.7355\n",
            "Epoch 135/150\n",
            "692/692 [==============================] - 0s 122us/step - loss: 0.5303 - accuracy: 0.7457\n",
            "Epoch 136/150\n",
            "692/692 [==============================] - 0s 124us/step - loss: 0.5348 - accuracy: 0.7413\n",
            "Epoch 137/150\n",
            "692/692 [==============================] - 0s 128us/step - loss: 0.5388 - accuracy: 0.7312\n",
            "Epoch 138/150\n",
            "692/692 [==============================] - 0s 120us/step - loss: 0.5311 - accuracy: 0.7413\n",
            "Epoch 139/150\n",
            "692/692 [==============================] - 0s 124us/step - loss: 0.5359 - accuracy: 0.7254\n",
            "Epoch 140/150\n",
            "692/692 [==============================] - 0s 121us/step - loss: 0.5279 - accuracy: 0.7413\n",
            "Epoch 141/150\n",
            "692/692 [==============================] - 0s 119us/step - loss: 0.5321 - accuracy: 0.7471\n",
            "Epoch 142/150\n",
            "692/692 [==============================] - 0s 126us/step - loss: 0.5287 - accuracy: 0.7514\n",
            "Epoch 143/150\n",
            "692/692 [==============================] - 0s 128us/step - loss: 0.5325 - accuracy: 0.7413\n",
            "Epoch 144/150\n",
            "692/692 [==============================] - 0s 122us/step - loss: 0.5241 - accuracy: 0.7413\n",
            "Epoch 145/150\n",
            "692/692 [==============================] - 0s 123us/step - loss: 0.5264 - accuracy: 0.7471\n",
            "Epoch 146/150\n",
            "692/692 [==============================] - 0s 119us/step - loss: 0.5213 - accuracy: 0.7558\n",
            "Epoch 147/150\n",
            "692/692 [==============================] - 0s 116us/step - loss: 0.5165 - accuracy: 0.7601\n",
            "Epoch 148/150\n",
            "692/692 [==============================] - 0s 122us/step - loss: 0.5177 - accuracy: 0.7673\n",
            "Epoch 149/150\n",
            "692/692 [==============================] - 0s 117us/step - loss: 0.5127 - accuracy: 0.7543\n",
            "Epoch 150/150\n",
            "692/692 [==============================] - 0s 110us/step - loss: 0.5165 - accuracy: 0.7659\n",
            "76/76 [==============================] - 0s 299us/step\n",
            "Epoch 1/150\n",
            "692/692 [==============================] - 0s 238us/step - loss: 0.6832 - accuracy: 0.6257\n",
            "Epoch 2/150\n",
            "692/692 [==============================] - 0s 108us/step - loss: 0.6677 - accuracy: 0.6503\n",
            "Epoch 3/150\n",
            "692/692 [==============================] - 0s 110us/step - loss: 0.6618 - accuracy: 0.6503\n",
            "Epoch 4/150\n",
            "692/692 [==============================] - 0s 115us/step - loss: 0.6570 - accuracy: 0.6503\n",
            "Epoch 5/150\n",
            "692/692 [==============================] - 0s 113us/step - loss: 0.6563 - accuracy: 0.6561\n",
            "Epoch 6/150\n",
            "692/692 [==============================] - 0s 113us/step - loss: 0.6479 - accuracy: 0.6517\n",
            "Epoch 7/150\n",
            "692/692 [==============================] - 0s 109us/step - loss: 0.6384 - accuracy: 0.6633\n",
            "Epoch 8/150\n",
            "692/692 [==============================] - 0s 113us/step - loss: 0.6299 - accuracy: 0.6647\n",
            "Epoch 9/150\n",
            "692/692 [==============================] - 0s 110us/step - loss: 0.6217 - accuracy: 0.6705\n",
            "Epoch 10/150\n",
            "692/692 [==============================] - 0s 112us/step - loss: 0.6206 - accuracy: 0.6749\n",
            "Epoch 11/150\n",
            "692/692 [==============================] - 0s 112us/step - loss: 0.6081 - accuracy: 0.6821\n",
            "Epoch 12/150\n",
            "692/692 [==============================] - 0s 132us/step - loss: 0.6007 - accuracy: 0.6777\n",
            "Epoch 13/150\n",
            "692/692 [==============================] - 0s 122us/step - loss: 0.6028 - accuracy: 0.6806\n",
            "Epoch 14/150\n",
            "692/692 [==============================] - 0s 115us/step - loss: 0.5963 - accuracy: 0.6864\n",
            "Epoch 15/150\n",
            "692/692 [==============================] - 0s 113us/step - loss: 0.5911 - accuracy: 0.6965\n",
            "Epoch 16/150\n",
            "692/692 [==============================] - 0s 112us/step - loss: 0.5885 - accuracy: 0.7081\n",
            "Epoch 17/150\n",
            "692/692 [==============================] - 0s 112us/step - loss: 0.5845 - accuracy: 0.7225\n",
            "Epoch 18/150\n",
            "692/692 [==============================] - 0s 114us/step - loss: 0.5811 - accuracy: 0.7254\n",
            "Epoch 19/150\n",
            "692/692 [==============================] - 0s 115us/step - loss: 0.5799 - accuracy: 0.7081\n",
            "Epoch 20/150\n",
            "692/692 [==============================] - 0s 136us/step - loss: 0.5794 - accuracy: 0.7066\n",
            "Epoch 21/150\n",
            "692/692 [==============================] - 0s 115us/step - loss: 0.5757 - accuracy: 0.7038\n",
            "Epoch 22/150\n",
            "692/692 [==============================] - 0s 132us/step - loss: 0.5723 - accuracy: 0.7197\n",
            "Epoch 23/150\n",
            "692/692 [==============================] - 0s 132us/step - loss: 0.5678 - accuracy: 0.7168\n",
            "Epoch 24/150\n",
            "692/692 [==============================] - 0s 129us/step - loss: 0.5628 - accuracy: 0.7240\n",
            "Epoch 25/150\n",
            "692/692 [==============================] - 0s 150us/step - loss: 0.5618 - accuracy: 0.7327\n",
            "Epoch 26/150\n",
            "692/692 [==============================] - 0s 138us/step - loss: 0.5593 - accuracy: 0.7225\n",
            "Epoch 27/150\n",
            "692/692 [==============================] - 0s 133us/step - loss: 0.5616 - accuracy: 0.7211\n",
            "Epoch 28/150\n",
            "692/692 [==============================] - 0s 118us/step - loss: 0.5605 - accuracy: 0.7269\n",
            "Epoch 29/150\n",
            "692/692 [==============================] - 0s 114us/step - loss: 0.5554 - accuracy: 0.7341\n",
            "Epoch 30/150\n",
            "692/692 [==============================] - 0s 114us/step - loss: 0.5515 - accuracy: 0.7283\n",
            "Epoch 31/150\n",
            "692/692 [==============================] - 0s 112us/step - loss: 0.5524 - accuracy: 0.7355\n",
            "Epoch 32/150\n",
            "692/692 [==============================] - 0s 118us/step - loss: 0.5507 - accuracy: 0.7283\n",
            "Epoch 33/150\n",
            "692/692 [==============================] - 0s 114us/step - loss: 0.5481 - accuracy: 0.7240\n",
            "Epoch 34/150\n",
            "692/692 [==============================] - 0s 116us/step - loss: 0.5507 - accuracy: 0.7197\n",
            "Epoch 35/150\n",
            "692/692 [==============================] - 0s 114us/step - loss: 0.5480 - accuracy: 0.7269\n",
            "Epoch 36/150\n",
            "692/692 [==============================] - 0s 112us/step - loss: 0.5432 - accuracy: 0.7384\n",
            "Epoch 37/150\n",
            "692/692 [==============================] - 0s 117us/step - loss: 0.5462 - accuracy: 0.7384\n",
            "Epoch 38/150\n",
            "692/692 [==============================] - 0s 112us/step - loss: 0.5416 - accuracy: 0.7355\n",
            "Epoch 39/150\n",
            "692/692 [==============================] - 0s 111us/step - loss: 0.5481 - accuracy: 0.7370\n",
            "Epoch 40/150\n",
            "692/692 [==============================] - 0s 115us/step - loss: 0.5427 - accuracy: 0.7471\n",
            "Epoch 41/150\n",
            "692/692 [==============================] - 0s 121us/step - loss: 0.5401 - accuracy: 0.7225\n",
            "Epoch 42/150\n",
            "692/692 [==============================] - 0s 118us/step - loss: 0.5395 - accuracy: 0.7283\n",
            "Epoch 43/150\n",
            "692/692 [==============================] - 0s 128us/step - loss: 0.5382 - accuracy: 0.7370\n",
            "Epoch 44/150\n",
            "692/692 [==============================] - 0s 114us/step - loss: 0.5380 - accuracy: 0.7486\n",
            "Epoch 45/150\n",
            "692/692 [==============================] - 0s 116us/step - loss: 0.5392 - accuracy: 0.7370\n",
            "Epoch 46/150\n",
            "692/692 [==============================] - 0s 118us/step - loss: 0.5371 - accuracy: 0.7312\n",
            "Epoch 47/150\n",
            "692/692 [==============================] - 0s 114us/step - loss: 0.5322 - accuracy: 0.7471\n",
            "Epoch 48/150\n",
            "692/692 [==============================] - 0s 112us/step - loss: 0.5342 - accuracy: 0.7471\n",
            "Epoch 49/150\n",
            "692/692 [==============================] - 0s 129us/step - loss: 0.5344 - accuracy: 0.7370\n",
            "Epoch 50/150\n",
            "692/692 [==============================] - 0s 117us/step - loss: 0.5367 - accuracy: 0.7457\n",
            "Epoch 51/150\n",
            "692/692 [==============================] - 0s 129us/step - loss: 0.5331 - accuracy: 0.7514\n",
            "Epoch 52/150\n",
            "692/692 [==============================] - 0s 124us/step - loss: 0.5270 - accuracy: 0.7327\n",
            "Epoch 53/150\n",
            "692/692 [==============================] - 0s 114us/step - loss: 0.5287 - accuracy: 0.7442\n",
            "Epoch 54/150\n",
            "692/692 [==============================] - 0s 118us/step - loss: 0.5289 - accuracy: 0.7428\n",
            "Epoch 55/150\n",
            "692/692 [==============================] - 0s 113us/step - loss: 0.5319 - accuracy: 0.7399\n",
            "Epoch 56/150\n",
            "692/692 [==============================] - 0s 113us/step - loss: 0.5267 - accuracy: 0.7370\n",
            "Epoch 57/150\n",
            "692/692 [==============================] - 0s 125us/step - loss: 0.5280 - accuracy: 0.7442\n",
            "Epoch 58/150\n",
            "692/692 [==============================] - 0s 132us/step - loss: 0.5247 - accuracy: 0.7529\n",
            "Epoch 59/150\n",
            "692/692 [==============================] - 0s 131us/step - loss: 0.5304 - accuracy: 0.7500\n",
            "Epoch 60/150\n",
            "692/692 [==============================] - 0s 132us/step - loss: 0.5308 - accuracy: 0.7428\n",
            "Epoch 61/150\n",
            "692/692 [==============================] - 0s 141us/step - loss: 0.5251 - accuracy: 0.7500\n",
            "Epoch 62/150\n",
            "692/692 [==============================] - 0s 137us/step - loss: 0.5284 - accuracy: 0.7543\n",
            "Epoch 63/150\n",
            "692/692 [==============================] - 0s 125us/step - loss: 0.5250 - accuracy: 0.7529\n",
            "Epoch 64/150\n",
            "692/692 [==============================] - 0s 111us/step - loss: 0.5261 - accuracy: 0.7471\n",
            "Epoch 65/150\n",
            "692/692 [==============================] - 0s 115us/step - loss: 0.5203 - accuracy: 0.7428\n",
            "Epoch 66/150\n",
            "692/692 [==============================] - 0s 115us/step - loss: 0.5239 - accuracy: 0.7601\n",
            "Epoch 67/150\n",
            "692/692 [==============================] - 0s 124us/step - loss: 0.5250 - accuracy: 0.7529\n",
            "Epoch 68/150\n",
            "692/692 [==============================] - 0s 121us/step - loss: 0.5186 - accuracy: 0.7673\n",
            "Epoch 69/150\n",
            "692/692 [==============================] - 0s 133us/step - loss: 0.5185 - accuracy: 0.7688\n",
            "Epoch 70/150\n",
            "692/692 [==============================] - 0s 132us/step - loss: 0.5166 - accuracy: 0.7471\n",
            "Epoch 71/150\n",
            "692/692 [==============================] - 0s 133us/step - loss: 0.5164 - accuracy: 0.7399\n",
            "Epoch 72/150\n",
            "692/692 [==============================] - 0s 139us/step - loss: 0.5139 - accuracy: 0.7688\n",
            "Epoch 73/150\n",
            "692/692 [==============================] - 0s 132us/step - loss: 0.5210 - accuracy: 0.7413\n",
            "Epoch 74/150\n",
            "692/692 [==============================] - 0s 129us/step - loss: 0.5169 - accuracy: 0.7616\n",
            "Epoch 75/150\n",
            "692/692 [==============================] - 0s 123us/step - loss: 0.5157 - accuracy: 0.7731\n",
            "Epoch 76/150\n",
            "692/692 [==============================] - 0s 111us/step - loss: 0.5171 - accuracy: 0.7471\n",
            "Epoch 77/150\n",
            "692/692 [==============================] - 0s 115us/step - loss: 0.5145 - accuracy: 0.7558\n",
            "Epoch 78/150\n",
            "692/692 [==============================] - 0s 112us/step - loss: 0.5232 - accuracy: 0.7558\n",
            "Epoch 79/150\n",
            "692/692 [==============================] - 0s 111us/step - loss: 0.5209 - accuracy: 0.7370\n",
            "Epoch 80/150\n",
            "692/692 [==============================] - 0s 136us/step - loss: 0.5105 - accuracy: 0.7775\n",
            "Epoch 81/150\n",
            "692/692 [==============================] - 0s 139us/step - loss: 0.5056 - accuracy: 0.7572\n",
            "Epoch 82/150\n",
            "692/692 [==============================] - 0s 137us/step - loss: 0.5180 - accuracy: 0.7688\n",
            "Epoch 83/150\n",
            "692/692 [==============================] - 0s 142us/step - loss: 0.5145 - accuracy: 0.7543\n",
            "Epoch 84/150\n",
            "692/692 [==============================] - 0s 137us/step - loss: 0.5064 - accuracy: 0.7645\n",
            "Epoch 85/150\n",
            "692/692 [==============================] - 0s 137us/step - loss: 0.5131 - accuracy: 0.7471\n",
            "Epoch 86/150\n",
            "692/692 [==============================] - 0s 128us/step - loss: 0.5038 - accuracy: 0.7645\n",
            "Epoch 87/150\n",
            "692/692 [==============================] - 0s 133us/step - loss: 0.5071 - accuracy: 0.7630\n",
            "Epoch 88/150\n",
            "692/692 [==============================] - 0s 116us/step - loss: 0.5054 - accuracy: 0.7601\n",
            "Epoch 89/150\n",
            "692/692 [==============================] - 0s 110us/step - loss: 0.5047 - accuracy: 0.7688\n",
            "Epoch 90/150\n",
            "692/692 [==============================] - 0s 115us/step - loss: 0.5085 - accuracy: 0.7572\n",
            "Epoch 91/150\n",
            "692/692 [==============================] - 0s 123us/step - loss: 0.5041 - accuracy: 0.7558\n",
            "Epoch 92/150\n",
            "692/692 [==============================] - 0s 111us/step - loss: 0.5002 - accuracy: 0.7717\n",
            "Epoch 93/150\n",
            "692/692 [==============================] - 0s 113us/step - loss: 0.5052 - accuracy: 0.7717\n",
            "Epoch 94/150\n",
            "692/692 [==============================] - 0s 114us/step - loss: 0.5079 - accuracy: 0.7500\n",
            "Epoch 95/150\n",
            "692/692 [==============================] - 0s 123us/step - loss: 0.5006 - accuracy: 0.7601\n",
            "Epoch 96/150\n",
            "692/692 [==============================] - 0s 132us/step - loss: 0.5008 - accuracy: 0.7803\n",
            "Epoch 97/150\n",
            "692/692 [==============================] - 0s 132us/step - loss: 0.5054 - accuracy: 0.7688\n",
            "Epoch 98/150\n",
            "692/692 [==============================] - 0s 114us/step - loss: 0.4987 - accuracy: 0.7688\n",
            "Epoch 99/150\n",
            "692/692 [==============================] - 0s 114us/step - loss: 0.5011 - accuracy: 0.7601\n",
            "Epoch 100/150\n",
            "692/692 [==============================] - 0s 125us/step - loss: 0.5044 - accuracy: 0.7616\n",
            "Epoch 101/150\n",
            "692/692 [==============================] - 0s 115us/step - loss: 0.5019 - accuracy: 0.7702\n",
            "Epoch 102/150\n",
            "692/692 [==============================] - 0s 120us/step - loss: 0.4989 - accuracy: 0.7702\n",
            "Epoch 103/150\n",
            "692/692 [==============================] - 0s 131us/step - loss: 0.4972 - accuracy: 0.7731\n",
            "Epoch 104/150\n",
            "692/692 [==============================] - 0s 112us/step - loss: 0.4983 - accuracy: 0.7673\n",
            "Epoch 105/150\n",
            "692/692 [==============================] - 0s 115us/step - loss: 0.4958 - accuracy: 0.7818\n",
            "Epoch 106/150\n",
            "692/692 [==============================] - 0s 115us/step - loss: 0.4946 - accuracy: 0.7601\n",
            "Epoch 107/150\n",
            "692/692 [==============================] - 0s 120us/step - loss: 0.4923 - accuracy: 0.7659\n",
            "Epoch 108/150\n",
            "692/692 [==============================] - 0s 114us/step - loss: 0.4996 - accuracy: 0.7630\n",
            "Epoch 109/150\n",
            "692/692 [==============================] - 0s 119us/step - loss: 0.4896 - accuracy: 0.7746\n",
            "Epoch 110/150\n",
            "692/692 [==============================] - 0s 112us/step - loss: 0.4944 - accuracy: 0.7688\n",
            "Epoch 111/150\n",
            "692/692 [==============================] - 0s 113us/step - loss: 0.4939 - accuracy: 0.7587\n",
            "Epoch 112/150\n",
            "692/692 [==============================] - 0s 114us/step - loss: 0.5010 - accuracy: 0.7630\n",
            "Epoch 113/150\n",
            "692/692 [==============================] - 0s 113us/step - loss: 0.4927 - accuracy: 0.7630\n",
            "Epoch 114/150\n",
            "692/692 [==============================] - 0s 115us/step - loss: 0.4953 - accuracy: 0.7760\n",
            "Epoch 115/150\n",
            "692/692 [==============================] - 0s 118us/step - loss: 0.4907 - accuracy: 0.7803\n",
            "Epoch 116/150\n",
            "692/692 [==============================] - 0s 113us/step - loss: 0.4877 - accuracy: 0.7673\n",
            "Epoch 117/150\n",
            "692/692 [==============================] - 0s 114us/step - loss: 0.4899 - accuracy: 0.7688\n",
            "Epoch 118/150\n",
            "692/692 [==============================] - 0s 112us/step - loss: 0.4909 - accuracy: 0.7746\n",
            "Epoch 119/150\n",
            "692/692 [==============================] - 0s 114us/step - loss: 0.4854 - accuracy: 0.7818\n",
            "Epoch 120/150\n",
            "692/692 [==============================] - 0s 121us/step - loss: 0.4868 - accuracy: 0.7789\n",
            "Epoch 121/150\n",
            "692/692 [==============================] - 0s 115us/step - loss: 0.4888 - accuracy: 0.7861\n",
            "Epoch 122/150\n",
            "692/692 [==============================] - 0s 113us/step - loss: 0.4798 - accuracy: 0.7775\n",
            "Epoch 123/150\n",
            "692/692 [==============================] - 0s 117us/step - loss: 0.4854 - accuracy: 0.7803\n",
            "Epoch 124/150\n",
            "692/692 [==============================] - 0s 121us/step - loss: 0.4860 - accuracy: 0.7803\n",
            "Epoch 125/150\n",
            "692/692 [==============================] - 0s 119us/step - loss: 0.4808 - accuracy: 0.7746\n",
            "Epoch 126/150\n",
            "692/692 [==============================] - 0s 114us/step - loss: 0.4837 - accuracy: 0.7746\n",
            "Epoch 127/150\n",
            "692/692 [==============================] - 0s 116us/step - loss: 0.4856 - accuracy: 0.7702\n",
            "Epoch 128/150\n",
            "692/692 [==============================] - 0s 116us/step - loss: 0.4819 - accuracy: 0.7760\n",
            "Epoch 129/150\n",
            "692/692 [==============================] - 0s 115us/step - loss: 0.4842 - accuracy: 0.7876\n",
            "Epoch 130/150\n",
            "692/692 [==============================] - 0s 115us/step - loss: 0.4921 - accuracy: 0.7818\n",
            "Epoch 131/150\n",
            "692/692 [==============================] - 0s 120us/step - loss: 0.4831 - accuracy: 0.7803\n",
            "Epoch 132/150\n",
            "692/692 [==============================] - 0s 117us/step - loss: 0.4819 - accuracy: 0.7890\n",
            "Epoch 133/150\n",
            "692/692 [==============================] - 0s 113us/step - loss: 0.4820 - accuracy: 0.7673\n",
            "Epoch 134/150\n",
            "692/692 [==============================] - 0s 112us/step - loss: 0.4802 - accuracy: 0.7746\n",
            "Epoch 135/150\n",
            "692/692 [==============================] - 0s 115us/step - loss: 0.4798 - accuracy: 0.7789\n",
            "Epoch 136/150\n",
            "692/692 [==============================] - 0s 111us/step - loss: 0.4846 - accuracy: 0.7746\n",
            "Epoch 137/150\n",
            "692/692 [==============================] - 0s 130us/step - loss: 0.4806 - accuracy: 0.7746\n",
            "Epoch 138/150\n",
            "692/692 [==============================] - 0s 157us/step - loss: 0.4829 - accuracy: 0.7717\n",
            "Epoch 139/150\n",
            "692/692 [==============================] - 0s 123us/step - loss: 0.4871 - accuracy: 0.7587\n",
            "Epoch 140/150\n",
            "692/692 [==============================] - 0s 119us/step - loss: 0.4823 - accuracy: 0.7803\n",
            "Epoch 141/150\n",
            "692/692 [==============================] - 0s 115us/step - loss: 0.4757 - accuracy: 0.7861\n",
            "Epoch 142/150\n",
            "692/692 [==============================] - 0s 111us/step - loss: 0.4830 - accuracy: 0.7832\n",
            "Epoch 143/150\n",
            "692/692 [==============================] - 0s 112us/step - loss: 0.4744 - accuracy: 0.7818\n",
            "Epoch 144/150\n",
            "692/692 [==============================] - 0s 119us/step - loss: 0.4767 - accuracy: 0.7673\n",
            "Epoch 145/150\n",
            "692/692 [==============================] - 0s 109us/step - loss: 0.4905 - accuracy: 0.7630\n",
            "Epoch 146/150\n",
            "692/692 [==============================] - 0s 111us/step - loss: 0.4768 - accuracy: 0.7702\n",
            "Epoch 147/150\n",
            "692/692 [==============================] - 0s 115us/step - loss: 0.4748 - accuracy: 0.7760\n",
            "Epoch 148/150\n",
            "692/692 [==============================] - 0s 123us/step - loss: 0.4713 - accuracy: 0.7847\n",
            "Epoch 149/150\n",
            "692/692 [==============================] - 0s 112us/step - loss: 0.4695 - accuracy: 0.7861\n",
            "Epoch 150/150\n",
            "692/692 [==============================] - 0s 109us/step - loss: 0.4651 - accuracy: 0.7890\n",
            "76/76 [==============================] - 0s 289us/step\n",
            "<built-in method mean of numpy.ndarray object at 0x7fb6c83d4df0>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fteuMJXKSRgA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "43f5b0ff-11a0-4ed1-9fcd-39b55b9bd006"
      },
      "source": [
        "print(results.mean())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7435919284820557\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8Fm_wQkSRZL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdWL03a3CtPZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLLPUa9sCu3o"
      },
      "source": [
        "**GRID SEARCH DEEP LEARNING MODEL PARAMETERS -- HYPERPARAMTER TUNNING**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-U-g7_tT7pi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "492bf69d-14b2-4bb9-8a79-822d9d9df3b6"
      },
      "source": [
        "#MLP for Pima Indians dataset with grid search via sklearn\n",
        "\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense \n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "#Function to create model, required for KerasClassifier\n",
        "def create_model():\n",
        "\n",
        "  #create model\n",
        "  model = Sequential()\n",
        "  model.add(Dense(12, input_dim=8, kernel_initializer='uniform', activation='relu'))\n",
        "  model.add(Dense(8, kernel_initializer='uniform', activation='relu'))\n",
        "  model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
        "\n",
        "  #Compile the model\n",
        "  model.compile(loss='binary_crossentropy', optimizer = 'adam', metrics=['accuracy'])\n",
        "\n",
        "  return model\n",
        "\n",
        "#Fix the random seed for reproducibility\n",
        "seed = 7\n",
        "np.random.seed(seed)\n",
        "\n",
        "#load the dataset\n",
        "dataset = pd.read_csv('/content/datasets_228_482_diabetes.csv')\n",
        "\n",
        "#Split the dataset into X and Y variables\n",
        "X = dataset.iloc[:, :8]\n",
        "Y = dataset.iloc[:, 8]\n",
        "\n",
        "#Create model \n",
        "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
        "\n",
        "#grid search epochs, batch size and optimizers\n",
        "\n",
        "batch_size = [10, 20, 40, 60, 80, 100]\n",
        "epochs = [10, 50, 100]\n",
        "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
        "grid_result = grid.fit(X, Y)\n",
        "\n",
        "#summarize results\n",
        "print(grid_result.best_score_, grid_result.best_params_)\n",
        "\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7265625 {'batch_size': 10, 'epochs': 100}\n",
            "0.682292 (0.008027) with: {'batch_size': 10, 'epochs': 10}\n",
            "0.687500 (0.008438) with: {'batch_size': 10, 'epochs': 50}\n",
            "0.726562 (0.005524) with: {'batch_size': 10, 'epochs': 100}\n",
            "0.664062 (0.030425) with: {'batch_size': 20, 'epochs': 10}\n",
            "0.684896 (0.003683) with: {'batch_size': 20, 'epochs': 50}\n",
            "0.720052 (0.017566) with: {'batch_size': 20, 'epochs': 100}\n",
            "0.653646 (0.019225) with: {'batch_size': 40, 'epochs': 10}\n",
            "0.675781 (0.009568) with: {'batch_size': 40, 'epochs': 50}\n",
            "0.701823 (0.013279) with: {'batch_size': 40, 'epochs': 100}\n",
            "0.651042 (0.024150) with: {'batch_size': 60, 'epochs': 10}\n",
            "0.673177 (0.039623) with: {'batch_size': 60, 'epochs': 50}\n",
            "0.700521 (0.011201) with: {'batch_size': 60, 'epochs': 100}\n",
            "0.651042 (0.024774) with: {'batch_size': 80, 'epochs': 10}\n",
            "0.692708 (0.006639) with: {'batch_size': 80, 'epochs': 50}\n",
            "0.670573 (0.037783) with: {'batch_size': 80, 'epochs': 100}\n",
            "0.651042 (0.024774) with: {'batch_size': 100, 'epochs': 10}\n",
            "0.667969 (0.024080) with: {'batch_size': 100, 'epochs': 50}\n",
            "0.688802 (0.014382) with: {'batch_size': 100, 'epochs': 100}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CSemnYnT7sM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "43ebf28e-7a4a-4a55-a007-fd2447672b54"
      },
      "source": [
        "\n",
        "# Use scikit-learn to grid search the batch size and epochs\n",
        "import numpy \n",
        "import pandas as pd\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "# Function to create model, required for KerasClassifier\n",
        "def create_model():\n",
        "\t# create model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Dense(12, input_dim=8, activation='relu'))\n",
        "\tmodel.add(Dense(1, activation='sigmoid'))\n",
        "\t# Compile model\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\treturn model\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "\n",
        "#load the dataset\n",
        "dataset = pd.read_csv('/content/datasets_228_482_diabetes.csv')\n",
        "\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset.iloc[:,0:8]\n",
        "Y = dataset.iloc[:,8]\n",
        "# create model\n",
        "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
        "# define the grid search parameters\n",
        "batch_size = [10, 20, 40, 60, 80, 100]\n",
        "epochs = [10, 50, 100]\n",
        "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
        "grid_result = grid.fit(X, Y)\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best: 0.694010 using {'batch_size': 10, 'epochs': 100}\n",
            "0.648438 (0.019918) with: {'batch_size': 10, 'epochs': 10}\n",
            "0.690104 (0.003683) with: {'batch_size': 10, 'epochs': 50}\n",
            "0.694010 (0.017566) with: {'batch_size': 10, 'epochs': 100}\n",
            "0.600260 (0.045368) with: {'batch_size': 20, 'epochs': 10}\n",
            "0.662760 (0.023510) with: {'batch_size': 20, 'epochs': 50}\n",
            "0.674479 (0.012890) with: {'batch_size': 20, 'epochs': 100}\n",
            "0.623698 (0.036966) with: {'batch_size': 40, 'epochs': 10}\n",
            "0.619792 (0.049855) with: {'batch_size': 40, 'epochs': 50}\n",
            "0.647135 (0.014382) with: {'batch_size': 40, 'epochs': 100}\n",
            "0.589844 (0.025315) with: {'batch_size': 60, 'epochs': 10}\n",
            "0.604167 (0.006639) with: {'batch_size': 60, 'epochs': 50}\n",
            "0.658854 (0.019488) with: {'batch_size': 60, 'epochs': 100}\n",
            "0.481771 (0.116767) with: {'batch_size': 80, 'epochs': 10}\n",
            "0.631510 (0.062364) with: {'batch_size': 80, 'epochs': 50}\n",
            "0.662760 (0.007366) with: {'batch_size': 80, 'epochs': 100}\n",
            "0.497396 (0.087598) with: {'batch_size': 100, 'epochs': 10}\n",
            "0.608073 (0.059868) with: {'batch_size': 100, 'epochs': 50}\n",
            "0.635417 (0.041504) with: {'batch_size': 100, 'epochs': 100}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lO2YPBiIT7vn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "299bf12b-eaa0-4b19-f01c-6c924ac98c82"
      },
      "source": [
        "\n",
        "# Use scikit-learn to grid search the weight initialization\n",
        "import numpy\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "# Function to create model, required for KerasClassifier\n",
        "def create_model(init_mode='uniform'):\n",
        "\t# create model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Dense(12, input_dim=8, kernel_initializer=init_mode, activation='relu'))\n",
        "\tmodel.add(Dense(1, kernel_initializer=init_mode, activation='sigmoid'))\n",
        "\t# Compile model\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\treturn model\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "# load dataset\n",
        "dataset = pd.read_csv(\"/content/diabetes.csv\")\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset.iloc[:,0:8]\n",
        "Y = dataset.iloc[:,8]\n",
        "# create model\n",
        "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
        "# define the grid search parameters\n",
        "init_mode = ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']\n",
        "param_grid = dict(init_mode=init_mode)\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
        "grid_result = grid.fit(X, Y)\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best: 0.725260 using {'init_mode': 'normal'}\n",
            "0.716146 (0.014382) with: {'init_mode': 'uniform'}\n",
            "0.688802 (0.006639) with: {'init_mode': 'lecun_uniform'}\n",
            "0.725260 (0.025976) with: {'init_mode': 'normal'}\n",
            "0.651042 (0.024774) with: {'init_mode': 'zero'}\n",
            "0.705729 (0.026557) with: {'init_mode': 'glorot_normal'}\n",
            "0.705729 (0.012075) with: {'init_mode': 'glorot_uniform'}\n",
            "0.680990 (0.015073) with: {'init_mode': 'he_normal'}\n",
            "0.690104 (0.027498) with: {'init_mode': 'he_uniform'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0COzZO2JIA_y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5AICPcWQdZL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evfDPQY7QerD"
      },
      "source": [
        "# "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pYN5Ub5Qdgt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 726
        },
        "outputId": "8dedf689-5af4-4592-cf87-6d40766987a6"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "#Fix the random seed for reproducibility\n",
        "seed = 7\n",
        "np.random.seed(seed)\n",
        "\n",
        "#Load the iris datset\n",
        "dataset = pd.read_csv(\"/content/Iris.csv\", header=None)\n",
        "\n",
        "\n",
        "#Split the dataset into X and Y variables\n",
        "X = dataset.iloc[:, :4]\n",
        "Y = dataset.iloc[:, 4]\n",
        "\n",
        "#Encode class values as integer\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(Y)\n",
        "encoded_Y = encoder.transform(Y)\n",
        "\n",
        "#Convert integers to dummy variables (i.e. one hot encoded)\n",
        "dummy_y = to_categorical(encoded_Y)\n",
        "\n",
        "#Create the model\n",
        "def baseline_model():\n",
        "  #create model\n",
        "  model = Sequential()\n",
        "  model.add(Dense(4, input_dim=4, kernel_initializer='uniform', activation = 'relu'))\n",
        "  model.add(Dense(3, kernel_initializer='uniform', activation = 'relu'))\n",
        "\n",
        "  #compile the model\n",
        "  model.compile(loss='binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "\n",
        "  return model\n",
        "\n",
        "estimator = KerasClassifier(build_fn=baseline_model, epochs=150, batch_size=10, verbose=0)\n",
        " \n",
        "\n",
        "kfold = KFold(n_splits=10, shuffle=True, random_state = seed)\n",
        "\n",
        "results = cross_val_score(estimator, X, dummy_y, cv=kfold)\n",
        "\n",
        "print(results.mean()*100, results.std()*100)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Error when checking target: expected dense_2 to have shape (3,) but got array with shape (23,)\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Error when checking target: expected dense_4 to have shape (3,) but got array with shape (23,)\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Error when checking target: expected dense_6 to have shape (3,) but got array with shape (23,)\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Error when checking target: expected dense_8 to have shape (3,) but got array with shape (23,)\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Error when checking target: expected dense_10 to have shape (3,) but got array with shape (23,)\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Error when checking target: expected dense_12 to have shape (3,) but got array with shape (23,)\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "nan nan\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Error when checking target: expected dense_14 to have shape (3,) but got array with shape (23,)\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Error when checking target: expected dense_16 to have shape (3,) but got array with shape (23,)\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Error when checking target: expected dense_18 to have shape (3,) but got array with shape (23,)\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Error when checking target: expected dense_20 to have shape (3,) but got array with shape (23,)\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2WXBXAuITNp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "7cee4744-7fd9-46d3-c6be-3a910e4d4132"
      },
      "source": [
        "pip install np_utils"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: np_utils in /usr/local/lib/python3.6/dist-packages (0.5.12.1)\n",
            "Requirement already satisfied: future>=0.16 in /usr/local/lib/python3.6/dist-packages (from np_utils) (0.16.0)\n",
            "Requirement already satisfied: numpy>=1.0 in /usr/local/lib/python3.6/dist-packages (from np_utils) (1.18.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXJZSPBiITbF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "outputId": "cf2ef00e-a6ab-4233-be19-9887999ab5cb"
      },
      "source": [
        "pip install keras-utils"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras-utils\n",
            "  Downloading https://files.pythonhosted.org/packages/31/a2/8be2aee1c8cd388e83d447556c2c84a396944c8bad93d710c5e757f8e98e/keras-utils-1.0.13.tar.gz\n",
            "Requirement already satisfied: Keras>=2.1.5 in /usr/local/lib/python3.6/dist-packages (from keras-utils) (2.3.1)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras-utils) (1.4.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras-utils) (1.12.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras-utils) (3.13)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras-utils) (1.18.4)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras-utils) (2.10.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras-utils) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras-utils) (1.1.2)\n",
            "Building wheels for collected packages: keras-utils\n",
            "  Building wheel for keras-utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-utils: filename=keras_utils-1.0.13-cp36-none-any.whl size=2657 sha256=52288cf899b247f677db92d310d226e86ca8647b7c9ec54bcda9856a9fdfd98e\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/25/27/7707005c1cb27e1ffc8277b004ac295e34767b02b44d73d6be\n",
            "Successfully built keras-utils\n",
            "Installing collected packages: keras-utils\n",
            "Successfully installed keras-utils-1.0.13\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rq6XJFlITn4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "8ee10923-672c-4e66-e785-f550935373a2"
      },
      "source": [
        "print(encoded_Y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[22  1  1  1  1  1  3  2  1  1  0  1  1  0  0  1  3  3  2  2  2  1  3  1\n",
            "  4  1  1  3  1  1  1  1  3  0  1  0  1  1  0  1  1  2  2  1  5  3  2  1\n",
            "  1  1  1 10 11 11  9 11  9 12  6  9 10  6 11  6 10  9 10 11  6 11  7 14\n",
            "  9 11  8  9 10 10 13 11  6  7  6  8 12 11 12 11  9  9  9  8 10  8  6  9\n",
            "  8  9  9  7  9 21 15 17 14 18 17 13 14 14 21 16 15 17 16 20 19 14 18 19\n",
            " 11 19 16 16 14 17 14 14 14 17 12 15 16 18 11 10 19 20 14 14 17 20 19 15\n",
            " 19 21 19 15 16 19 14]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKuuqqRaXi4C"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H36EB6apXi-K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 726
        },
        "outputId": "82ccf6c4-798f-49c5-850e-cc0621671b53"
      },
      "source": [
        "# multi-class classification with Keras\n",
        "import pandas\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.utils import np_utils\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "# load dataset\n",
        "dataset = pandas.read_csv(\"/content/diabetes.csv\", header=None)\n",
        "\n",
        "X = dataset.iloc[:,0:4]\n",
        "Y = dataset.iloc[:,4]\n",
        "# encode class values as integers\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(Y)\n",
        "encoded_Y = encoder.transform(Y)\n",
        "# convert integers to dummy variables (i.e. one hot encoded)\n",
        "dummy_y = np_utils.to_categorical(encoded_Y)\n",
        " \n",
        "# define baseline model\n",
        "def baseline_model():\n",
        "\t# create model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Dense(8, input_dim=4, activation='relu'))\n",
        "\tmodel.add(Dense(3, activation='softmax'))\n",
        "\t# Compile model\n",
        "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\treturn model\n",
        " \n",
        "estimator = KerasClassifier(build_fn=baseline_model, epochs=200, batch_size=5, verbose=0)\n",
        "kfold = KFold(n_splits=10, shuffle=True)\n",
        "results = cross_val_score(estimator, X, dummy_y, cv=kfold)\n",
        "print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Error when checking target: expected dense_26 to have shape (3,) but got array with shape (187,)\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Error when checking target: expected dense_28 to have shape (3,) but got array with shape (187,)\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Error when checking target: expected dense_30 to have shape (3,) but got array with shape (187,)\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Error when checking target: expected dense_32 to have shape (3,) but got array with shape (187,)\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Error when checking target: expected dense_34 to have shape (3,) but got array with shape (187,)\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Error when checking target: expected dense_36 to have shape (3,) but got array with shape (187,)\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Error when checking target: expected dense_38 to have shape (3,) but got array with shape (187,)\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Baseline: nan% (nan%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Error when checking target: expected dense_40 to have shape (3,) but got array with shape (187,)\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Error when checking target: expected dense_42 to have shape (3,) but got array with shape (187,)\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Error when checking target: expected dense_44 to have shape (3,) but got array with shape (187,)\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8GLv9JHXjHq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ww8asF98XjSc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "outputId": "ca175f64-25f3-4260-c94e-1d187e52475d"
      },
      "source": [
        "# multi-class classification with Keras\n",
        "import pandas\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.utils import np_utils\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "# load dataset\n",
        "dataframe = pandas.read_csv(\"/content/diabetes.csv\", header=None)\n",
        "dataset = dataframe.values\n",
        "X = dataset[:,0:4].astype(float)\n",
        "Y = dataset[:,4]\n",
        "# encode class values as integers\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(Y)\n",
        "encoded_Y = encoder.transform(Y)\n",
        "# convert integers to dummy variables (i.e. one hot encoded)\n",
        "dummy_y = np_utils.to_categorical(encoded_Y)\n",
        " \n",
        "# define baseline model\n",
        "def baseline_model():\n",
        "\t# create model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Dense(8, input_dim=4, activation='relu'))\n",
        "\tmodel.add(Dense(3, activation='softmax'))\n",
        "\t# Compile model\n",
        "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\treturn model\n",
        " \n",
        "estimator = KerasClassifier(build_fn=baseline_model, epochs=200, batch_size=5, verbose=0)\n",
        "kfold = KFold(n_splits=10, shuffle=True)\n",
        "results = cross_val_score(estimator, X, dummy_y, cv=kfold)\n",
        "print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-a03a7f1edee1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mdataframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/diabetes.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# encode class values as integers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Pregnancies'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M29kX1FBXjVx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MM4RoEPaXjZR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "outputId": "1d656743-b0e1-42c9-d8d4-3335a64dc455"
      },
      "source": [
        "# Multiclass Classification with the Iris Flowers Dataset\n",
        "import numpy\n",
        "import pandas\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.utils import np_utils\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "# load dataset\n",
        "dataframe = pandas.read_csv(\"/content/diabetes.csv\", header=None)\n",
        "dataset = dataframe.values\n",
        "X = dataset.iloc[:,0:4].values()\n",
        "Y = dataset.iloc[:,4].values()\n",
        "# encode class values as integers\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(Y)\n",
        "encoded_Y = encoder.transform(Y)\n",
        "# convert integers to dummy variables (i.e. one hot encoded)\n",
        "dummy_y = np_utils.to_categorical(encoded_Y)\n",
        "\n",
        "# define baseline model\n",
        "def baseline_model():\n",
        "# create model\n",
        "   model = Sequential()\n",
        "   model.add(Dense(4, input_dim=4, init= normal , activation = relu ))\n",
        "   model.add(Dense(3, init= normal , activation = sigmoid ))\n",
        "   # Compile model\n",
        "   model.compile(loss= categorical_crossentropy , optimizer= adam , metrics=[ accuracy ])\n",
        "   return model\n",
        "\n",
        "estimator = KerasClassifier(build_fn=baseline_model, nb_epoch=200, batch_size=5, verbose=0)\n",
        "kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "results = cross_val_score(estimator, X, dummy_y, cv=kfold)\n",
        "print(\"Accuracy: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-9c37649669ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mdataframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/diabetes.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# encode class values as integers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'iloc'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_uHEToJXjlC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 726
        },
        "outputId": "89d55eea-418a-41bf-db78-f547b807c3d0"
      },
      "source": [
        "# multi-class classification with Keras\n",
        "import pandas\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.utils import np_utils\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.pipeline import Pipeline\n",
        "# load dataset\n",
        "dataframe = pandas.read_csv(\"/content/Iris.csv\", header=None)\n",
        "dataset = dataframe.values\n",
        "X = dataset[1:,0:4].astype(float)\n",
        "Y = dataset[1:,4]\n",
        "# encode class values as integers\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(Y)\n",
        "encoded_Y = encoder.transform(Y)\n",
        "# convert integers to dummy variables (i.e. one hot encoded)\n",
        "dummy_y = to_categorical(encoded_Y)\n",
        "\n",
        "# define baseline model\n",
        "def baseline_model():\n",
        "\t# create model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Dense(8, input_dim=4, activation='relu'))\n",
        "\tmodel.add(Dense(3, activation='softmax'))\n",
        "\t# Compile model\n",
        "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\treturn model\n",
        "\n",
        "estimator = KerasClassifier(build_fn=baseline_model, epochs=200, batch_size=5, verbose=0)\n",
        "kfold = KFold(n_splits=10, shuffle=True)\n",
        "results = cross_val_score(estimator, X, dummy_y, cv=kfold)\n",
        "print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Error when checking target: expected dense_82 to have shape (3,) but got array with shape (22,)\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Error when checking target: expected dense_84 to have shape (3,) but got array with shape (22,)\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Error when checking target: expected dense_86 to have shape (3,) but got array with shape (22,)\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Error when checking target: expected dense_88 to have shape (3,) but got array with shape (22,)\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Error when checking target: expected dense_90 to have shape (3,) but got array with shape (22,)\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Baseline: nan% (nan%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Error when checking target: expected dense_92 to have shape (3,) but got array with shape (22,)\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Error when checking target: expected dense_94 to have shape (3,) but got array with shape (22,)\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Error when checking target: expected dense_96 to have shape (3,) but got array with shape (22,)\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Error when checking target: expected dense_98 to have shape (3,) but got array with shape (22,)\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Error when checking target: expected dense_100 to have shape (3,) but got array with shape (22,)\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3u45RYFXjuN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGrO_jJ5Xj0r"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4zGrEDTXjyn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrA4LYMWXjrO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "da2c0f57-3b7e-4acd-b664-c042f446cc7f"
      },
      "source": [
        "  # Binary Classification with Sonar Dataset: Baseline\n",
        "import numpy\n",
        "import pandas\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "# load dataset\n",
        "dataframe = pandas.read_csv(\"/content/sonar (1).all-data\", header=None)\n",
        "dataset = dataframe.values\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[:,0:60].astype(float)\n",
        "Y = dataset[:,60]\n",
        "# encode class values as integers\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(Y)\n",
        "encoded_Y = encoder.transform(Y)\n",
        "\n",
        "# baseline model\n",
        "def create_baseline():\n",
        "   # create model\n",
        "   model = Sequential()\n",
        "   model.add(Dense(60, input_dim=60, kernel_initializer= 'normal' , activation= 'relu' ))\n",
        "   model.add(Dense(40, kernel_initializer='normal', activation = 'relu'))\n",
        "  \n",
        "   model.add(Dense(1, kernel_initializer = 'normal' , activation= 'sigmoid' ))\n",
        "   # Compile model\n",
        "   model.compile(loss= 'binary_crossentropy' , optimizer= 'adam' , metrics=[ 'accuracy' ])\n",
        "   return model\n",
        "\n",
        "# evaluate model with standardized dataset\n",
        "estimator = KerasClassifier(build_fn=create_baseline, nb_epoch=100, batch_size=240, verbose=0)\n",
        "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "results = cross_val_score(estimator, X, encoded_Y, cv=kfold)\n",
        "print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))   "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Baseline: 53.38% (3.42%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVvuAB3r-6M2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBPMG9liXjpO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zl3oKfo2Xjii",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5cce4c15-585c-41e7-c27c-a6c2da0bf04d"
      },
      "source": [
        "#Binary Clasiification with Sonar Dataset: Standardized\n",
        "\n",
        "import numpy\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense \n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "#fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "\n",
        "#load dataset \n",
        "dataset = pd.read_csv(\"/content/sonar (1).all-data\", header=None)\n",
        "#Split the dataset into X and Y variable\n",
        "X = dataset.iloc[:, :60]\n",
        "Y = dataset.iloc[:, 60]\n",
        "\n",
        "#encode the varible as integer\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(Y)\n",
        "encoded_Y = encoder.transform(Y)\n",
        "\n",
        "#baseline model\n",
        "def baseline_model():\n",
        "   # create model\n",
        "   model = Sequential()\n",
        "   model.add(Dense(60, input_dim=60, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "   model.add(Dense(30, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "   model.add(Dense(1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
        "\n",
        "   #compile model \n",
        "   model.compile(loss= 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "\n",
        "   return model\n",
        "\n",
        "#Evaluate baseline model with standardized dataset\n",
        "numpy.random.seed(seed)\n",
        "estimators = []\n",
        "estimators.append((\"standardize\", StandardScaler()))\n",
        "estimators.append((\"mlp\", KerasClassifier(build_fn = baseline_model, epochs = 100, batch_size = 10, verbose = 0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "\n",
        "kfold = StratifiedKFold(n_splits = 10, shuffle = True, random_state = seed)\n",
        "results = cross_val_score(pipeline, X, encoded_Y, cv = kfold )\n",
        "print(results.mean()*100, results.std()*100)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "87.45238125324249 8.826913274634286\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBsEhIXkXje3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "169d1c47-907f-4ecb-83ef-c9e33449af7c"
      },
      "source": [
        "# Regression Example With Boston Dataset: Baseline\n",
        "import numpy\n",
        "import pandas\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "# load dataset\n",
        "dataframe = pandas.read_csv(\"housing.csv\", delim_whitespace=True, header=None)\n",
        "dataset = dataframe.values\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[:,0:13]\n",
        "Y = dataset[:,13]\n",
        "\n",
        "# define base model\n",
        "def baseline_model():\n",
        "# create model\n",
        "   model = Sequential()\n",
        "   model.add(Dense(13, input_dim=13, kernel_initializer= 'normal' , activation= 'relu' ))\n",
        "   model.add(Dense(1, kernel_initializer= 'normal' ))\n",
        "   # Compile model\n",
        "   model.compile(loss= 'mean_squared_error' , optimizer= 'adam')\n",
        "   return model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-30-bb556d003bbb>\"\u001b[0;36m, line \u001b[0;32m20\u001b[0m\n\u001b[0;31m    model = Sequential()\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEhR8IuAXjcR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        },
        "outputId": "83689b70-c6fe-4e86-f423-d260152bf6c2"
      },
      "source": [
        "# Visualize training history\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "# load pima indians dataset\n",
        "dataset = pandas.read_csv(\"/content/diabetes.csv\", delimiter=\",\")\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset.iloc[:,0:8]\n",
        "Y = dataset.iloc[:,8]\n",
        "# create model\n",
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim=8, kernel_initializer= 'uniform' , activation= 'relu' ))\n",
        "model.add(Dense(8, kernel_initializer= 'uniform' , activation= 'relu' ))\n",
        "model.add(Dense(1, kernel_initializer= 'uniform' , activation= 'sigmoid' ))\n",
        "# Compile model\n",
        "model.compile(loss= 'binary_crossentropy' , optimizer= 'adam' , metrics=['accuracy'])\n",
        "# Fit the model\n",
        "history = model.fit(X, Y, validation_split=0.33, epochs=150, batch_size=10, verbose=0)\n",
        "# list all data in history\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train' , 'test' ], loc= 'upper left')\n",
        "plt.show()\n",
        "#summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train' , 'test'], loc= 'upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o170KbqaXiyc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oowz94u9ITkQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "29ef30d8-4ecf-4e34-8df2-71ccc1cff6a4"
      },
      "source": [
        "# Baseline Model on the Sonar Dataset\n",
        "import numpy\n",
        "import pandas\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.constraints import maxnorm\n",
        "from keras.optimizers import SGD\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "# load dataset\n",
        "dataframe = pandas.read_csv(\"/content/sonar (1).all-data\", header=None)\n",
        "dataset = dataframe.values\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[:,0:60].astype(float)\n",
        "Y = dataset[:,60]\n",
        "# encode class values as integers\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(Y)\n",
        "encoded_Y = encoder.transform(Y)\n",
        "# baseline\n",
        "def create_baseline():\n",
        "  # create model\n",
        "  model = Sequential()\n",
        "  model.add(Dense(60, input_dim = 60, kernel_initializer ='uniform', activation = 'relu'))\n",
        "  model.add(Dense(30, kernel_initializer='uniform', activation = 'relu'))\n",
        "  model.add(Dense(1, kernel_initializer='uniform', activation = 'sigmoid'))\n",
        "  # Compile model\n",
        "  sgd = SGD(lr=0.01, momentum=0.8, decay=0.0, nesterov=False)\n",
        "  model.compile(loss= 'binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "numpy.random.seed(seed)\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp' , KerasClassifier(build_fn=create_baseline, nb_epoch=300, batch_size=16, verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "results = cross_val_score(pipeline, X, encoded_Y, cv=kfold)\n",
        "print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Baseline: 53.38% (1.62%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4v2M4YhBITgZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "e5ac39b5-7c6a-4510-8e25-3b5984bc76b1"
      },
      "source": [
        "# Example of Dropout on the Sonar Dataset: Visible Layer\n",
        "import numpy\n",
        "import pandas\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.constraints import maxnorm\n",
        "from keras.optimizers import SGD\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "# load dataset\n",
        "dataframe = pandas.read_csv(\"/content/sonar (1).all-data\", header=None)\n",
        "dataset = dataframe.values\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[:,0:60].astype(float)\n",
        "Y = dataset[:,60]\n",
        "# encode class values as integers\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(Y)\n",
        "encoded_Y = encoder.transform(Y)\n",
        "# dropout in the input layer with weight constraint\n",
        "def create_model():\n",
        "# create model\n",
        "  model = Sequential()\n",
        "  \n",
        "  model.add(Dense(60, input_dim = 60, kernel_initializer = 'uniform' , activation= 'relu' , W_constraint=maxnorm(3)))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(30, kernel_initializer = 'uniform' , activation= 'relu' , W_constraint=maxnorm(3)))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(1, kernel_initializer = 'uniform' , activation= 'sigmoid' ))\n",
        "  # Compile model\n",
        "  sgd = SGD(lr=0.1, momentum=0.9, decay=0.0, nesterov=False)\n",
        "  model.compile(loss= 'binary_crossentropy' , optimizer=sgd, metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "numpy.random.seed(seed)\n",
        "estimators = []\n",
        "estimators.append(('standardize' , StandardScaler()))\n",
        "estimators.append(('mlp' , KerasClassifier(build_fn=create_model, nb_epoch=300, batch_size=16, verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "results = cross_val_score(pipeline, X, encoded_Y, cv=kfold)\n",
        "print(\"Visible: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:33: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(60, input_dim=60, kernel_initializer=\"uniform\", activation=\"relu\", kernel_constraint=<keras.con...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:35: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(30, kernel_initializer=\"uniform\", activation=\"relu\", kernel_constraint=<keras.con...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:33: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(60, input_dim=60, kernel_initializer=\"uniform\", activation=\"relu\", kernel_constraint=<keras.con...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:35: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(30, kernel_initializer=\"uniform\", activation=\"relu\", kernel_constraint=<keras.con...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:33: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(60, input_dim=60, kernel_initializer=\"uniform\", activation=\"relu\", kernel_constraint=<keras.con...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:35: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(30, kernel_initializer=\"uniform\", activation=\"relu\", kernel_constraint=<keras.con...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:33: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(60, input_dim=60, kernel_initializer=\"uniform\", activation=\"relu\", kernel_constraint=<keras.con...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:35: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(30, kernel_initializer=\"uniform\", activation=\"relu\", kernel_constraint=<keras.con...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:33: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(60, input_dim=60, kernel_initializer=\"uniform\", activation=\"relu\", kernel_constraint=<keras.con...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:35: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(30, kernel_initializer=\"uniform\", activation=\"relu\", kernel_constraint=<keras.con...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:33: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(60, input_dim=60, kernel_initializer=\"uniform\", activation=\"relu\", kernel_constraint=<keras.con...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:35: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(30, kernel_initializer=\"uniform\", activation=\"relu\", kernel_constraint=<keras.con...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:33: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(60, input_dim=60, kernel_initializer=\"uniform\", activation=\"relu\", kernel_constraint=<keras.con...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:35: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(30, kernel_initializer=\"uniform\", activation=\"relu\", kernel_constraint=<keras.con...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:33: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(60, input_dim=60, kernel_initializer=\"uniform\", activation=\"relu\", kernel_constraint=<keras.con...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:35: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(30, kernel_initializer=\"uniform\", activation=\"relu\", kernel_constraint=<keras.con...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:33: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(60, input_dim=60, kernel_initializer=\"uniform\", activation=\"relu\", kernel_constraint=<keras.con...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:35: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(30, kernel_initializer=\"uniform\", activation=\"relu\", kernel_constraint=<keras.con...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:33: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(60, input_dim=60, kernel_initializer=\"uniform\", activation=\"relu\", kernel_constraint=<keras.con...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:35: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(30, kernel_initializer=\"uniform\", activation=\"relu\", kernel_constraint=<keras.con...)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Visible: 53.38% (1.62%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxLVsF8iNTdD"
      },
      "source": [
        "import pandas\n",
        "import numpy\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import SGD\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "# load dataset\n",
        "dataframe = pandas.read_csv(\"\", header=None)\n",
        "dataset = dataframe.values\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[:,0:34].astype(float)\n",
        "Y = dataset[:,34]\n",
        "# encode class values as integers\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(Y)\n",
        "Y = encoder.transform(Y)\n",
        "# create model\n",
        "model = Sequential()\n",
        "model.add(Dense(34, input_dim=34, init= normal , activation= relu ))\n",
        "model.add(Dense(1, init= normal , activation= sigmoid ))\n",
        "# Compile model\n",
        "epochs = 50\n",
        "learning_rate = 0.1\n",
        "decay_rate = learning_rate / epochs\n",
        "momentum = 0.8\n",
        "sgd = SGD(lr=learning_rate, momentum=momentum, decay=decay_rate, nesterov=False)\n",
        "model.compile(loss= binary_crossentropy , optimizer=sgd, metrics=[ accuracy ])\n",
        "# Fit the model\n",
        "model.fit(X, Y, validation_split=0.33, nb_epoch=epochs, batch_size=28, verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBXBgV6qNTgi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUtBVvCPNTjq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z58eYVgGNTm6"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import KFold"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhuQgxpcNTp1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "fc790522-30bd-4807-f8e1-b12d29e666b3"
      },
      "source": [
        "df = pd.read_csv('/content/datasets_228_482_diabetes.csv')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Pregnancies  Glucose  BloodPressure  ...  DiabetesPedigreeFunction  Age  Outcome\n",
              "0            6      148             72  ...                     0.627   50        1\n",
              "1            1       85             66  ...                     0.351   31        0\n",
              "2            8      183             64  ...                     0.672   32        1\n",
              "3            1       89             66  ...                     0.167   21        0\n",
              "4            0      137             40  ...                     2.288   33        1\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APb4G_iGs9qG"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgfHvDYns-Q-"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ib7zbcNEvzly"
      },
      "source": [
        "X = df.drop('Outcome', axis=1)\n",
        "X = StandardScaler().fit_transform(X)\n",
        "y = df['Outcome']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPCSfORRvzs5"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.25, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tu_zb9iBvz8h"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TrTa71ov0R8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "0665e7f9-7d54-487a-c60a-29c8138fcdb9"
      },
      "source": [
        "model = SVC()\n",
        "kernel = ['poly', 'rbf', 'sigmoid']\n",
        "C = [50, 10, 1.0, 0.1, 0.01]\n",
        "gamma = ['scale']\n",
        "# define grid search\n",
        "grid = dict(kernel=kernel,C=C,gamma=gamma)\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
        "grid_result = grid_search.fit(X, y)\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best: 0.758704 using {'C': 0.1, 'gamma': 'scale', 'kernel': 'sigmoid'}\n",
            "0.719999 (0.040300) with: {'C': 50, 'gamma': 'scale', 'kernel': 'poly'}\n",
            "0.709655 (0.054998) with: {'C': 50, 'gamma': 'scale', 'kernel': 'rbf'}\n",
            "0.679255 (0.057011) with: {'C': 50, 'gamma': 'scale', 'kernel': 'sigmoid'}\n",
            "0.738226 (0.039583) with: {'C': 10, 'gamma': 'scale', 'kernel': 'poly'}\n",
            "0.750849 (0.043030) with: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
            "0.685743 (0.046110) with: {'C': 10, 'gamma': 'scale', 'kernel': 'sigmoid'}\n",
            "0.739981 (0.038349) with: {'C': 1.0, 'gamma': 'scale', 'kernel': 'poly'}\n",
            "0.756089 (0.045867) with: {'C': 1.0, 'gamma': 'scale', 'kernel': 'rbf'}\n",
            "0.708738 (0.047943) with: {'C': 1.0, 'gamma': 'scale', 'kernel': 'sigmoid'}\n",
            "0.715710 (0.031721) with: {'C': 0.1, 'gamma': 'scale', 'kernel': 'poly'}\n",
            "0.753907 (0.039248) with: {'C': 0.1, 'gamma': 'scale', 'kernel': 'rbf'}\n",
            "0.758704 (0.044031) with: {'C': 0.1, 'gamma': 'scale', 'kernel': 'sigmoid'}\n",
            "0.655827 (0.009918) with: {'C': 0.01, 'gamma': 'scale', 'kernel': 'poly'}\n",
            "0.651059 (0.003418) with: {'C': 0.01, 'gamma': 'scale', 'kernel': 'rbf'}\n",
            "0.651059 (0.003418) with: {'C': 0.01, 'gamma': 'scale', 'kernel': 'sigmoid'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fe7E3NP0QwG-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "ef51a7b5-f243-4b86-85a0-2c5632f3c9f5"
      },
      "source": [
        "model = SVC(C = 0.1, gamma = 'scale', kernel = 'sigmoid')\n",
        "model.fit(X_train, y_train)\n",
        "predictions = cross_val_predict(model, X_test, y_test, cv=5)\n",
        "print(classification_report(y_test, predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.98      0.82       130\n",
            "           1       0.82      0.15      0.25        62\n",
            "\n",
            "    accuracy                           0.71       192\n",
            "   macro avg       0.76      0.56      0.53       192\n",
            "weighted avg       0.74      0.71      0.64       192\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Iec_1LXRPA9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "ac5b518a-2295-4342-97f5-f4c1f68df196"
      },
      "source": [
        "print(confusion_matrix(y_test, predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[128   2]\n",
            " [ 53   9]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EV7GOkJRSew",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7809e138-3617-4a87-ca63-373f8f4face2"
      },
      "source": [
        "score = np.mean(cross_val_score(model, X_test, y_test, cv=5, scoring='roc_auc'))\n",
        "np.around(score, decimals=4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8363"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZdrveSOv0bL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "4fdb6791-172d-4e93-b3e7-304af0ea5645"
      },
      "source": [
        "model = RandomForestClassifier()\n",
        "n_estimators = [10, 100, 1000]\n",
        "max_features = ['sqrt', 'log2']\n",
        "# define grid search\n",
        "grid = dict(n_estimators=n_estimators,max_features=max_features)\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
        "grid_result = grid_search.fit(X, y)\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best: 0.765197 using {'max_features': 'log2', 'n_estimators': 100}\n",
            "0.747431 (0.038258) with: {'max_features': 'sqrt', 'n_estimators': 10}\n",
            "0.764758 (0.042945) with: {'max_features': 'sqrt', 'n_estimators': 100}\n",
            "0.764348 (0.046405) with: {'max_features': 'sqrt', 'n_estimators': 1000}\n",
            "0.739998 (0.042670) with: {'max_features': 'log2', 'n_estimators': 10}\n",
            "0.765197 (0.040648) with: {'max_features': 'log2', 'n_estimators': 100}\n",
            "0.763038 (0.045600) with: {'max_features': 'log2', 'n_estimators': 1000}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4cBsbH5v0Xv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "dd3ed180-ac95-43cd-8fc2-da624c6ddc8f"
      },
      "source": [
        "model = RandomForestClassifier(max_features = 'log2', n_estimators = 100)\n",
        "model.fit(X_train, y_train)\n",
        "predictions = cross_val_predict(model, X_test, y_test, cv=5)\n",
        "print(classification_report(y_test, predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.85      0.83       130\n",
            "           1       0.64      0.55      0.59        62\n",
            "\n",
            "    accuracy                           0.76       192\n",
            "   macro avg       0.72      0.70      0.71       192\n",
            "weighted avg       0.75      0.76      0.75       192\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9buAACKv0Vr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "ed7c470e-b4c2-4a83-bd5f-a9927191690d"
      },
      "source": [
        "print(confusion_matrix(y_test, predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[111  19]\n",
            " [ 28  34]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4hYZz2Qv0Pr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e6ee8233-7fa2-4bea-dd47-534b1f6dab31"
      },
      "source": [
        "score = np.mean(cross_val_score(model, X_test, y_test, cv=5, scoring='roc_auc'))\n",
        "np.around(score, decimals=4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8262"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3Xko7Ywv0NI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "to6jf-33v0KM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a674bb85-ff6b-495c-83a1-e4d29df0fdca"
      },
      "source": [
        "           \n",
        "a = []\n",
        "a = [int(item) for item in input().split()]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QwNXIsWv0H2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Abby1PMBv0Fa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRiaOGRAv0Ct"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLshK0xov0Am"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQLMItK5vz6F"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MJ2KiWXvz3o"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2WA7nhsvz0p"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvALKu0svzyn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSOZpSCtvzxQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhfoXuQ-vzqX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouQNRpcRvr1c"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_nzhxZrvrzC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_BPAfCKvru2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}